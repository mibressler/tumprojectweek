{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:29.325377971Z",
     "start_time": "2024-01-11T04:01:20.538849213Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (23.3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (2.1.4)\n",
      "Requirement already satisfied: tables in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python310\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from tables) (2.8.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from tables) (23.2)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from tables) (9.0.0)\n",
      "Requirement already satisfied: blosc2>=2.3.0 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from tables) (2.4.0)\n",
      "Requirement already satisfied: ndindex>=1.4 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from blosc2>=2.3.0->tables) (1.7)\n",
      "Requirement already satisfied: msgpack in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from blosc2>=2.3.0->tables) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "     -------------------------------------- 126.8/126.8 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in c:\\program files\\python310\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: torchvision in c:\\program files\\python310\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: torchaudio in c:\\program files\\python310\\lib\\site-packages (0.11.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (3.4.2)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tokenizers-0.15.0-cp310-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp310-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\program files\\python310\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (9.5.0)\n",
      "Collecting psutil (from peft)\n",
      "  Downloading psutil-5.9.7-cp37-abi3-win_amd64.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of peft to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting peft\n",
      "  Downloading peft-0.7.0-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading peft-0.6.1-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading peft-0.6.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading peft-0.3.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB 2.9 MB/s eta 0:00:00\n",
      "INFO: pip is still looking at multiple versions of peft to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading peft-0.2.0-py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "  Downloading peft-0.1.0-py3-none-any.whl (38 kB)\n",
      "  Downloading peft-0.0.2-py3-none-any.whl (34 kB)\n",
      "  Downloading peft-0.0.1-py3-none-any.whl (34 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.1.2-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-2.1.1-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.1.0-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 19.4 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-2.0.1-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 22.5 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-0.13.1-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 26.1 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-0.13.0-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 7.3 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-0.12.1-cp310-cp310-win_amd64.whl (969 kB)\n",
      "     ------------------------------------- 969.7/969.7 kB 10.2 MB/s eta 0:00:00\n",
      "INFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-0.12.0-cp310-cp310-win_amd64.whl (969 kB)\n",
      "     ------------------------------------- 969.8/969.8 kB 15.5 MB/s eta 0:00:00\n",
      "  Downloading torchaudio-0.11.0-cp310-cp310-win_amd64.whl (372 kB)\n",
      "     ------------------------------------- 372.6/372.6 kB 11.7 MB/s eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.2-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2023.12.2)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-0.26.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\michi\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch) (1.2.1)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "   ---------------------------------------- 8.2/8.2 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.16.2-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 1.1/1.1 MB 17.9 MB/s eta 0:00:00\n",
      "Downloading torch-2.1.2-cp310-cp310-win_amd64.whl (192.3 MB)\n",
      "   --------------------------------------- 192.3/192.3 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.1.2-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 2.3/2.3 MB 21.2 MB/s eta 0:00:00\n",
      "Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
      "   --------------------------------------- 168.3/168.3 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.26.0-py3-none-any.whl (270 kB)\n",
      "   --------------------------------------- 270.7/270.7 kB 16.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "   --------------------------------------- 330.3/330.3 kB 20.0 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.1-cp310-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 277.3/277.3 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.0-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.7-cp37-abi3-win_amd64.whl (252 kB)\n",
      "   ---------------------------------------- 252.2/252.2 kB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, psutil, torch, huggingface-hub, torchvision, torchaudio, tokenizers, accelerate, transformers, peft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip \n",
    "import datetime\n",
    "!pip install pandas tables\n",
    "import pandas as pd\n",
    "!pip install transformers torch torchvision torchaudio peft\n",
    "!pip -qqq install bitsandbytes accelerate\n",
    "import torch\n",
    "\n",
    "print(f\"{torch.cuda.is_available()=}\\t{torch.cuda.device_count()=}\\t{torch.version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e280f03a3113c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:29.325612691Z",
     "start_time": "2024-01-11T04:01:29.314007703Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('processed_data.pkl')\n",
    "training_df = df[df[\"train\"]]\n",
    "testing_df = df[df[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc0d3e00d125c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:29.325750282Z",
     "start_time": "2024-01-11T04:01:29.314128043Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROMT_DIR_PATH = Path(\"mistral-prediction\") / \"prompt-variations\"\n",
    "\n",
    "PROMT_PATHS = sorted(PROMT_DIR_PATH.glob(\"v*.txt\"), key=lambda f: int(f.name.strip(\"v.txt\")))\n",
    "SYSTEM_PROMPT = [f.read_text(encoding=\"utf-8\") for f in PROMT_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf84439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:34.720617951Z",
     "start_time": "2024-01-11T04:01:29.314201183Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fd5fdb0f2440e48a77359e3c966163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_path = \"mibressler/tumproject\"\n",
    "token = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, token=token)\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=nf4_config,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype='auto',\n",
    "    token=token,\n",
    ").eval()\n",
    "\n",
    "def generate_response(system_promt: str, text: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": system_promt + \"\\nText to evaluate: \\\"\" + text + \"\\\"\"},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True,\n",
    "                                              return_tensors='pt')\n",
    "    output_ids = model.generate(input_ids=input_ids.to('cuda'), max_new_tokens=1024)\n",
    "    return tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def run_model(prompt_id: int, model: str):\n",
    "    results = []\n",
    "    start_time = datetime.datetime.now()\n",
    "    for i, (row_index, row) in enumerate(testing_df.iterrows()):\n",
    "        total = testing_df[\"text\"].count()\n",
    "        counter = i + 1\n",
    "        elapsed = datetime.datetime.now() - start_time\n",
    "        percentage = counter / total\n",
    "        s_per_gen = elapsed / counter\n",
    "        print(f'[{elapsed}<{s_per_gen * (total - counter)}, {s_per_gen}s/generations] '\n",
    "              f'{model} - promt {prompt_id}: {counter}/{total} | {percentage * 100:.2f}%')\n",
    "        answer = generate_response(SYSTEM_PROMPT[prompt_id], row[\"text\"])\n",
    "        results.append({\n",
    "            'prompt_id': prompt_id,\n",
    "            'model': model,\n",
    "            'sample_size': total,\n",
    "            \"text\": row[\"text\"],\n",
    "            \"answer\": answer,\n",
    "            \"labeled_hateful\": row[\"hate\"]\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa5115",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-11T04:01:34.727708312Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_runs = pd.DataFrame()\n",
    "for i in range(len(SYSTEM_PROMPT)):\n",
    "    run = run_model(i, \"fine-tuned-mistral-7b-v0.2-instruct\")\n",
    "    all_runs = pd.concat([all_runs, run])\n",
    "    pd.DataFrame(all_runs).to_pickle(\"fine-tuned.pkl\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223579e746ec60",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fa34e",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587e2b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29324/2859821035.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Your text input for explanation\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_in_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\lime\\lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    411\u001b[0m                                         mask_string=self.mask_string))\n\u001b[0;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         data, yss, distances = self.__data_labels_distances(\n\u001b[0m\u001b[0;32m    414\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m             distance_metric=distance_metric)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\lime\\lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[1;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29324/2859821035.py\u001b[0m in \u001b[0;36mpredict_fn\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSYSTEM_PROMPT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\"hate_speech_probability\": (\\d+\\.\\d+)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_response' is not defined"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import re\n",
    "\n",
    "def predict_fn(texts):\n",
    "    probabilities = []\n",
    "    for text in texts:\n",
    "        answer = generate_response(SYSTEM_PROMPT[0], text)\n",
    "        match = re.search(r'\"hate_speech_probability\": (\\d+\\.\\d+)', answer)\n",
    "        if match:\n",
    "            hate_speech_probability = float(match.group(1))\n",
    "            probabilities.append([1 - hate_speech_probability, hate_speech_probability])\n",
    "    return probabilities\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=[\"Not Hate Speech\", \"Hate Speech\"]) \n",
    "\n",
    "instance = \"Your text input for explanation\"\n",
    "\n",
    "exp = explainer.explain_instance(instance, predict_fn, num_features=5)\n",
    "\n",
    "exp.show_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
