{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:30:45.272472544Z",
     "start_time": "2024-01-10T01:30:39.335001892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (1.26.3)\r\n",
      "Requirement already satisfied: pandas in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (2.1.4)\r\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from pandas) (1.26.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from pandas) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: tables in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (3.9.2)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from tables) (1.26.3)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from tables) (2.8.8)\r\n",
      "Requirement already satisfied: packaging in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from tables) (23.2)\r\n",
      "Requirement already satisfied: py-cpuinfo in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from tables) (9.0.0)\r\n",
      "Requirement already satisfied: blosc2>=2.3.0 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from tables) (2.4.0)\r\n",
      "Requirement already satisfied: ndindex>=1.4 in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from blosc2>=2.3.0->tables) (1.7)\r\n",
      "Requirement already satisfied: msgpack in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (from blosc2>=2.3.0->tables) (1.0.7)\r\n",
      "Requirement already satisfied: tqdm in /home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages (4.66.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tables\n",
    "import pandas as pd\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f4e280f03a3113c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:30:45.304785313Z",
     "start_time": "2024-01-10T01:30:45.274132352Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('processed_data.pkl')\n",
    "training_df = df[df[\"train\"]]\n",
    "testing_df = df[df[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0ccc458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T01:30:45.314442308Z",
     "start_time": "2024-01-10T01:30:45.308433769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          file_id  user_id  subforum_id  num_contexts   hate  \\\n0      12834217_1   572066         1346             0  False   \n1      12834217_2   572066         1346             0  False   \n2      12834217_3   572066         1346             0  False   \n3      12834217_4   572066         1346             0   True   \n4      12834217_5   572066         1346             0  False   \n...           ...      ...          ...           ...    ...   \n10939  33676864_5   734541         1388             0  False   \n10940  33677019_1   735154         1388             0  False   \n10941  33677019_2   735154         1388             0  False   \n10942  33677053_1   572266         1388             0   True   \n10943  33677053_2   572266         1388             0  False   \n\n                                                    text  train   test  \n0      As of March 13th , 2014 , the booklet had been...  False  False  \n1      In order to help increase the booklets downloa...   True  False  \n2      ( Simply copy and paste the following text int...  False  False  \n3      Click below for a FREE download of a colorfull...   True  False  \n4      Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...  False  False  \n...                                                  ...    ...    ...  \n10939  Billy - `` That guy would n't leave me alone ,...  False  False  \n10940  Wish we at least had a Marine Le Pen to vote f...  False  False  \n10941  Its like the choices are white genocide candid...  False  False  \n10942  Why White people used to say that sex was a si...   True  False  \n10943                                     Now I get it !  False   True  \n\n[10703 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_id</th>\n      <th>user_id</th>\n      <th>subforum_id</th>\n      <th>num_contexts</th>\n      <th>hate</th>\n      <th>text</th>\n      <th>train</th>\n      <th>test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12834217_1</td>\n      <td>572066</td>\n      <td>1346</td>\n      <td>0</td>\n      <td>False</td>\n      <td>As of March 13th , 2014 , the booklet had been...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12834217_2</td>\n      <td>572066</td>\n      <td>1346</td>\n      <td>0</td>\n      <td>False</td>\n      <td>In order to help increase the booklets downloa...</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12834217_3</td>\n      <td>572066</td>\n      <td>1346</td>\n      <td>0</td>\n      <td>False</td>\n      <td>( Simply copy and paste the following text int...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12834217_4</td>\n      <td>572066</td>\n      <td>1346</td>\n      <td>0</td>\n      <td>True</td>\n      <td>Click below for a FREE download of a colorfull...</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12834217_5</td>\n      <td>572066</td>\n      <td>1346</td>\n      <td>0</td>\n      <td>False</td>\n      <td>Click on the `` DOWNLOAD ( 7.42 MB ) '' green ...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10939</th>\n      <td>33676864_5</td>\n      <td>734541</td>\n      <td>1388</td>\n      <td>0</td>\n      <td>False</td>\n      <td>Billy - `` That guy would n't leave me alone ,...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10940</th>\n      <td>33677019_1</td>\n      <td>735154</td>\n      <td>1388</td>\n      <td>0</td>\n      <td>False</td>\n      <td>Wish we at least had a Marine Le Pen to vote f...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10941</th>\n      <td>33677019_2</td>\n      <td>735154</td>\n      <td>1388</td>\n      <td>0</td>\n      <td>False</td>\n      <td>Its like the choices are white genocide candid...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10942</th>\n      <td>33677053_1</td>\n      <td>572266</td>\n      <td>1388</td>\n      <td>0</td>\n      <td>True</td>\n      <td>Why White people used to say that sex was a si...</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10943</th>\n      <td>33677053_2</td>\n      <td>572266</td>\n      <td>1388</td>\n      <td>0</td>\n      <td>False</td>\n      <td>Now I get it !</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>10703 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3dc0d3e00d125c3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:30:45.399006122Z",
     "start_time": "2024-01-10T01:30:45.313484162Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = ['prompt-variations/v0.txt', 'prompt-variations/v1.txt']\n",
    "SYSTEM_PROMPT = []\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r') as file:\n",
    "        SYSTEM_PROMPT.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cf84439",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:30:45.400175303Z",
     "start_time": "2024-01-10T01:30:45.357843243Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PPLX_KEY\")\n",
    "VALID_MODELS = ['codellama-34b-instruct', 'llama-2-70b-chat', 'mistral-7b-instruct', 'mixtral-8x7b-instruct', 'pplx-7b-chat', 'pplx-70b-chat']\n",
    "\n",
    "def run_model(prompt_id, model, sample_size, print_results=False):\n",
    "    if model not in VALID_MODELS:\n",
    "        raise ValueError(f'Invalid model {model}. Valid options are {VALID_MODELS}')\n",
    "\n",
    "    sample_df = testing_df.sample(n=sample_size)\n",
    "\n",
    "    results = []\n",
    "    for index, row in tqdm(sample_df.iterrows(), total=sample_df[\"text\"].count(), unit=\"generations\", desc=f'Running {model} (Promt {prompt_id})'):\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": SYSTEM_PROMPT[prompt_id]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": row[\"text\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(\"https://api.perplexity.ai/chat/completions\", json=payload, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error\")\n",
    "        data = json.loads(response.text)\n",
    "        answer = data['choices'][0]['message']['content']\n",
    "        results.append({\n",
    "            'prompt_id': prompt_id,\n",
    "            'model': model,\n",
    "            'sample_size': sample_size,\n",
    "            \"text\": row[\"text\"],\n",
    "            \"answer\": answer,\n",
    "            \"labeled_hateful\": row[\"hate\"]\n",
    "        })\n",
    "        if print_results:\n",
    "            print(row[\"text\"])\n",
    "            if lines := [line for line in answer.split(\"\\n\") if \"hate_speech_probability\" in line]:\n",
    "                print(lines)\n",
    "            else:\n",
    "                print(answer)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(60*20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T02:01:30.408887875Z",
     "start_time": "2024-01-10T01:41:30.404900766Z"
    }
   },
   "id": "56f9e6fa1341c139",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 478/478 [25:13<00:00,  3.17s/it]\n",
      "  9%|â–‰         | 43/478 [02:31<25:35,  3.53s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 14\u001B[0m\n\u001B[1;32m      4\u001B[0m CONFIG \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      5\u001B[0m     (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmistral-7b-instruct\u001B[39m\u001B[38;5;124m'\u001B[39m, total_samples),\n\u001B[1;32m      6\u001B[0m     (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmixtral-8x7b-instruct\u001B[39m\u001B[38;5;124m'\u001B[39m, total_samples),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmixtral-8x7b-instruct\u001B[39m\u001B[38;5;124m'\u001B[39m, total_samples),\n\u001B[1;32m     11\u001B[0m ]\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m config \u001B[38;5;129;01min\u001B[39;00m CONFIG:\n\u001B[0;32m---> 14\u001B[0m     run \u001B[38;5;241m=\u001B[39m \u001B[43mrun_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m     all_runs \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([all_runs, run])\n\u001B[1;32m     16\u001B[0m     pd\u001B[38;5;241m.\u001B[39mDataFrame(all_runs)\u001B[38;5;241m.\u001B[39mto_pickle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall_runs.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[15], line 34\u001B[0m, in \u001B[0;36mrun_model\u001B[0;34m(prompt_id, model, sample_size, print_results)\u001B[0m\n\u001B[1;32m     32\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.perplexity.ai/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m, json\u001B[38;5;241m=\u001B[39mpayload, headers\u001B[38;5;241m=\u001B[39mheaders)\n\u001B[1;32m     33\u001B[0m data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext)\n\u001B[0;32m---> 34\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchoices\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     35\u001B[0m results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m: prompt_id,\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m: model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabeled_hateful\u001B[39m\u001B[38;5;124m\"\u001B[39m: row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhate\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     42\u001B[0m })\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m print_results:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "total_samples = len(testing_df)\n",
    "all_runs = pd.read_pickle(\"all_runs.pkl\")\n",
    "\n",
    "CONFIG = [\n",
    "    #(0, 'mistral-7b-instruct', total_samples),\n",
    "    (0, 'mixtral-8x7b-instruct', total_samples),\n",
    "    (0, 'pplx-70b-chat', total_samples),\n",
    "    (0, 'pplx-7b-chat', total_samples),\n",
    "    (1, 'mistral-7b-instruct', total_samples),\n",
    "    (1, 'mixtral-8x7b-instruct', total_samples),\n",
    "]\n",
    "\n",
    "for config in CONFIG:\n",
    "    run = run_model(*config)\n",
    "    all_runs = pd.concat([all_runs, run])\n",
    "    pd.DataFrame(all_runs).to_pickle(\"all_runs.pkl\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T02:29:15.403288016Z",
     "start_time": "2024-01-10T02:01:30.413958907Z"
    }
   },
   "id": "05aa5115",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_runs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T02:29:15.406069168Z",
     "start_time": "2024-01-10T02:29:15.405020591Z"
    }
   },
   "id": "cd355e8d7d370a48",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "all_runs = pd.read_pickle(\"all_runs.pkl\")\n",
    "all_runs = all_runs[all_runs[\"model\"]==\"mistral-7b-instruct\"]\n",
    "failed_runs = all_runs[all_runs[\"model\"]!=\"mistral-7b-instruct\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T08:17:39.004397512Z",
     "start_time": "2024-01-10T08:17:38.960981166Z"
    }
   },
   "id": "a15f65639f2f5d30",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
