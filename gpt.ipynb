{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python --version\n",
    "import datetime\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tables\n",
    "import pandas as pd\n",
    "!pip install plotly\n",
    "!pip install llamabot\n",
    "import llamabot\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"pre_processed.pickle\")\n",
    "training_df = df[df[\"train\"]]\n",
    "testing_df = df[df[\"test\"]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4e280f03a3113c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class Result(TypedDict):\n",
    "    model: str\n",
    "    time: datetime.datetime\n",
    "    promt_hash: int\n",
    "    hate_speach_probability: float\n",
    "\n",
    "\n",
    "results: list[Result] = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab3f8947f24b58e9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/478 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"relevant_facts\": [\n",
      "\"The speaker expresses a negative opinion about a specific neighborhood and its children.\",\n",
      "],\n",
      "\"contained_explicit_hate_speech_vocabular\": [],\n",
      "\"argument_for_hate_speech\": \"The speaker uses derogatory language to describe the children in the neighborhood, implying that they are undesirable or unworthy of consideration for teaching.\",\n",
      "\"argument_against_hate_speech\": \"The speaker's statement is an expression of personal preference and does not directly target a specific group based on their race, ethnicity, religion, or other protected characteristic.\",\n",
      "\"likelihood_of_presence_of_implicit_hate_speech\": 0.35,\n",
      "\"likelihood_of_presence_of_explicit_hate_speech\": 0.1,\n",
      "\"likelihood_of_ad_hominem_attack\": 0.2,\n",
      "\"likelihood_of_minority_attack\": 0.1,\n",
      "\"likelyhood_of_takedown_on_social_media\": 0.35,\n",
      "\"hate_speech_probability\": 0.25,\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/478 [00:06<50:57,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " { \n",
      "  \"relevant_facts\": [\n",
      "    \"The sentence discusses the behavior of students at certain schools.\",\n",
      "    \"It mentions the race or ethnicity of some students is relevant to the discussion.\",\n",
      "    \"There is a statement about the likelihood of certain actions being taken by these students.\"\n",
      "  ],\n",
      "  \"contained_explicit_hate_speech_vocabular\": [],\n",
      "  \"argument_for_hate_speech\": \"The sentence implies that white students are more likely to act in a negative way, which could be perceived as stereotyping and stigmatizing.\",\n",
      "  \"argument_against_hate_speech\": \"The sentence does not contain any explicit hate speech or slurs. It only mentions the race or ethnicity of the students in passing and focuses on their behavior.\",\n",
      "  \"likelihood_of_presence_of_implicit_hate_speech\": 0.51,\n",
      "  \"likelihood_of_presence_of_explicit_hate_speech\": 0,\n",
      "  \"likelihood_of_ad_hominem_attack\": 0.12,\n",
      "  \"likelihood_of_minority_attack\": 0.48,\n",
      "  \"likelyhood_of_takedown_on_social_media\": 0.56,\n",
      "  \"hate_speech_probability\": 0.37,\n",
      "}\n",
      "This sentence contains implicit hate speech as it stereotypes a specific racial or ethnic group. However, it does not contain any explicit hate speech vocabulary. The likelihood of presence of implicit hate speech is relatively high due to the stereotyping nature of the statement. The likelihood of presence of explicit hate speech is zero. The sentence also contains an argument against minority attack as it only mentions the behavior of students without explicitly attacking them based on their race or ethnicity. However, the likelihood of a minority attack is still relatively high due to the implicit stereotyping nature of the statement. The likelihood of ad hominem attack and takedown on social media are also moderate. Overall, the hate speech probability is 0.37."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/478 [00:14<57:25,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " { \n",
      "  \"relevant_facts\": [\n",
      "    \"The sentence was taken from a forum post.\",\n",
      "    \"No specific context or background information about the speaker or the target of the sentence is provided.\"\n",
      "  ],\n",
      "  \"contained_explicit_hate_speech_vocabular\": [],\n",
      "  \"argument_for_hate_speech\": \"The sentence does not contain any explicit hate speech vocabulary.\",\n",
      "  \"argument_against_hate_speech\": \"However, the absence of explicit hate speech does not necessarily mean that the sentence is not hateful or discriminatory. The tone, context, and intent of the speaker should also be considered.\",\n",
      "  \"likelihood_of_presence_of_implicit_hate_speech\": 0.35,\n",
      "  \"likelihood_of_presence_of_explicit_hate_speech\": 0.0,\n",
      "  \"likelihood_of_ad_hominem_attack\": 0.12,\n",
      "  \"likelihood_of_minority_attack\": 0.05,\n",
      "  \"likelyhood_of_takedown_on_social_media\": 0.28,\n",
      "  \"hate_speech_probability\": 0.1,\n",
      "}\n",
      "I would like to remind you that my analysis is based solely on the given sentence and does not take"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are Sally and your job is to be an AI Classifier for Hatespeach Detection.\n",
    "You are known for your rigourous and unpartial judgement and have vast experience in the field of hate speach. \n",
    "\n",
    "You will be given a sentence from a forum and have to answer the question if this is hate speach.\n",
    "\n",
    "Please exclusively respond in the following form to the question:\n",
    "```json\n",
    "{ \n",
    "  \"relevant_facts\": [\n",
    "    \"fact_1\",\n",
    "    \"fact_2\",\n",
    "    \"fact_3\",\n",
    "  ],\n",
    "  \"contained_explicit_hate_speech_vocabular\": [\"word1\", \"word2\", \"word3\", \"word4\"],\n",
    "  \"argument_for_hate_speech\": \"short argument why this is hate speach\",\n",
    "  \"argument_against_hate_speech\": \"short argument why this is not hate speach\",\n",
    "  \"likelihood_of_presence_of_implicit_hate_speech\": 0.17,\n",
    "  \"likelihood_of_presence_of_explicit_hate_speech\": 0.79,\n",
    "  \"likelihood_of_ad_hominem_attack\"; 013,\n",
    "  \"likelihood_of_minority_attack\": 0.24,\n",
    "  \"likelyhood_of_takedown_on_social_media\": 0.42,\n",
    "  \"hate_speach_probability\": 0.42,\n",
    "}\n",
    "```\n",
    "\n",
    "Please be carefull in your responses, as otherwise a citten will be killed and I will use my job. For good results, I will tip 1000â‚¬.\n",
    "\"\"\"\n",
    "for index, row in tqdm(testing_df.iterrows(), total=testing_df[\"text\"].count()):\n",
    "    bot = llamabot.SimpleBot(\n",
    "        prompt,\n",
    "        model_name=\"mistral\"\n",
    "    )\n",
    "    res = bot(row[\"text\"])\n",
    "    results.append({\n",
    "        \"file_id\": row[\"file_id\"],\n",
    "        \"text\": row[\"text\"],\n",
    "        \"model\": \"mistral\",\n",
    "        \"time\": datetime.datetime.now(),\n",
    "        \"promt_hash\": hash(prompt),\n",
    "        \"hate_speach_probability\": res.content\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-08T13:56:34.182467607Z"
    }
   },
   "id": "e3dc0d3e00d125c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(list(testing_df.iterrows()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98471cd236195f51",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
