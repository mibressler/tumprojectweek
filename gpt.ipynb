{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:29.325377971Z",
     "start_time": "2024-01-11T04:01:20.538849213Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./venv/lib/python3.11/site-packages (23.3.2)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.1.4)\r\n",
      "Requirement already satisfied: tables in ./venv/lib/python3.11/site-packages (3.9.2)\r\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in ./venv/lib/python3.11/site-packages (from pandas) (1.26.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.11/site-packages (from pandas) (2023.4)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in ./venv/lib/python3.11/site-packages (from tables) (2.8.8)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from tables) (23.2)\r\n",
      "Requirement already satisfied: py-cpuinfo in ./venv/lib/python3.11/site-packages (from tables) (9.0.0)\r\n",
      "Requirement already satisfied: blosc2>=2.3.0 in ./venv/lib/python3.11/site-packages (from tables) (2.4.0)\r\n",
      "Requirement already satisfied: ndindex>=1.4 in ./venv/lib/python3.11/site-packages (from blosc2>=2.3.0->tables) (1.7)\r\n",
      "Requirement already satisfied: msgpack in ./venv/lib/python3.11/site-packages (from blosc2>=2.3.0->tables) (1.0.7)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./venv/lib/python3.11/site-packages (4.36.2)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.11/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.11/site-packages (0.16.2)\r\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.11/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: peft in ./venv/lib/python3.11/site-packages (0.7.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv/lib/python3.11/site-packages (from transformers) (0.20.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.11/site-packages (from transformers) (1.26.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.11/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv/lib/python3.11/site-packages (from transformers) (0.15.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.11/site-packages (from transformers) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.11/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.11/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from torch) (2023.12.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.11/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.11/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.11/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.11/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.11/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.11/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.11/site-packages (from torch) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.11/site-packages (from torch) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.11/site-packages (from torchvision) (10.2.0)\r\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from peft) (5.9.7)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./venv/lib/python3.11/site-packages (from peft) (0.26.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available()=True\ttorch.cuda.device_count()=1\ttorch.version=<module 'torch.version' from '/home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages/torch/version.py'>\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip \n",
    "import datetime\n",
    "!pip install pandas tables\n",
    "import pandas as pd\n",
    "!pip install transformers torch torchvision torchaudio peft\n",
    "!pip -qqq install bitsandbytes accelerate\n",
    "import torch\n",
    "\n",
    "print(f\"{torch.cuda.is_available()=}\\t{torch.cuda.device_count()=}\\t{torch.version=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f4e280f03a3113c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:29.325612691Z",
     "start_time": "2024-01-11T04:01:29.314007703Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('processed_data.pkl')\n",
    "training_df = df[df[\"train\"]]\n",
    "testing_df = df[df[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3dc0d3e00d125c3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:29.325750282Z",
     "start_time": "2024-01-11T04:01:29.314128043Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROMT_DIR_PATH = Path(\"mistral-prediction\") / \"prompt-variations\"\n",
    "\n",
    "PROMT_PATHS = sorted(PROMT_DIR_PATH.glob(\"v*.txt\"), key=lambda f: int(f.name.strip(\"v.txt\")))\n",
    "SYSTEM_PROMPT = [f.read_text(encoding=\"utf-8\") for f in PROMT_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cf84439",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T04:01:34.720617951Z",
     "start_time": "2024-01-11T04:01:29.314201183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08fd5fdb0f2440e48a77359e3c966163"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_path = \"mibressler/tumproject\"\n",
    "token = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, token=token)\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=nf4_config,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype='auto',\n",
    "    token=token,\n",
    ").eval()\n",
    "\n",
    "def generate_response(system_promt: str, text: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": system_promt + \"\\nText to evaluate: \\\"\" + text + \"\\\"\"},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True,\n",
    "                                              return_tensors='pt')\n",
    "    output_ids = model.generate(input_ids=input_ids.to('cuda'), max_new_tokens=1024)\n",
    "    return tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def run_model(prompt_id: int, model: str):\n",
    "    results = []\n",
    "    start_time = datetime.datetime.now()\n",
    "    for i, (row_index, row) in enumerate(testing_df.iterrows()):\n",
    "        total = testing_df[\"text\"].count()\n",
    "        counter = i + 1\n",
    "        elapsed = datetime.datetime.now() - start_time\n",
    "        percentage = counter / total\n",
    "        s_per_gen = elapsed / counter\n",
    "        print(f'[{elapsed}<{s_per_gen * (total - counter)}, {s_per_gen}s/generations] '\n",
    "              f'{model} - promt {prompt_id}: {counter}/{total} | {percentage * 100:.2f}%')\n",
    "        answer = generate_response(SYSTEM_PROMPT[prompt_id], row[\"text\"])\n",
    "        results.append({\n",
    "            'prompt_id': prompt_id,\n",
    "            'model': model,\n",
    "            'sample_size': total,\n",
    "            \"text\": row[\"text\"],\n",
    "            \"answer\": answer,\n",
    "            \"labeled_hateful\": row[\"hate\"]\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:00:00.000374<0:00:00.178398, 0:00:00.000374s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 1/478 | 0.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/dev/uni/tumprojectweek/venv/lib/python3.11/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:00:15.565736<1:01:44.645168, 0:00:07.782868s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 2/478 | 0.42%\n",
      "[0:00:29.952371<1:19:02.458900, 0:00:09.984124s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 3/478 | 0.63%\n",
      "[0:00:40.731126<1:20:26.638668, 0:00:10.182782s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 4/478 | 0.84%\n",
      "[0:00:51.645460<1:21:25.660516, 0:00:10.329092s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 5/478 | 1.05%\n",
      "[0:01:03.174882<1:22:49.757384, 0:00:10.529147s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 6/478 | 1.26%\n",
      "[0:01:15.841276<1:25:03.034428, 0:00:10.834468s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 7/478 | 1.46%\n",
      "[0:01:28.800261<1:26:57.015510, 0:00:11.100033s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 8/478 | 1.67%\n",
      "[0:01:40.251519<1:27:04.218202, 0:00:11.139058s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 9/478 | 1.88%\n",
      "[0:01:53.610209<1:28:36.957828, 0:00:11.361021s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 10/478 | 2.09%\n",
      "[0:02:06.496631<1:29:30.357098, 0:00:11.499694s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 11/478 | 2.30%\n",
      "[0:02:18.752197<1:29:48.210278, 0:00:11.562683s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 12/478 | 2.51%\n",
      "[0:02:33.924978<1:31:45.778095, 0:00:11.840383s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 13/478 | 2.72%\n",
      "[0:02:45.798927<1:31:35.049920, 0:00:11.842780s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 14/478 | 2.93%\n",
      "[0:02:58.544104<1:31:51.061220, 0:00:11.902940s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 15/478 | 3.14%\n",
      "[0:03:15.793890<1:34:13.548516, 0:00:12.237118s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 16/478 | 3.35%\n",
      "[0:03:29.832631<1:34:50.167256, 0:00:12.343096s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 17/478 | 3.56%\n",
      "[0:03:44.165489<1:35:28.673480, 0:00:12.453638s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 18/478 | 3.77%\n",
      "[0:03:57.695288<1:35:42.217602, 0:00:12.510278s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 19/478 | 3.97%\n",
      "[0:04:13.392322<1:36:42.684128, 0:00:12.669616s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 20/478 | 4.18%\n",
      "[0:04:26.100931<1:36:30.863161, 0:00:12.671473s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 21/478 | 4.39%\n",
      "[0:04:41.735014<1:37:19.598472, 0:00:12.806137s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 22/478 | 4.60%\n",
      "[0:04:55.646917<1:37:28.667370, 0:00:12.854214s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 23/478 | 4.81%\n",
      "[0:05:07.669116<1:37:00.073884, 0:00:12.819546s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 24/478 | 5.02%\n",
      "[0:05:21.616965<1:37:07.699587, 0:00:12.864679s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 25/478 | 5.23%\n",
      "[0:05:32.252467<1:36:16.081332, 0:00:12.778941s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 26/478 | 5.44%\n",
      "[0:05:45.351281<1:36:08.645388, 0:00:12.790788s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 27/478 | 5.65%\n",
      "[0:05:57.426736<1:35:44.358450, 0:00:12.765241s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 28/478 | 5.86%\n",
      "[0:06:09.256100<1:35:17.103081, 0:00:12.732969s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 29/478 | 6.07%\n",
      "[0:06:20.221399<1:34:37.973056, 0:00:12.674047s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 30/478 | 6.28%\n",
      "[0:06:33.046607<1:34:27.478581, 0:00:12.678923s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 31/478 | 6.49%\n",
      "[0:06:46.030300<1:34:19.047362, 0:00:12.688447s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 32/478 | 6.69%\n",
      "[0:06:59.334838<1:34:14.666620, 0:00:12.707116s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 33/478 | 6.90%\n",
      "[0:07:11.795419<1:33:58.740060, 0:00:12.699865s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 34/478 | 7.11%\n",
      "[0:07:23.324474<1:33:31.221402, 0:00:12.666414s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 35/478 | 7.32%\n",
      "[0:07:39.736028<1:34:04.536690, 0:00:12.770445s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 36/478 | 7.53%\n",
      "[0:07:54.017281<1:34:09.773598, 0:00:12.811278s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 37/478 | 7.74%\n",
      "[0:08:09.073555<1:34:22.957080, 0:00:12.870357s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 38/478 | 7.95%\n",
      "[0:08:21.649758<1:34:06.775346, 0:00:12.862814s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 39/478 | 8.16%\n",
      "[0:08:34.754888<1:33:56.565936, 0:00:12.868872s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 40/478 | 8.37%\n",
      "[0:08:47.211141<1:33:39.299096, 0:00:12.858808s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 41/478 | 8.58%\n",
      "[0:08:57.338050<1:32:58.080668, 0:00:12.793763s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 42/478 | 8.79%\n",
      "[0:09:08.267162<1:32:26.423565, 0:00:12.750399s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 43/478 | 9.00%\n",
      "[0:09:21.813399<1:32:21.522924, 0:00:12.768486s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 44/478 | 9.21%\n",
      "[0:09:35.025903<1:32:13.026849, 0:00:12.778353s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 45/478 | 9.41%\n",
      "[0:09:45.346641<1:31:37.168464, 0:00:12.724927s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 46/478 | 9.62%\n",
      "[0:09:54.964972<1:30:55.955299, 0:00:12.658829s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 47/478 | 9.83%\n",
      "[0:10:05.896672<1:30:27.824210, 0:00:12.622847s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 48/478 | 10.04%\n",
      "[0:10:17.341455<1:30:04.887345, 0:00:12.598805s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 49/478 | 10.25%\n",
      "[0:10:30.549760<1:29:57.505860, 0:00:12.610995s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 50/478 | 10.46%\n",
      "[0:10:43.659599<1:29:49.071352, 0:00:12.620776s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 51/478 | 10.67%\n",
      "[0:10:53.840639<1:29:16.463508, 0:00:12.573858s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 52/478 | 10.88%\n",
      "[0:11:06.263236<1:29:02.676700, 0:00:12.571004s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 53/478 | 11.09%\n",
      "[0:11:17.167934<1:28:37.022328, 0:00:12.540147s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 54/478 | 11.30%\n",
      "[0:11:32.912577<1:28:49.127430, 0:00:12.598410s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 55/478 | 11.51%\n",
      "[0:11:45.014379<1:28:32.786724, 0:00:12.589542s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 56/478 | 11.72%\n",
      "[0:12:00.960050<1:28:44.985662, 0:00:12.648422s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 57/478 | 11.92%\n",
      "[0:12:14.837901<1:28:41.239980, 0:00:12.669619s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 58/478 | 12.13%\n",
      "[0:12:27.735428<1:28:30.188958, 0:00:12.673482s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 59/478 | 12.34%\n",
      "[0:12:42.591076<1:28:32.717718, 0:00:12.709851s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 60/478 | 12.55%\n",
      "[0:12:55.763764<1:28:23.172063, 0:00:12.717439s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 61/478 | 12.76%\n",
      "[0:13:09.108181<1:28:14.661216, 0:00:12.727551s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 62/478 | 12.97%\n",
      "[0:13:23.009850<1:28:09.668020, 0:00:12.746188s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 63/478 | 13.18%\n",
      "[0:13:36.372649<1:28:00.910722, 0:00:12.755823s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 64/478 | 13.39%\n",
      "[0:13:50.073165<1:27:54.157028, 0:00:12.770356s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 65/478 | 13.60%\n",
      "[0:14:03.927700<1:27:48.154596, 0:00:12.786783s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 66/478 | 13.81%\n",
      "[0:14:19.456020<1:27:52.185522, 0:00:12.827702s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 67/478 | 14.02%\n",
      "[0:14:36.387775<1:28:04.102960, 0:00:12.888056s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 68/478 | 14.23%\n",
      "[0:14:49.842567<1:27:54.574021, 0:00:12.896269s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 69/478 | 14.44%\n",
      "[0:15:04.142621<1:27:49.859784, 0:00:12.916323s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 70/478 | 14.64%\n",
      "[0:15:18.145026<1:27:43.169340, 0:00:12.931620s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 71/478 | 14.85%\n",
      "[0:15:31.100936<1:27:30.374542, 0:00:12.931957s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 72/478 | 15.06%\n",
      "[0:15:45.541383<1:27:25.811910, 0:00:12.952622s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 73/478 | 15.27%\n",
      "[0:15:58.002155<1:27:10.173900, 0:00:12.945975s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 74/478 | 15.48%\n",
      "[0:16:09.258599<1:26:48.149544, 0:00:12.923448s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 75/478 | 15.69%\n",
      "[0:16:20.991357<1:26:28.927962, 0:00:12.907781s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 76/478 | 15.90%\n",
      "[0:16:38.688137<1:26:40.960376, 0:00:12.969976s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 77/478 | 16.11%\n",
      "[0:16:49.961501<1:26:19.289600, 0:00:12.948224s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 78/478 | 16.32%\n",
      "[0:17:07.054944<1:26:27.277305, 0:00:13.000695s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 79/478 | 16.53%\n",
      "[0:17:19.915518<1:26:13.579712, 0:00:12.998944s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 80/478 | 16.74%\n",
      "[0:17:31.978597<1:25:55.993830, 0:00:12.987390s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 81/478 | 16.95%\n",
      "[0:17:46.565776<1:25:50.732400, 0:00:13.006900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 82/478 | 17.15%\n",
      "[0:18:00.987440<1:25:44.458275, 0:00:13.023945s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 83/478 | 17.36%\n",
      "[0:18:13.516117<1:25:29.111306, 0:00:13.018049s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 84/478 | 17.57%\n",
      "[0:18:24.216447<1:25:05.377326, 0:00:12.990782s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 85/478 | 17.78%\n",
      "[0:18:35.912042<1:24:46.482632, 0:00:12.975721s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 86/478 | 17.99%\n",
      "[0:18:46.144024<1:24:21.175944, 0:00:12.944184s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 87/478 | 18.20%\n",
      "[0:19:00.329812<1:24:13.734270, 0:00:12.958293s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 88/478 | 18.41%\n",
      "[0:19:09.933798<1:23:46.114956, 0:00:12.920604s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 89/478 | 18.62%\n",
      "[0:19:19.478544<1:23:18.640860, 0:00:12.883095s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 90/478 | 18.83%\n",
      "[0:19:31.472188<1:23:01.975227, 0:00:12.873321s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 91/478 | 19.04%\n",
      "[0:19:41.624716<1:22:37.686342, 0:00:12.843747s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 92/478 | 19.25%\n",
      "[0:19:53.482701<1:22:20.761595, 0:00:12.833147s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 93/478 | 19.46%\n",
      "[0:20:06.229543<1:22:07.575936, 0:00:12.832229s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 94/478 | 19.67%\n",
      "[0:20:18.479629<1:21:52.396683, 0:00:12.826101s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 95/478 | 19.87%\n",
      "[0:20:31.073403<1:21:38.646142, 0:00:12.823681s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 96/478 | 20.08%\n",
      "[0:20:42.269437<1:21:19.429281, 0:00:12.806901s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 97/478 | 20.29%\n",
      "[0:20:55.474336<1:21:08.165940, 0:00:12.810963s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 98/478 | 20.50%\n",
      "[0:21:09.593787<1:21:00.364220, 0:00:12.824180s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 99/478 | 20.71%\n",
      "[0:21:21.562457<1:20:44.306250, 0:00:12.815625s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 100/478 | 20.92%\n",
      "[0:21:33.741522<1:20:29.114394, 0:00:12.809322s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 101/478 | 21.13%\n",
      "[0:21:44.304074<1:20:08.022920, 0:00:12.787295s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 102/478 | 21.34%\n",
      "[0:21:57.015950<1:19:54.961125, 0:00:12.786563s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 103/478 | 21.55%\n",
      "[0:22:09.004040<1:19:39.302990, 0:00:12.778885s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 104/478 | 21.76%\n",
      "[0:22:22.054972<1:19:27.490548, 0:00:12.781476s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 105/478 | 21.97%\n",
      "[0:22:37.746040<1:19:24.920100, 0:00:12.808925s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 106/478 | 22.18%\n",
      "[0:22:49.616073<1:19:08.855650, 0:00:12.800150s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 107/478 | 22.38%\n",
      "[0:23:01.946047<1:18:54.444890, 0:00:12.795797s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 108/478 | 22.59%\n",
      "[0:23:13.473016<1:18:37.353564, 0:00:12.784156s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 109/478 | 22.80%\n",
      "[0:23:26.839268<1:18:26.516864, 0:00:12.789448s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 110/478 | 23.01%\n",
      "[0:23:37.902123<1:18:08.018731, 0:00:12.773893s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 111/478 | 23.22%\n",
      "[0:23:52.833052<1:18:02.293632, 0:00:12.793152s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 112/478 | 23.43%\n",
      "[0:24:04.928907<1:17:47.248065, 0:00:12.786981s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 113/478 | 23.64%\n",
      "[0:24:18.309212<1:17:36.355704, 0:00:12.792186s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 114/478 | 23.85%\n",
      "[0:24:32.524592<1:17:28.056006, 0:00:12.804562s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 115/478 | 24.06%\n",
      "[0:24:44.954589<1:17:14.082546, 0:00:12.801333s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 116/478 | 24.27%\n",
      "[0:24:58.278854<1:17:02.894522, 0:00:12.805802s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 117/478 | 24.48%\n",
      "[0:25:11.301045<1:16:50.748960, 0:00:12.807636s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 118/478 | 24.69%\n",
      "[0:25:28.165191<1:16:50.178916, 0:00:12.841724s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 119/478 | 24.90%\n",
      "[0:25:41.178599<1:16:37.849490, 0:00:12.843155s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 120/478 | 25.10%\n",
      "[0:25:53.355224<1:16:23.039622, 0:00:12.837646s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 121/478 | 25.31%\n",
      "[0:26:04.969343<1:16:06.632008, 0:00:12.827618s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 122/478 | 25.52%\n",
      "[0:26:19.333482<1:15:58.239050, 0:00:12.840110s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 123/478 | 25.73%\n",
      "[0:26:30.235194<1:15:39.864858, 0:00:12.824477s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 124/478 | 25.94%\n",
      "[0:26:43.776160<1:15:29.063777, 0:00:12.830209s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 125/478 | 26.15%\n",
      "[0:26:56.076724<1:15:14.754112, 0:00:12.826006s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 126/478 | 26.36%\n",
      "[0:27:10.655738<1:15:06.772959, 0:00:12.839809s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 127/478 | 26.57%\n",
      "[0:27:23.313753<1:14:53.436150, 0:00:12.838389s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 128/478 | 26.78%\n",
      "[0:27:37.066762<1:14:43.072171, 0:00:12.845479s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 129/478 | 26.99%\n",
      "[0:27:51.548945<1:14:34.608012, 0:00:12.858069s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 130/478 | 27.20%\n",
      "[0:28:04.259565<1:14:21.359221, 0:00:12.856943s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 131/478 | 27.41%\n",
      "[0:28:16.614335<1:14:07.186094, 0:00:12.853139s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 132/478 | 27.62%\n",
      "[0:28:31.922716<1:14:00.701655, 0:00:12.871599s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 133/478 | 27.82%\n",
      "[0:28:42.795309<1:13:42.698264, 0:00:12.856681s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 134/478 | 28.03%\n",
      "[0:28:54.484890<1:13:26.876348, 0:00:12.848036s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 135/478 | 28.24%\n",
      "[0:29:10.152850<1:13:21.119682, 0:00:12.868771s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 136/478 | 28.45%\n",
      "[0:29:25.544063<1:13:14.529403, 0:00:12.887183s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 137/478 | 28.66%\n",
      "[0:29:36.548011<1:12:57.002240, 0:00:12.873536s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 138/478 | 28.87%\n",
      "[0:29:47.598967<1:12:39.683736, 0:00:12.860424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 139/478 | 29.08%\n",
      "[0:30:00.758545<1:12:27.545618, 0:00:12.862561s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 140/478 | 29.29%\n",
      "[0:30:13.648414<1:12:14.748435, 0:00:12.862755s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 141/478 | 29.50%\n",
      "[0:30:27.279141<1:12:03.702768, 0:00:12.868163s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 142/478 | 29.71%\n",
      "[0:30:39.207303<1:11:48.632650, 0:00:12.861590s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 143/478 | 29.92%\n",
      "[0:30:48.759214<1:11:28.094404, 0:00:12.838606s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 144/478 | 30.13%\n",
      "[0:30:59.197522<1:11:09.743316, 0:00:12.822052s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 145/478 | 30.33%\n",
      "[0:31:10.750499<1:10:54.035520, 0:00:12.813360s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 146/478 | 30.54%\n",
      "[0:31:21.580701<1:10:36.756639, 0:00:12.799869s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 147/478 | 30.75%\n",
      "[0:31:36.433504<1:10:28.534200, 0:00:12.813740s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 148/478 | 30.96%\n",
      "[0:31:49.383986<1:10:16.022482, 0:00:12.814658s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 149/478 | 31.17%\n",
      "[0:32:03.970063<1:10:07.081176, 0:00:12.826467s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 150/478 | 31.38%\n",
      "[0:32:19.796840<1:10:00.752199, 0:00:12.846337s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 151/478 | 31.59%\n",
      "[0:32:33.311674<1:09:49.339610, 0:00:12.850735s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 152/478 | 31.80%\n",
      "[0:32:46.791371<1:09:37.824950, 0:00:12.854846s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 153/478 | 32.01%\n",
      "[0:32:59.245215<1:09:24.126408, 0:00:12.852242s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 154/478 | 32.22%\n",
      "[0:33:11.105431<1:09:09.206643, 0:00:12.845841s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 155/478 | 32.43%\n",
      "[0:33:23.199858<1:08:54.810050, 0:00:12.841025s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 156/478 | 32.64%\n",
      "[0:33:36.342951<1:08:42.586629, 0:00:12.842949s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 157/478 | 32.85%\n",
      "[0:33:50.358827<1:08:32.119040, 0:00:12.850372s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 158/478 | 33.05%\n",
      "[0:34:02.950982<1:08:18.750612, 0:00:12.848748s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 159/478 | 33.26%\n",
      "[0:34:16.657359<1:08:07.606344, 0:00:12.854108s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 160/478 | 33.47%\n",
      "[0:34:31.420072<1:07:58.510271, 0:00:12.865963s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 161/478 | 33.68%\n",
      "[0:34:42.016442<1:07:41.217148, 0:00:12.851953s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 162/478 | 33.89%\n",
      "[0:34:56.292377<1:07:31.117035, 0:00:12.860689s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 163/478 | 34.10%\n",
      "[0:35:11.132150<1:07:22.045698, 0:00:12.872757s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 164/478 | 34.31%\n",
      "[0:35:27.366023<1:07:15.548751, 0:00:12.893127s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 165/478 | 34.52%\n",
      "[0:35:38.266489<1:06:58.910376, 0:00:12.881123s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 166/478 | 34.73%\n",
      "[0:35:52.123067<1:06:47.845804, 0:00:12.886964s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 167/478 | 34.94%\n",
      "[0:36:04.001473<1:06:33.097910, 0:00:12.880961s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 168/478 | 35.15%\n",
      "[0:36:16.655751<1:06:19.802580, 0:00:12.879620s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 169/478 | 35.36%\n",
      "[0:36:27.455483<1:06:03.154580, 0:00:12.867385s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 170/478 | 35.56%\n",
      "[0:36:39.737913<1:05:49.236948, 0:00:12.863964s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 171/478 | 35.77%\n",
      "[0:36:57.112789<1:05:44.398446, 0:00:12.890191s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 172/478 | 35.98%\n",
      "[0:37:12.200994<1:05:35.383280, 0:00:12.902896s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 173/478 | 36.19%\n",
      "[0:37:23.753619<1:05:20.121344, 0:00:12.895136s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 174/478 | 36.40%\n",
      "[0:37:39.596338<1:05:12.329637, 0:00:12.911979s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 175/478 | 36.61%\n",
      "[0:37:54.741479<1:05:03.249434, 0:00:12.924667s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 176/478 | 36.82%\n",
      "[0:38:06.577848<1:04:48.474219, 0:00:12.918519s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 177/478 | 37.03%\n",
      "[0:38:21.166027<1:04:38.369700, 0:00:12.927899s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 178/478 | 37.24%\n",
      "[0:38:36.992685<1:04:30.283807, 0:00:12.944093s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 179/478 | 37.45%\n",
      "[0:38:50.235164<1:04:17.833798, 0:00:12.945751s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 180/478 | 37.66%\n",
      "[0:39:01.459327<1:04:02.062983, 0:00:12.936239s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 181/478 | 37.87%\n",
      "[0:39:15.582000<1:03:51.056368, 0:00:12.942758s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 182/478 | 38.08%\n",
      "[0:39:29.153941<1:03:39.127820, 0:00:12.946196s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 183/478 | 38.28%\n",
      "[0:39:41.633179<1:03:25.435746, 0:00:12.943659s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 184/478 | 38.49%\n",
      "[0:39:53.293886<1:03:10.460132, 0:00:12.936724s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 185/478 | 38.70%\n",
      "[0:40:05.570261<1:02:56.486516, 0:00:12.933173s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 186/478 | 38.91%\n",
      "[0:40:17.406445<1:02:41.846337, 0:00:12.927307s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 187/478 | 39.12%\n",
      "[0:40:30.482476<1:02:29.148420, 0:00:12.928098s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 188/478 | 39.33%\n",
      "[0:40:45.376415<1:02:19.226500, 0:00:12.938500s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 189/478 | 39.54%\n",
      "[0:40:58.701968<1:02:06.874656, 0:00:12.940537s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 190/478 | 39.75%\n",
      "[0:41:10.247863<1:01:51.838445, 0:00:12.933235s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 191/478 | 39.96%\n",
      "[0:41:22.868363<1:01:38.439316, 0:00:12.931606s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 192/478 | 40.17%\n",
      "[0:41:35.770225<1:01:25.463820, 0:00:12.931452s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 193/478 | 40.38%\n",
      "[0:41:48.529668<1:01:12.280460, 0:00:12.930565s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 194/478 | 40.59%\n",
      "[0:42:01.186645<1:00:58.952846, 0:00:12.929162s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 195/478 | 40.79%\n",
      "[0:42:16.182329<1:00:48.997092, 0:00:12.939706s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 196/478 | 41.00%\n",
      "[0:42:31.471046<1:00:39.408030, 0:00:12.951630s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 197/478 | 41.21%\n",
      "[0:42:45.255948<1:00:27.634640, 0:00:12.955838s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 198/478 | 41.42%\n",
      "[0:42:56.196467<1:00:11.853369, 0:00:12.945711s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 199/478 | 41.63%\n",
      "[0:43:07.648103<0:59:56.830998, 0:00:12.938241s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 200/478 | 41.84%\n",
      "[0:43:21.163585<0:59:44.688024, 0:00:12.941112s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 201/478 | 42.05%\n",
      "[0:43:32.815283<0:59:29.985204, 0:00:12.934729s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 202/478 | 42.26%\n",
      "[0:43:46.395913<0:59:17.925525, 0:00:12.937911s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 203/478 | 42.47%\n",
      "[0:43:57.635989<0:59:02.707112, 0:00:12.929588s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 204/478 | 42.68%\n",
      "[0:44:10.759900<0:58:50.036328, 0:00:12.930536s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 205/478 | 42.89%\n",
      "[0:44:21.732493<0:58:34.520704, 0:00:12.921032s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 206/478 | 43.10%\n",
      "[0:44:32.793712<0:58:19.164737, 0:00:12.912047s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 207/478 | 43.31%\n",
      "[0:44:46.185702<0:58:06.875580, 0:00:12.914354s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 208/478 | 43.51%\n",
      "[0:44:59.555775<0:57:54.547915, 0:00:12.916535s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 209/478 | 43.72%\n",
      "[0:45:10.180042<0:57:38.705892, 0:00:12.905619s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 210/478 | 43.93%\n",
      "[0:45:23.194161<0:57:25.937511, 0:00:12.906133s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 211/478 | 44.14%\n",
      "[0:45:35.683951<0:57:12.509220, 0:00:12.904170s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 212/478 | 44.35%\n",
      "[0:45:47.861116<0:56:58.700340, 0:00:12.900756s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 213/478 | 44.56%\n",
      "[0:46:00.428126<0:56:45.388008, 0:00:12.899197s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 214/478 | 44.77%\n",
      "[0:46:12.655129<0:56:31.666410, 0:00:12.896070s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 215/478 | 44.98%\n",
      "[0:46:23.046496<0:56:15.732450, 0:00:12.884475s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 216/478 | 45.19%\n",
      "[0:46:37.193481<0:56:04.366473, 0:00:12.890293s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 217/478 | 45.40%\n",
      "[0:46:48.425571<0:55:49.498360, 0:00:12.882686s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 218/478 | 45.61%\n",
      "[0:46:59.545311<0:55:34.530724, 0:00:12.874636s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 219/478 | 45.82%\n",
      "[0:47:11.862563<0:55:21.002574, 0:00:12.872103s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 220/478 | 46.03%\n",
      "[0:47:25.796219<0:55:09.364842, 0:00:12.876906s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 221/478 | 46.23%\n",
      "[0:47:38.864079<0:54:56.708096, 0:00:12.877766s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 222/478 | 46.44%\n",
      "[0:47:52.625940<0:54:44.841405, 0:00:12.881731s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 223/478 | 46.65%\n",
      "[0:48:03.441415<0:54:29.616524, 0:00:12.872506s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 224/478 | 46.86%\n",
      "[0:48:15.479468<0:54:15.805894, 0:00:12.868798s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 225/478 | 47.07%\n",
      "[0:48:27.825438<0:54:02.353968, 0:00:12.866484s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 226/478 | 47.28%\n",
      "[0:48:43.879459<0:53:53.012026, 0:00:12.880526s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 227/478 | 47.49%\n",
      "[0:48:56.214094<0:53:39.533000, 0:00:12.878132s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 228/478 | 47.70%\n",
      "[0:49:08.107694<0:53:25.584417, 0:00:12.873833s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 229/478 | 47.91%\n",
      "[0:49:21.834469<0:53:13.630168, 0:00:12.877541s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 230/478 | 48.12%\n",
      "[0:49:35.670041<0:53:01.776936, 0:00:12.881688s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 231/478 | 48.33%\n",
      "[0:49:46.513481<0:52:46.734138, 0:00:12.872903s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 232/478 | 48.54%\n",
      "[0:49:57.861708<0:52:32.257955, 0:00:12.866359s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 233/478 | 48.74%\n",
      "[0:50:12.497502<0:52:21.236724, 0:00:12.873921s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 234/478 | 48.95%\n",
      "[0:50:24.167918<0:52:07.118400, 0:00:12.868800s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 235/478 | 49.16%\n",
      "[0:50:36.388297<0:51:53.584584, 0:00:12.866052s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 236/478 | 49.37%\n",
      "[0:50:50.384722<0:51:41.868102, 0:00:12.870822s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 237/478 | 49.58%\n",
      "[0:50:59.959761<0:51:25.673760, 0:00:12.856974s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 238/478 | 49.79%\n",
      "[0:51:10.818758<0:51:10.818746, 0:00:12.848614s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 239/478 | 50.00%\n",
      "[0:51:23.328214<0:50:57.633838, 0:00:12.847201s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 240/478 | 50.21%\n",
      "[0:51:33.317335<0:50:41.976054, 0:00:12.835342s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 241/478 | 50.42%\n",
      "[0:51:47.149824<0:50:30.113032, 0:00:12.839462s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 242/478 | 50.63%\n",
      "[0:51:58.477692<0:50:15.811870, 0:00:12.833242s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 243/478 | 50.84%\n",
      "[0:52:11.942387<0:50:03.583986, 0:00:12.835829s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 244/478 | 51.05%\n",
      "[0:52:24.764891<0:49:50.735575, 0:00:12.835775s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 245/478 | 51.26%\n",
      "[0:52:39.278363<0:49:39.482040, 0:00:12.842595s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 246/478 | 51.46%\n",
      "[0:52:51.361920<0:49:25.929582, 0:00:12.839522s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 247/478 | 51.67%\n",
      "[0:53:04.177509<0:49:13.067750, 0:00:12.839425s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 248/478 | 51.88%\n",
      "[0:53:16.108011<0:48:59.392475, 0:00:12.835775s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 249/478 | 52.09%\n",
      "[0:53:30.399745<0:48:47.884572, 0:00:12.841599s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 250/478 | 52.30%\n",
      "[0:53:44.919060<0:48:36.560241, 0:00:12.848283s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 251/478 | 52.51%\n",
      "[0:53:56.033066<0:48:22.156626, 0:00:12.841401s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 252/478 | 52.72%\n",
      "[0:54:06.804308<0:48:07.474275, 0:00:12.833219s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 253/478 | 52.93%\n",
      "[0:54:16.939520<0:47:52.261728, 0:00:12.822597s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 254/478 | 53.14%\n",
      "[0:54:33.236820<0:47:42.477729, 0:00:12.836223s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 255/478 | 53.35%\n",
      "[0:54:45.193058<0:47:28.878270, 0:00:12.832785s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 256/478 | 53.56%\n",
      "[0:54:57.654475<0:47:15.726140, 0:00:12.831340s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 257/478 | 53.77%\n",
      "[0:55:09.338556<0:47:01.916680, 0:00:12.826894s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 258/478 | 53.97%\n",
      "[0:55:24.042426<0:46:50.676879, 0:00:12.834141s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 259/478 | 54.18%\n",
      "[0:55:37.238528<0:46:38.146194, 0:00:12.835533s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 260/478 | 54.39%\n",
      "[0:55:50.233683<0:46:25.443248, 0:00:12.836144s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 261/478 | 54.60%\n",
      "[0:56:03.742442<0:46:13.161792, 0:00:12.838712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 262/478 | 54.81%\n",
      "[0:56:16.451859<0:46:00.217300, 0:00:12.838220s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 263/478 | 55.02%\n",
      "[0:56:30.047434<0:45:47.993046, 0:00:12.841089s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 264/478 | 55.23%\n",
      "[0:56:44.116338<0:45:36.138786, 0:00:12.845722s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 265/478 | 55.44%\n",
      "[0:56:56.383841<0:45:22.832176, 0:00:12.843548s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 266/478 | 55.65%\n",
      "[0:57:09.470481<0:45:10.180849, 0:00:12.844459s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 267/478 | 55.86%\n",
      "[0:57:23.372990<0:44:58.165470, 0:00:12.848407s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 268/478 | 56.07%\n",
      "[0:57:38.982147<0:44:47.462030, 0:00:12.858670s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 269/478 | 56.28%\n",
      "[0:57:52.293562<0:44:34.952176, 0:00:12.860347s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 270/478 | 56.49%\n",
      "[0:58:07.116206<0:44:23.590509, 0:00:12.867587s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 271/478 | 56.69%\n",
      "[0:58:21.462356<0:44:11.842738, 0:00:12.873023s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 272/478 | 56.90%\n",
      "[0:58:34.573332<0:43:59.148475, 0:00:12.873895s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 273/478 | 57.11%\n",
      "[0:58:48.011471<0:43:46.694616, 0:00:12.875954s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 274/478 | 57.32%\n",
      "[0:59:00.570821<0:43:33.585009, 0:00:12.874803s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 275/478 | 57.53%\n",
      "[0:59:10.814950<0:43:18.784944, 0:00:12.865272s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 276/478 | 57.74%\n",
      "[0:59:22.196189<0:43:04.842714, 0:00:12.859914s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 277/478 | 57.95%\n",
      "[0:59:32.315827<0:42:50.011400, 0:00:12.850057s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 278/478 | 58.16%\n",
      "[0:59:43.435283<0:42:35.926946, 0:00:12.843854s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 279/478 | 58.37%\n",
      "[0:59:53.535018<0:42:21.142692, 0:00:12.834054s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 280/478 | 58.58%\n",
      "[1:00:06.814604<0:42:08.620883, 0:00:12.835639s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 281/478 | 58.79%\n",
      "[1:00:20.083599<0:41:56.086496, 0:00:12.837176s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 282/478 | 59.00%\n",
      "[1:00:32.737552<0:41:43.122960, 0:00:12.836528s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 283/478 | 59.21%\n",
      "[1:00:45.015193<0:41:29.904834, 0:00:12.834561s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 284/478 | 59.41%\n",
      "[1:00:57.458360<0:41:16.805091, 0:00:12.833187s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 285/478 | 59.62%\n",
      "[1:01:09.731663<0:41:03.596160, 0:00:12.831230s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 286/478 | 59.83%\n",
      "[1:01:24.574549<0:40:52.103649, 0:00:12.838239s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 287/478 | 60.04%\n",
      "[1:01:36.074894<0:40:38.382670, 0:00:12.833593s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 288/478 | 60.25%\n",
      "[1:01:45.631198<0:40:23.405817, 0:00:12.822253s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 289/478 | 60.46%\n",
      "[1:01:58.322781<0:40:10.498964, 0:00:12.821803s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 290/478 | 60.67%\n",
      "[1:02:11.792022<0:39:58.093236, 0:00:12.824028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 291/478 | 60.88%\n",
      "[1:02:25.245274<0:39:45.669852, 0:00:12.826182s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 292/478 | 61.09%\n",
      "[1:02:39.182143<0:39:33.545005, 0:00:12.829973s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 293/478 | 61.30%\n",
      "[1:02:52.824660<0:39:21.223608, 0:00:12.832737s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 294/478 | 61.51%\n",
      "[1:03:07.624895<0:39:09.611298, 0:00:12.839406s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 295/478 | 61.72%\n",
      "[1:03:21.522118<0:38:57.422360, 0:00:12.842980s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 296/478 | 61.92%\n",
      "[1:03:33.155396<0:38:43.842167, 0:00:12.838907s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 297/478 | 62.13%\n",
      "[1:03:44.257505<0:38:29.954220, 0:00:12.833079s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 298/478 | 62.34%\n",
      "[1:03:57.834638<0:38:17.566493, 0:00:12.835567s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 299/478 | 62.55%\n",
      "[1:04:11.544997<0:38:05.249974, 0:00:12.838483s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 300/478 | 62.76%\n",
      "[1:04:24.100066<0:37:52.244934, 0:00:12.837542s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 301/478 | 62.97%\n",
      "[1:04:34.120008<0:37:37.765312, 0:00:12.828212s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 302/478 | 63.18%\n",
      "[1:04:45.274247<0:37:23.970225, 0:00:12.822687s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 303/478 | 63.39%\n",
      "[1:04:57.970891<0:37:11.075502, 0:00:12.822273s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 304/478 | 63.60%\n",
      "[1:05:10.483669<0:36:58.077634, 0:00:12.821258s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 305/478 | 63.81%\n",
      "[1:05:22.978880<0:36:45.073024, 0:00:12.820192s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 306/478 | 64.02%\n",
      "[1:05:33.028150<0:36:30.709557, 0:00:12.811167s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 307/478 | 64.23%\n",
      "[1:05:45.439500<0:36:17.677730, 0:00:12.809869s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 308/478 | 64.44%\n",
      "[1:05:58.189629<0:36:04.835075, 0:00:12.809675s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 309/478 | 64.64%\n",
      "[1:06:13.986583<0:35:53.644416, 0:00:12.819312s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 310/478 | 64.85%\n",
      "[1:06:26.721217<0:35:40.779513, 0:00:12.819039s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 311/478 | 65.06%\n",
      "[1:06:39.604192<0:35:27.994504, 0:00:12.819244s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 312/478 | 65.27%\n",
      "[1:06:52.675940<0:35:15.308415, 0:00:12.820051s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 313/478 | 65.48%\n",
      "[1:07:04.150044<0:35:01.785296, 0:00:12.815764s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 314/478 | 65.69%\n",
      "[1:07:18.287151<0:34:49.653317, 0:00:12.819959s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 315/478 | 65.90%\n",
      "[1:07:29.266480<0:34:35.889708, 0:00:12.814134s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 316/478 | 66.11%\n",
      "[1:07:40.123684<0:34:22.081721, 0:00:12.807961s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 317/478 | 66.32%\n",
      "[1:07:56.221481<0:34:10.929120, 0:00:12.818307s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 318/478 | 66.53%\n",
      "[1:08:07.188217<0:33:57.187818, 0:00:12.812502s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 319/478 | 66.74%\n",
      "[1:08:21.576518<0:33:45.153466, 0:00:12.817427s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 320/478 | 66.95%\n",
      "[1:08:33.072555<0:33:31.689670, 0:00:12.813310s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 321/478 | 67.15%\n",
      "[1:08:48.624576<0:33:20.203140, 0:00:12.821815s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 322/478 | 67.36%\n",
      "[1:09:03.852281<0:33:08.535920, 0:00:12.829264s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 323/478 | 67.57%\n",
      "[1:09:16.124651<0:32:55.441930, 0:00:12.827545s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 324/478 | 67.78%\n",
      "[1:09:28.650379<0:32:42.472401, 0:00:12.826617s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 325/478 | 67.99%\n",
      "[1:09:39.015381<0:32:28.498032, 0:00:12.819066s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 326/478 | 68.20%\n",
      "[1:09:51.414048<0:32:15.484780, 0:00:12.817780s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 327/478 | 68.41%\n",
      "[1:10:02.484801<0:32:01.868100, 0:00:12.812454s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 328/478 | 68.62%\n",
      "[1:10:16.707289<0:31:49.694111, 0:00:12.816739s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 329/478 | 68.83%\n",
      "[1:10:31.265166<0:31:37.658368, 0:00:12.822016s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 330/478 | 69.04%\n",
      "[1:10:42.190300<0:31:23.993895, 0:00:12.816285s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 331/478 | 69.25%\n",
      "[1:10:54.530653<0:31:10.968246, 0:00:12.814851s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 332/478 | 69.46%\n",
      "[1:11:06.508163<0:30:57.788865, 0:00:12.812337s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 333/478 | 69.67%\n",
      "[1:11:20.083012<0:30:45.305280, 0:00:12.814620s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 334/478 | 69.87%\n",
      "[1:11:30.645943<0:30:31.529414, 0:00:12.807898s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 335/478 | 70.08%\n",
      "[1:11:42.160101<0:30:18.174816, 0:00:12.804048s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 336/478 | 70.29%\n",
      "[1:11:54.422987<0:30:05.144322, 0:00:12.802442s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 337/478 | 70.50%\n",
      "[1:12:06.373993<0:29:51.989220, 0:00:12.799923s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 338/478 | 70.71%\n",
      "[1:12:18.857290<0:29:39.059471, 0:00:12.798989s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 339/478 | 70.92%\n",
      "[1:12:32.457459<0:29:26.585610, 0:00:12.801345s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 340/478 | 71.13%\n",
      "[1:12:46.292116<0:29:14.199512, 0:00:12.804376s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 341/478 | 71.34%\n",
      "[1:12:56.949827<0:29:00.541464, 0:00:12.798099s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 342/478 | 71.55%\n",
      "[1:13:09.827768<0:28:47.774820, 0:00:12.798332s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 343/478 | 71.76%\n",
      "[1:13:23.783068<0:28:35.427130, 0:00:12.801695s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 344/478 | 71.97%\n",
      "[1:13:37.133540<0:28:22.837038, 0:00:12.803286s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 345/478 | 72.18%\n",
      "[1:13:48.277027<0:28:09.400548, 0:00:12.798489s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 346/478 | 72.38%\n",
      "[1:14:02.708993<0:27:57.218676, 0:00:12.803196s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 347/478 | 72.59%\n",
      "[1:14:14.063363<0:27:43.874290, 0:00:12.799033s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 348/478 | 72.80%\n",
      "[1:14:24.698318<0:27:30.275328, 0:00:12.792832s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 349/478 | 73.01%\n",
      "[1:14:36.930995<0:27:17.277568, 0:00:12.791231s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 350/478 | 73.22%\n",
      "[1:14:50.708921<0:27:04.843461, 0:00:12.794043s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 351/478 | 73.43%\n",
      "[1:15:03.038407<0:26:51.883098, 0:00:12.792723s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 352/478 | 73.64%\n",
      "[1:15:15.261243<0:26:38.888500, 0:00:12.791108s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 353/478 | 73.85%\n",
      "[1:15:24.879299<0:26:24.985980, 0:00:12.782145s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 354/478 | 74.06%\n",
      "[1:15:37.224819<0:26:12.052545, 0:00:12.780915s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 355/478 | 74.27%\n",
      "[1:15:49.014935<0:25:58.932104, 0:00:12.778132s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 356/478 | 74.48%\n",
      "[1:16:02.975050<0:25:46.554603, 0:00:12.781443s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 357/478 | 74.69%\n",
      "[1:16:18.321237<0:25:34.632840, 0:00:12.788607s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 358/478 | 74.90%\n",
      "[1:16:28.371671<0:25:20.936620, 0:00:12.780980s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 359/478 | 75.10%\n",
      "[1:16:43.275343<0:25:08.851368, 0:00:12.786876s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 360/478 | 75.31%\n",
      "[1:16:54.787884<0:24:55.651482, 0:00:12.783346s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 361/478 | 75.52%\n",
      "[1:17:08.041324<0:24:43.018820, 0:00:12.784645s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 362/478 | 75.73%\n",
      "[1:17:20.062405<0:24:29.992215, 0:00:12.782541s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 363/478 | 75.94%\n",
      "[1:17:33.322699<0:24:17.359356, 0:00:12.783854s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 364/478 | 76.15%\n",
      "[1:17:43.672965<0:24:03.822018, 0:00:12.777186s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 365/478 | 76.36%\n",
      "[1:17:56.269562<0:23:50.989616, 0:00:12.776693s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 366/478 | 76.57%\n",
      "[1:18:06.273545<0:23:37.374318, 0:00:12.769138s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 367/478 | 76.78%\n",
      "[1:18:18.040599<0:23:24.305650, 0:00:12.766415s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 368/478 | 76.99%\n",
      "[1:18:28.883755<0:23:10.971127, 0:00:12.761203s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 369/478 | 77.20%\n",
      "[1:18:42.708880<0:22:58.520424, 0:00:12.764078s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 370/478 | 77.41%\n",
      "[1:18:53.576164<0:22:45.209255, 0:00:12.758965s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 371/478 | 77.62%\n",
      "[1:19:04.366157<0:22:31.889232, 0:00:12.753672s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 372/478 | 77.82%\n",
      "[1:19:17.025182<0:22:19.108995, 0:00:12.753419s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 373/478 | 78.03%\n",
      "[1:19:29.618659<0:22:06.311064, 0:00:12.752991s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 374/478 | 78.24%\n",
      "[1:19:43.126003<0:21:53.765309, 0:00:12.755003s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 375/478 | 78.45%\n",
      "[1:19:56.836689<0:21:41.269488, 0:00:12.757544s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 376/478 | 78.66%\n",
      "[1:20:08.789271<0:21:28.296309, 0:00:12.755409s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 377/478 | 78.87%\n",
      "[1:20:20.833303<0:21:15.352700, 0:00:12.753527s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 378/478 | 79.08%\n",
      "[1:20:33.111158<0:21:02.474928, 0:00:12.752272s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 379/478 | 79.29%\n",
      "[1:20:43.943869<0:20:49.227658, 0:00:12.747221s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 380/478 | 79.50%\n",
      "[1:20:56.537595<0:20:36.441346, 0:00:12.746818s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 381/478 | 79.71%\n",
      "[1:21:10.415953<0:20:23.978880, 0:00:12.749780s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 382/478 | 79.92%\n",
      "[1:21:20.779167<0:20:10.637155, 0:00:12.743549s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 383/478 | 80.13%\n",
      "[1:21:35.245325<0:19:58.315290, 0:00:12.748035s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 384/478 | 80.33%\n",
      "[1:21:45.506867<0:19:44.966568, 0:00:12.741576s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 385/478 | 80.54%\n",
      "[1:22:00.588123<0:19:32.782696, 0:00:12.747638s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 386/478 | 80.75%\n",
      "[1:22:14.687300<0:19:20.352830, 0:00:12.751130s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 387/478 | 80.96%\n",
      "[1:22:27.524943<0:19:07.621770, 0:00:12.751353s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 388/478 | 81.17%\n",
      "[1:22:38.762407<0:18:54.524029, 0:00:12.747461s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 389/478 | 81.38%\n",
      "[1:22:49.463605<0:18:41.314832, 0:00:12.742214s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 390/478 | 81.59%\n",
      "[1:23:01.833937<0:18:28.489881, 0:00:12.741263s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 391/478 | 81.80%\n",
      "[1:23:14.635039<0:18:15.761776, 0:00:12.741416s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 392/478 | 82.01%\n",
      "[1:23:28.539588<0:18:03.271960, 0:00:12.744376s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 393/478 | 82.22%\n",
      "[1:23:46.765948<0:17:51.696276, 0:00:12.758289s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 394/478 | 82.43%\n",
      "[1:24:02.115354<0:17:39.482467, 0:00:12.764849s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 395/478 | 82.64%\n",
      "[1:24:15.603008<0:17:26.867268, 0:00:12.766674s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 396/478 | 82.85%\n",
      "[1:24:26.486849<0:17:13.716492, 0:00:12.761932s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 397/478 | 83.05%\n",
      "[1:24:40.451738<0:17:01.196320, 0:00:12.764954s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 398/478 | 83.26%\n",
      "[1:24:54.716724<0:16:48.728406, 0:00:12.768714s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 399/478 | 83.47%\n",
      "[1:25:08.283577<0:16:36.115302, 0:00:12.770709s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 400/478 | 83.68%\n",
      "[1:25:20.481000<0:16:23.234483, 0:00:12.769279s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 401/478 | 83.89%\n",
      "[1:25:32.880298<0:16:10.395284, 0:00:12.768359s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 402/478 | 84.10%\n",
      "[1:25:48.346594<0:15:58.129050, 0:00:12.775054s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 403/478 | 84.31%\n",
      "[1:26:00.024872<0:15:45.153086, 0:00:12.772339s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 404/478 | 84.52%\n",
      "[1:26:10.943423<0:15:32.046626, 0:00:12.767762s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 405/478 | 84.73%\n",
      "[1:26:25.420762<0:15:19.581984, 0:00:12.771972s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 406/478 | 84.94%\n",
      "[1:26:37.881008<0:15:06.755626, 0:00:12.771206s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 407/478 | 85.15%\n",
      "[1:26:49.214784<0:14:53.737810, 0:00:12.767683s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 408/478 | 85.36%\n",
      "[1:27:02.780661<0:14:41.104815, 0:00:12.769635s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 409/478 | 85.56%\n",
      "[1:27:18.461532<0:14:28.817980, 0:00:12.776735s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 410/478 | 85.77%\n",
      "[1:27:29.033262<0:14:15.681790, 0:00:12.771370s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 411/478 | 85.98%\n",
      "[1:27:43.973122<0:14:03.257844, 0:00:12.776634s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 412/478 | 86.19%\n",
      "[1:27:57.024679<0:13:50.524435, 0:00:12.777299s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 413/478 | 86.40%\n",
      "[1:28:08.581751<0:13:37.558528, 0:00:12.774352s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 414/478 | 86.61%\n",
      "[1:28:20.856006<0:13:24.708261, 0:00:12.773147s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 415/478 | 86.82%\n",
      "[1:28:36.762256<0:13:12.402036, 0:00:12.780678s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 416/478 | 87.03%\n",
      "[1:28:49.181806<0:12:59.568532, 0:00:12.779812s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 417/478 | 87.24%\n",
      "[1:29:02.163943<0:12:46.817820, 0:00:12.780297s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 418/478 | 87.45%\n",
      "[1:29:14.497594<0:12:33.974629, 0:00:12.779231s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 419/478 | 87.66%\n",
      "[1:29:27.219599<0:12:21.187452, 0:00:12.779094s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 420/478 | 87.87%\n",
      "[1:29:37.593745<0:12:08.082774, 0:00:12.773382s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 421/478 | 88.08%\n",
      "[1:29:51.520779<0:11:55.462496, 0:00:12.776116s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 422/478 | 88.28%\n",
      "[1:30:02.533651<0:11:42.457085, 0:00:12.771947s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 423/478 | 88.49%\n",
      "[1:30:13.118692<0:11:29.406606, 0:00:12.766789s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 424/478 | 88.70%\n",
      "[1:30:26.269123<0:11:16.687676, 0:00:12.767692s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 425/478 | 88.91%\n",
      "[1:30:36.344117<0:11:03.591292, 0:00:12.761371s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 426/478 | 89.12%\n",
      "[1:30:52.731031<0:10:51.262962, 0:00:12.769862s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 427/478 | 89.33%\n",
      "[1:31:05.887129<0:10:38.538200, 0:00:12.770764s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 428/478 | 89.54%\n",
      "[1:31:16.760052<0:10:25.550660, 0:00:12.766340s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 429/478 | 89.75%\n",
      "[1:31:28.299561<0:10:12.647376, 0:00:12.763487s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 430/478 | 89.96%\n",
      "[1:31:43.653185<0:10:00.166359, 0:00:12.769497s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 431/478 | 90.17%\n",
      "[1:31:55.579238<0:09:47.307070, 0:00:12.767545s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 432/478 | 90.38%\n",
      "[1:32:05.184888<0:09:34.210890, 0:00:12.760242s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 433/478 | 90.59%\n",
      "[1:32:15.274621<0:09:21.179916, 0:00:12.754089s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 434/478 | 90.79%\n",
      "[1:32:30.349614<0:09:08.655232, 0:00:12.759424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 435/478 | 91.00%\n",
      "[1:32:44.474869<0:08:56.027394, 0:00:12.762557s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 436/478 | 91.21%\n",
      "[1:32:56.535976<0:08:43.199032, 0:00:12.760952s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 437/478 | 91.42%\n",
      "[1:33:08.748029<0:08:30.387960, 0:00:12.759699s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 438/478 | 91.63%\n",
      "[1:33:22.195323<0:08:17.689335, 0:00:12.761265s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 439/478 | 91.84%\n",
      "[1:33:36.792410<0:08:05.086606, 0:00:12.765437s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 440/478 | 92.05%\n",
      "[1:33:51.207808<0:07:52.459623, 0:00:12.769179s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 441/478 | 92.26%\n",
      "[1:34:06.180595<0:07:39.869904, 0:00:12.774164s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 442/478 | 92.47%\n",
      "[1:34:24.416055<0:07:27.527220, 0:00:12.786492s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 443/478 | 92.68%\n",
      "[1:34:33.969166<0:07:14.493140, 0:00:12.779210s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 444/478 | 92.89%\n",
      "[1:34:43.556453<0:07:01.477221, 0:00:12.772037s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 445/478 | 93.10%\n",
      "[1:34:56.371523<0:06:48.708256, 0:00:12.772133s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 446/478 | 93.31%\n",
      "[1:35:06.924610<0:06:35.782239, 0:00:12.767169s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 447/478 | 93.51%\n",
      "[1:35:19.778199<0:06:23.020860, 0:00:12.767362s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 448/478 | 93.72%\n",
      "[1:35:32.082046<0:06:10.223570, 0:00:12.766330s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 449/478 | 93.93%\n",
      "[1:35:44.789726<0:05:57.453572, 0:00:12.766199s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 450/478 | 94.14%\n",
      "[1:35:57.366355<0:05:44.676033, 0:00:12.765779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 451/478 | 94.35%\n",
      "[1:36:09.630860<0:05:31.881420, 0:00:12.764670s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 452/478 | 94.56%\n",
      "[1:36:21.346168<0:05:19.058850, 0:00:12.762354s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 453/478 | 94.77%\n",
      "[1:36:32.721900<0:05:06.223176, 0:00:12.759299s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 454/478 | 94.98%\n",
      "[1:36:47.537519<0:04:53.567837, 0:00:12.763819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 455/478 | 95.19%\n",
      "[1:37:00.071995<0:04:40.792952, 0:00:12.763316s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 456/478 | 95.40%\n",
      "[1:37:13.267870<0:04:28.049502, 0:00:12.764262s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 457/478 | 95.61%\n",
      "[1:37:25.506649<0:04:15.262300, 0:00:12.763115s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 458/478 | 95.82%\n",
      "[1:37:36.701477<0:04:02.434262, 0:00:12.759698s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 459/478 | 96.03%\n",
      "[1:37:50.354405<0:03:49.709520, 0:00:12.761640s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 460/478 | 96.23%\n",
      "[1:38:06.814207<0:03:37.084254, 0:00:12.769662s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 461/478 | 96.44%\n",
      "[1:38:20.177954<0:03:24.335168, 0:00:12.770948s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 462/478 | 96.65%\n",
      "[1:38:31.190497<0:03:11.507250, 0:00:12.767150s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 463/478 | 96.86%\n",
      "[1:38:45.142477<0:02:58.775856, 0:00:12.769704s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 464/478 | 97.07%\n",
      "[1:38:58.048667<0:02:46.009961, 0:00:12.769997s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 465/478 | 97.28%\n",
      "[1:39:11.002237<0:02:33.244692, 0:00:12.770391s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 466/478 | 97.49%\n",
      "[1:39:21.413995<0:02:20.418740, 0:00:12.765340s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 467/478 | 97.70%\n",
      "[1:39:35.643634<0:02:07.684690, 0:00:12.768469s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 468/478 | 97.91%\n",
      "[1:39:48.998305<0:01:54.927471, 0:00:12.769719s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 469/478 | 98.12%\n",
      "[1:39:58.649679<0:01:42.104672, 0:00:12.763084s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 470/478 | 98.33%\n",
      "[1:40:09.266569<0:01:29.309696, 0:00:12.758528s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 471/478 | 98.54%\n",
      "[1:40:20.313349<0:01:16.529406, 0:00:12.754901s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 472/478 | 98.74%\n",
      "[1:40:34.351405<0:01:03.788070, 0:00:12.757614s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 473/478 | 98.95%\n",
      "[1:40:43.989558<0:00:51.004132, 0:00:12.751033s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 474/478 | 99.16%\n",
      "[1:40:56.812734<0:00:38.253555, 0:00:12.751185s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 475/478 | 99.37%\n",
      "[1:41:08.357922<0:00:25.497302, 0:00:12.748651s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 476/478 | 99.58%\n",
      "[1:41:21.561990<0:00:12.749606, 0:00:12.749606s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 477/478 | 99.79%\n",
      "[1:41:32.463040<0:00:00, 0:00:12.745739s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 0: 478/478 | 100.00%\n",
      "[0:00:00.000185<0:00:00.088245, 0:00:00.000185s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 1/478 | 0.21%\n",
      "[0:00:17.907036<1:11:01.874568, 0:00:08.953518s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 2/478 | 0.42%\n",
      "[0:00:35.532493<1:33:45.977900, 0:00:11.844164s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 3/478 | 0.63%\n",
      "[0:00:48.181870<1:35:09.551832, 0:00:12.045468s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 4/478 | 0.84%\n",
      "[0:01:00.824319<1:35:53.980672, 0:00:12.164864s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 5/478 | 1.05%\n",
      "[0:01:14.285058<1:37:23.757896, 0:00:12.380843s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 6/478 | 1.26%\n",
      "[0:01:34.231519<1:45:40.435266, 0:00:13.461646s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 7/478 | 1.46%\n",
      "[0:01:53.378202<1:51:00.969250, 0:00:14.172275s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 8/478 | 1.67%\n",
      "[0:02:14.515479<1:56:49.750916, 0:00:14.946164s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 9/478 | 1.88%\n",
      "[0:02:35.501799<2:01:17.484240, 0:00:15.550180s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 10/478 | 2.09%\n",
      "[0:02:53.645878<2:02:52.056863, 0:00:15.785989s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 11/478 | 2.30%\n",
      "[0:03:09.636825<2:02:44.230154, 0:00:15.803069s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 12/478 | 2.51%\n",
      "[0:03:28.511320<2:04:18.289380, 0:00:16.039332s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 13/478 | 2.72%\n",
      "[0:03:44.069182<2:03:46.293088, 0:00:16.004942s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 14/478 | 2.93%\n",
      "[0:04:02.705926<2:04:51.522885, 0:00:16.180395s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 15/478 | 3.14%\n",
      "[0:04:20.499865<2:05:21.933804, 0:00:16.281242s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 16/478 | 3.35%\n",
      "[0:04:36.446794<2:04:56.586536, 0:00:16.261576s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 17/478 | 3.56%\n",
      "[0:04:55.876282<2:06:01.282660, 0:00:16.437571s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 18/478 | 3.77%\n",
      "[0:05:13.096897<2:06:03.761856, 0:00:16.478784s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 19/478 | 3.97%\n",
      "[0:05:29.699679<2:05:50.122672, 0:00:16.484984s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 20/478 | 4.18%\n",
      "[0:06:01.731719<2:11:11.971240, 0:00:17.225320s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 21/478 | 4.39%\n",
      "[0:06:21.437729<2:11:46.164024, 0:00:17.338079s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 22/478 | 4.60%\n",
      "[0:06:36.154568<2:10:36.970960, 0:00:17.224112s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 23/478 | 4.81%\n",
      "[0:06:52.964484<2:10:11.911716, 0:00:17.206854s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 24/478 | 5.02%\n",
      "[0:07:15.605817<2:11:33.177549, 0:00:17.424233s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 25/478 | 5.23%\n",
      "[0:07:28.470997<2:09:56.495568, 0:00:17.248884s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 26/478 | 5.44%\n",
      "[0:07:44.039781<2:09:11.183209, 0:00:17.186659s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 27/478 | 5.65%\n",
      "[0:07:56.471787<2:07:37.582500, 0:00:17.016850s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 28/478 | 5.86%\n",
      "[0:08:10.905474<2:06:40.570975, 0:00:16.927775s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 29/478 | 6.07%\n",
      "[0:08:23.706865<2:05:22.022592, 0:00:16.790229s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 30/478 | 6.28%\n",
      "[0:08:44.595671<2:06:04.331127, 0:00:16.922441s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 31/478 | 6.49%\n",
      "[0:09:07.333407<2:07:08.459374, 0:00:17.104169s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 32/478 | 6.69%\n",
      "[0:09:24.378762<2:06:50.562215, 0:00:17.102387s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 33/478 | 6.90%\n",
      "[0:09:39.262657<2:06:04.488828, 0:00:17.037137s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 34/478 | 7.11%\n",
      "[0:09:56.687165<2:05:52.354815, 0:00:17.048205s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 35/478 | 7.32%\n",
      "[0:10:27.909837<2:08:29.337480, 0:00:17.441940s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 36/478 | 7.53%\n",
      "[0:10:46.411684<2:08:24.528426, 0:00:17.470586s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 37/478 | 7.74%\n",
      "[0:11:09.247677<2:09:09.183640, 0:00:17.611781s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 38/478 | 7.95%\n",
      "[0:11:26.763805<2:08:50.494992, 0:00:17.609328s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 39/478 | 8.16%\n",
      "[0:11:45.907972<2:08:49.692162, 0:00:17.647699s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 40/478 | 8.37%\n",
      "[0:12:03.797602<2:08:34.623200, 0:00:17.653600s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 41/478 | 8.58%\n",
      "[0:12:15.933004<2:07:19.685304, 0:00:17.522214s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 42/478 | 8.79%\n",
      "[0:12:31.244042<2:06:39.794520, 0:00:17.470792s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 43/478 | 9.00%\n",
      "[0:12:49.977260<2:06:34.775622, 0:00:17.499483s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 44/478 | 9.21%\n",
      "[0:13:07.265078<2:06:15.239740, 0:00:17.494780s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 45/478 | 9.41%\n",
      "[0:13:20.229485<2:05:15.198576, 0:00:17.396293s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 46/478 | 9.62%\n",
      "[0:13:37.412210<2:04:55.843819, 0:00:17.391749s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 47/478 | 9.83%\n",
      "[0:13:53.943224<2:04:30.741310, 0:00:17.373817s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 48/478 | 10.04%\n",
      "[0:14:06.698684<2:03:32.933385, 0:00:17.279565s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 49/478 | 10.25%\n",
      "[0:14:23.545937<2:03:11.953332, 0:00:17.270919s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 50/478 | 10.46%\n",
      "[0:14:44.538611<2:03:25.842738, 0:00:17.343894s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 51/478 | 10.67%\n",
      "[0:14:57.330888<2:02:31.210638, 0:00:17.256363s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 52/478 | 10.88%\n",
      "[0:15:19.814245<2:02:55.869050, 0:00:17.354986s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 53/478 | 11.09%\n",
      "[0:15:32.217187<2:01:59.631144, 0:00:17.263281s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 54/478 | 11.30%\n",
      "[0:16:00.956802<2:03:10.631466, 0:00:17.471942s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 55/478 | 11.51%\n",
      "[0:16:14.937360<2:02:26.849512, 0:00:17.409596s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 56/478 | 11.72%\n",
      "[0:16:36.506056<2:02:40.158602, 0:00:17.482562s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 57/478 | 11.92%\n",
      "[0:16:57.328366<2:02:46.860480, 0:00:17.540144s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 58/478 | 12.13%\n",
      "[0:17:13.586887<2:02:20.218818, 0:00:17.518422s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 59/478 | 12.34%\n",
      "[0:17:28.165137<2:01:42.217142, 0:00:17.469419s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 60/478 | 12.55%\n",
      "[0:17:46.741220<2:01:32.312937, 0:00:17.487561s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 61/478 | 12.76%\n",
      "[0:18:08.850849<2:01:45.837760, 0:00:17.562110s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 62/478 | 12.97%\n",
      "[0:18:27.051337<2:01:32.480845, 0:00:17.572243s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 63/478 | 13.18%\n",
      "[0:18:52.498006<2:02:05.846334, 0:00:17.695281s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 64/478 | 13.39%\n",
      "[0:19:13.140066<2:02:06.874408, 0:00:17.740616s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 65/478 | 13.60%\n",
      "[0:19:31.880277<2:01:55.373944, 0:00:17.755762s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 66/478 | 13.81%\n",
      "[0:19:52.214876<2:01:53.437572, 0:00:17.794252s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 67/478 | 14.02%\n",
      "[0:20:24.645437<2:03:03.891720, 0:00:18.009492s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 68/478 | 14.23%\n",
      "[0:20:54.059735<2:03:53.484611, 0:00:18.174779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 69/478 | 14.44%\n",
      "[0:21:13.180914<2:03:40.825992, 0:00:18.188299s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 70/478 | 14.64%\n",
      "[0:21:32.856415<2:03:31.162715, 0:00:18.209245s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 71/478 | 14.85%\n",
      "[0:21:53.815223<2:03:28.458204, 0:00:18.247434s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 72/478 | 15.06%\n",
      "[0:22:13.136406<2:03:16.167915, 0:00:18.262143s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 73/478 | 15.27%\n",
      "[0:22:25.964486<2:02:28.238436, 0:00:18.188709s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 74/478 | 15.48%\n",
      "[0:22:40.815301<2:01:52.114212, 0:00:18.144204s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 75/478 | 15.69%\n",
      "[0:22:55.709382<2:01:16.778478, 0:00:18.101439s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 76/478 | 15.90%\n",
      "[0:23:16.015999<2:01:10.161278, 0:00:18.130078s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 77/478 | 16.11%\n",
      "[0:23:31.718526<2:00:39.582000, 0:00:18.098955s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 78/478 | 16.32%\n",
      "[0:23:47.072393<2:00:07.618992, 0:00:18.064208s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 79/478 | 16.53%\n",
      "[0:24:08.013826<2:00:03.868854, 0:00:18.100173s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 80/478 | 16.74%\n",
      "[0:24:26.093417<1:59:45.667843, 0:00:18.099919s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 81/478 | 16.95%\n",
      "[0:24:46.772024<1:59:40.020936, 0:00:18.131366s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 82/478 | 17.15%\n",
      "[0:25:00.681844<1:59:01.799080, 0:00:18.080504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 83/478 | 17.36%\n",
      "[0:25:17.761325<1:58:39.023278, 0:00:18.068587s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 84/478 | 17.57%\n",
      "[0:25:30.267174<1:57:55.235199, 0:00:18.003143s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 85/478 | 17.78%\n",
      "[0:25:43.140157<1:57:13.848080, 0:00:17.943490s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 86/478 | 17.99%\n",
      "[0:25:55.862523<1:56:32.439507, 0:00:17.883477s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 87/478 | 18.20%\n",
      "[0:26:14.151455<1:56:16.353150, 0:00:17.888085s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 88/478 | 18.41%\n",
      "[0:26:27.585680<1:55:38.997949, 0:00:17.838041s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 89/478 | 18.62%\n",
      "[0:26:40.608677<1:55:00.401908, 0:00:17.784541s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 90/478 | 18.83%\n",
      "[0:26:52.673609<1:54:18.293256, 0:00:17.721688s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 91/478 | 19.04%\n",
      "[0:27:05.259798<1:53:39.024662, 0:00:17.665867s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 92/478 | 19.25%\n",
      "[0:27:24.403190<1:53:27.475675, 0:00:17.681755s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 93/478 | 19.46%\n",
      "[0:27:43.103379<1:53:13.954176, 0:00:17.692589s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 94/478 | 19.67%\n",
      "[0:27:59.032466<1:52:49.151958, 0:00:17.674026s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 95/478 | 19.87%\n",
      "[0:28:18.840838<1:52:39.970938, 0:00:17.696259s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 96/478 | 20.08%\n",
      "[0:28:34.955033<1:52:16.060569, 0:00:17.679949s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 97/478 | 20.29%\n",
      "[0:28:56.850718<1:52:14.727460, 0:00:17.722967s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 98/478 | 20.50%\n",
      "[0:29:13.564822<1:51:53.142104, 0:00:17.712776s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 99/478 | 20.71%\n",
      "[0:29:27.253618<1:51:20.218608, 0:00:17.672536s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 100/478 | 20.92%\n",
      "[0:29:46.279092<1:51:07.596364, 0:00:17.685932s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 101/478 | 21.13%\n",
      "[0:29:58.799434<1:50:30.868664, 0:00:17.635289s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 102/478 | 21.34%\n",
      "[0:30:15.100429<1:50:08.375250, 0:00:17.622334s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 103/478 | 21.55%\n",
      "[0:30:30.019777<1:49:41.032656, 0:00:17.596344s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 104/478 | 21.76%\n",
      "[0:30:46.528569<1:49:19.572778, 0:00:17.585986s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 105/478 | 21.97%\n",
      "[0:31:07.935009<1:49:15.394416, 0:00:17.622028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 106/478 | 22.18%\n",
      "[0:31:22.463347<1:48:47.045665, 0:00:17.593115s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 107/478 | 22.38%\n",
      "[0:31:42.131065<1:48:36.560250, 0:00:17.612325s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 108/478 | 22.59%\n",
      "[0:31:58.311529<1:48:14.100372, 0:00:17.599188s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 109/478 | 22.80%\n",
      "[0:32:18.495554<1:48:05.148816, 0:00:17.622687s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 110/478 | 23.01%\n",
      "[0:32:35.865472<1:47:46.690470, 0:00:17.620410s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 111/478 | 23.22%\n",
      "[0:32:55.492090<1:47:35.625852, 0:00:17.638322s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 112/478 | 23.43%\n",
      "[0:33:12.924804<1:47:17.323595, 0:00:17.636503s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 113/478 | 23.64%\n",
      "[0:33:31.021489<1:47:01.156196, 0:00:17.640539s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 114/478 | 23.85%\n",
      "[0:33:53.855944<1:46:59.910552, 0:00:17.685704s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 115/478 | 24.06%\n",
      "[0:34:12.026028<1:46:43.736560, 0:00:17.689880s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 116/478 | 24.27%\n",
      "[0:34:27.780562<1:46:20.075018, 0:00:17.673338s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 117/478 | 24.48%\n",
      "[0:34:44.800237<1:46:00.407640, 0:00:17.667799s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 118/478 | 24.69%\n",
      "[0:35:04.046870<1:45:47.502694, 0:00:17.681066s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 119/478 | 24.90%\n",
      "[0:35:19.904666<1:45:24.382176, 0:00:17.665872s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 120/478 | 25.10%\n",
      "[0:35:34.443196<1:44:57.489282, 0:00:17.640026s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 121/478 | 25.31%\n",
      "[0:35:50.542797<1:44:35.354400, 0:00:17.627400s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 122/478 | 25.52%\n",
      "[0:36:07.674013<1:44:16.294930, 0:00:17.623366s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 123/478 | 25.73%\n",
      "[0:36:20.517217<1:43:45.024864, 0:00:17.584816s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 124/478 | 25.94%\n",
      "[0:36:38.671328<1:43:29.047963, 0:00:17.589371s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 125/478 | 26.15%\n",
      "[0:36:57.550461<1:43:15.061664, 0:00:17.599607s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 126/478 | 26.36%\n",
      "[0:37:15.193561<1:42:57.582099, 0:00:17.599949s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 127/478 | 26.57%\n",
      "[0:37:39.178136<1:42:57.440150, 0:00:17.649829s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 128/478 | 26.78%\n",
      "[0:38:07.906886<1:43:09.763488, 0:00:17.735712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 129/478 | 26.99%\n",
      "[0:38:25.790032<1:42:52.422408, 0:00:17.736846s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 130/478 | 27.20%\n",
      "[0:38:44.457921<1:42:37.152038, 0:00:17.743954s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 131/478 | 27.41%\n",
      "[0:39:04.408768<1:42:25.192512, 0:00:17.760672s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 132/478 | 27.62%\n",
      "[0:39:24.529796<1:42:13.554900, 0:00:17.778420s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 133/478 | 27.82%\n",
      "[0:39:37.095085<1:41:42.393504, 0:00:17.739516s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 134/478 | 28.03%\n",
      "[0:39:52.173819<1:41:17.893458, 0:00:17.719806s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 135/478 | 28.24%\n",
      "[0:40:17.023280<1:41:18.102660, 0:00:17.772230s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 136/478 | 28.45%\n",
      "[0:40:36.961886<1:41:05.722663, 0:00:17.788043s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 137/478 | 28.66%\n",
      "[0:40:50.515559<1:40:37.502060, 0:00:17.757359s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 138/478 | 28.87%\n",
      "[0:41:03.278928<1:40:07.565109, 0:00:17.721431s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 139/478 | 29.08%\n",
      "[0:41:23.361867<1:39:55.545062, 0:00:17.738299s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 140/478 | 29.29%\n",
      "[0:41:44.407566<1:39:45.711772, 0:00:17.761756s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 141/478 | 29.50%\n",
      "[0:41:59.530008<1:39:21.704784, 0:00:17.743169s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 142/478 | 29.71%\n",
      "[0:42:17.184213<1:39:03.753245, 0:00:17.742547s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 143/478 | 29.92%\n",
      "[0:42:29.652644<1:38:33.777614, 0:00:17.705921s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 144/478 | 30.13%\n",
      "[0:42:42.316936<1:38:04.493283, 0:00:17.671151s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 145/478 | 30.33%\n",
      "[0:42:58.038736<1:37:42.389600, 0:00:17.657800s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 146/478 | 30.54%\n",
      "[0:43:10.722084<1:37:13.530760, 0:00:17.623960s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 147/478 | 30.75%\n",
      "[0:43:25.903966<1:36:50.461470, 0:00:17.607459s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 148/478 | 30.96%\n",
      "[0:43:40.236050<1:36:25.621933, 0:00:17.585477s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 149/478 | 31.17%\n",
      "[0:43:57.144879<1:36:06.556848, 0:00:17.580966s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 150/478 | 31.38%\n",
      "[0:44:17.601701<1:35:55.203597, 0:00:17.600011s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 151/478 | 31.59%\n",
      "[0:44:39.715529<1:35:47.284482, 0:00:17.629707s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 152/478 | 31.80%\n",
      "[0:45:05.610204<1:35:47.211275, 0:00:17.683727s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 153/478 | 32.01%\n",
      "[0:45:25.361607<1:35:33.877572, 0:00:17.697153s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 154/478 | 32.22%\n",
      "[0:45:46.665663<1:35:23.696952, 0:00:17.720424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 155/478 | 32.43%\n",
      "[0:46:09.466747<1:35:16.463424, 0:00:17.752992s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 156/478 | 32.64%\n",
      "[0:46:33.776444<1:35:12.116034, 0:00:17.794754s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 157/478 | 32.85%\n",
      "[0:46:55.851106<1:35:02.989440, 0:00:17.821842s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 158/478 | 33.05%\n",
      "[0:47:09.637082<1:34:37.070740, 0:00:17.796460s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 159/478 | 33.26%\n",
      "[0:47:26.311182<1:34:17.043510, 0:00:17.789445s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 160/478 | 33.47%\n",
      "[0:47:49.611609<1:34:10.104975, 0:00:17.823675s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 161/478 | 33.68%\n",
      "[0:48:02.234480<1:33:42.136436, 0:00:17.791571s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 162/478 | 33.89%\n",
      "[0:48:25.173533<1:33:34.292565, 0:00:17.823151s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 163/478 | 34.10%\n",
      "[0:48:41.613802<1:33:13.821452, 0:00:17.814718s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 164/478 | 34.31%\n",
      "[0:49:00.574723<1:32:58.181145, 0:00:17.821665s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 165/478 | 34.52%\n",
      "[0:49:12.169962<1:32:28.656672, 0:00:17.784156s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 166/478 | 34.73%\n",
      "[0:49:26.674900<1:32:04.765720, 0:00:17.764520s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 167/478 | 34.94%\n",
      "[0:49:40.026968<1:31:38.859360, 0:00:17.738256s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 168/478 | 35.15%\n",
      "[0:49:58.838272<1:31:23.082945, 0:00:17.744605s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 169/478 | 35.36%\n",
      "[0:50:11.958274<1:30:56.959816, 0:00:17.717402s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 170/478 | 35.56%\n",
      "[0:50:25.545976<1:30:31.828057, 0:00:17.693251s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 171/478 | 35.77%\n",
      "[0:50:45.757700<1:30:18.615564, 0:00:17.707894s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 172/478 | 35.98%\n",
      "[0:51:10.594138<1:30:13.475195, 0:00:17.749099s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 173/478 | 36.19%\n",
      "[0:51:24.988353<1:29:49.864672, 0:00:17.729818s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 174/478 | 36.40%\n",
      "[0:51:40.385512<1:29:28.096167, 0:00:17.716489s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 175/478 | 36.61%\n",
      "[0:51:58.472892<1:29:11.015992, 0:00:17.718596s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 176/478 | 36.82%\n",
      "[0:52:12.220098<1:28:46.543859, 0:00:17.696159s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 177/478 | 37.03%\n",
      "[0:52:31.792240<1:28:32.009400, 0:00:17.706698s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 178/478 | 37.24%\n",
      "[0:52:45.802825<1:28:08.128651, 0:00:17.686049s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 179/478 | 37.45%\n",
      "[0:53:04.643677<1:27:52.354570, 0:00:17.692465s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 180/478 | 37.66%\n",
      "[0:53:18.840667<1:27:28.926441, 0:00:17.673153s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 181/478 | 37.87%\n",
      "[0:53:33.212698<1:27:05.884440, 0:00:17.655015s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 182/478 | 38.08%\n",
      "[0:53:49.242929<1:26:45.610120, 0:00:17.646136s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 183/478 | 38.28%\n",
      "[0:54:07.792031<1:26:29.406936, 0:00:17.651044s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 184/478 | 38.49%\n",
      "[0:54:19.313267<1:26:02.047630, 0:00:17.617910s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 185/478 | 38.70%\n",
      "[0:54:36.353386<1:25:43.522476, 0:00:17.614803s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 186/478 | 38.91%\n",
      "[0:54:52.859803<1:25:24.182916, 0:00:17.608876s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 187/478 | 39.12%\n",
      "[0:55:12.306938<1:25:09.409660, 0:00:17.618654s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 188/478 | 39.33%\n",
      "[0:55:31.497704<1:24:54.194908, 0:00:17.626972s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 189/478 | 39.54%\n",
      "[0:55:47.745304<1:24:34.477056, 0:00:17.619712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 190/478 | 39.75%\n",
      "[0:56:03.047591<1:24:13.375173, 0:00:17.607579s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 191/478 | 39.96%\n",
      "[0:56:16.712308<1:23:49.894298, 0:00:17.587043s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 192/478 | 40.17%\n",
      "[0:56:31.775566<1:23:28.580595, 0:00:17.573967s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 193/478 | 40.38%\n",
      "[0:56:48.817340<1:23:10.227332, 0:00:17.571223s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 194/478 | 40.59%\n",
      "[0:57:05.276620<1:22:51.042443, 0:00:17.565521s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 195/478 | 40.79%\n",
      "[0:57:22.859132<1:22:33.501456, 0:00:17.565608s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 196/478 | 41.00%\n",
      "[0:57:55.339727<1:22:37.210358, 0:00:17.641318s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 197/478 | 41.21%\n",
      "[0:58:13.188086<1:22:19.861920, 0:00:17.642364s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 198/478 | 41.42%\n",
      "[0:58:27.181800<1:21:57.104091, 0:00:17.624029s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 199/478 | 41.63%\n",
      "[0:58:38.821809<1:21:31.162302, 0:00:17.594109s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 200/478 | 41.84%\n",
      "[0:58:56.257492<1:21:13.349917, 0:00:17.593321s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 201/478 | 42.05%\n",
      "[0:59:08.045670<1:20:47.824908, 0:00:17.564583s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 202/478 | 42.26%\n",
      "[0:59:25.756818<1:20:30.458875, 0:00:17.565305s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 203/478 | 42.47%\n",
      "[0:59:39.946064<1:20:08.358870, 0:00:17.548755s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 204/478 | 42.68%\n",
      "[0:59:53.531818<1:19:45.532752, 0:00:17.529424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 205/478 | 42.89%\n",
      "[1:00:06.961263<1:19:22.589712, 0:00:17.509521s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 206/478 | 43.10%\n",
      "[1:00:22.145434<1:19:02.035777, 0:00:17.498287s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 207/478 | 43.31%\n",
      "[1:00:38.277152<1:18:42.763590, 0:00:17.491717s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 208/478 | 43.51%\n",
      "[1:00:55.500002<1:18:24.925939, 0:00:17.490431s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 209/478 | 43.72%\n",
      "[1:01:07.007497<1:17:59.799920, 0:00:17.461940s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 210/478 | 43.93%\n",
      "[1:01:26.415775<1:17:44.801055, 0:00:17.471165s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 211/478 | 44.14%\n",
      "[1:01:42.120125<1:17:25.113046, 0:00:17.462831s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 212/478 | 44.35%\n",
      "[1:01:57.383483<1:17:04.913825, 0:00:17.452505s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 213/478 | 44.56%\n",
      "[1:02:13.916317<1:16:46.326648, 0:00:17.448207s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 214/478 | 44.77%\n",
      "[1:02:28.283311<1:16:25.109388, 0:00:17.433876s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 215/478 | 44.98%\n",
      "[1:02:39.680090<1:16:00.352612, 0:00:17.405926s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 216/478 | 45.19%\n",
      "[1:02:58.452128<1:15:44.589942, 0:00:17.412222s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 217/478 | 45.40%\n",
      "[1:03:10.349001<1:15:20.599720, 0:00:17.386922s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 218/478 | 45.61%\n",
      "[1:03:21.876952<1:14:56.283771, 0:00:17.360169s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 219/478 | 45.82%\n",
      "[1:03:33.594894<1:14:32.306676, 0:00:17.334522s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 220/478 | 46.03%\n",
      "[1:03:47.456606<1:14:10.933656, 0:00:17.318808s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 221/478 | 46.23%\n",
      "[1:04:03.775511<1:13:52.461824, 0:00:17.314304s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 222/478 | 46.44%\n",
      "[1:04:22.947293<1:13:37.271670, 0:00:17.322634s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 223/478 | 46.65%\n",
      "[1:04:35.914269<1:13:15.010006, 0:00:17.303189s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 224/478 | 46.86%\n",
      "[1:04:49.567455<1:12:53.602398, 0:00:17.286966s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 225/478 | 47.07%\n",
      "[1:05:04.064515<1:12:33.204744, 0:00:17.274622s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 226/478 | 47.28%\n",
      "[1:05:21.061575<1:12:15.623149, 0:00:17.273399s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 227/478 | 47.49%\n",
      "[1:05:34.639373<1:11:54.297500, 0:00:17.257190s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 228/478 | 47.70%\n",
      "[1:05:47.461682<1:11:32.218176, 0:00:17.237824s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 229/478 | 47.91%\n",
      "[1:06:03.583126<1:11:13.776560, 0:00:17.232970s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 230/478 | 48.12%\n",
      "[1:06:23.351613<1:10:59.254662, 0:00:17.243946s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 231/478 | 48.33%\n",
      "[1:06:35.326668<1:10:36.424056, 0:00:17.221236s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 232/478 | 48.54%\n",
      "[1:06:48.636988<1:10:15.090495, 0:00:17.204451s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 233/478 | 48.74%\n",
      "[1:07:06.786560<1:09:58.871560, 0:00:17.208490s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 234/478 | 48.95%\n",
      "[1:07:20.753118<1:09:38.310642, 0:00:17.194694s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 235/478 | 49.16%\n",
      "[1:07:39.444791<1:09:22.650954, 0:00:17.201037s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 236/478 | 49.37%\n",
      "[1:07:57.714516<1:09:06.536586, 0:00:17.205546s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 237/478 | 49.58%\n",
      "[1:08:10.689385<1:08:45.065040, 0:00:17.187771s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 238/478 | 49.79%\n",
      "[1:08:24.744832<1:08:24.744935, 0:00:17.174665s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 239/478 | 50.00%\n",
      "[1:08:40.343699<1:08:06.007562, 0:00:17.168099s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 240/478 | 50.21%\n",
      "[1:08:51.473747<1:07:42.901665, 0:00:17.143045s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 241/478 | 50.42%\n",
      "[1:09:09.776039<1:07:26.889060, 0:00:17.147835s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 242/478 | 50.63%\n",
      "[1:09:23.888422<1:07:06.805605, 0:00:17.135343s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 243/478 | 50.84%\n",
      "[1:09:41.011633<1:06:49.658796, 0:00:17.135294s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 244/478 | 51.05%\n",
      "[1:09:54.709807<1:06:29.254745, 0:00:17.121265s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 245/478 | 51.26%\n",
      "[1:10:15.817041<1:06:15.892576, 0:00:17.137468s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 246/478 | 51.46%\n",
      "[1:10:30.992049<1:05:56.919582, 0:00:17.129522s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 247/478 | 51.67%\n",
      "[1:10:45.183002<1:05:37.064790, 0:00:17.117673s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 248/478 | 51.88%\n",
      "[1:10:58.478674<1:05:16.432196, 0:00:17.102324s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 249/478 | 52.09%\n",
      "[1:11:10.582008<1:04:54.770784, 0:00:17.082328s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 250/478 | 52.30%\n",
      "[1:11:25.027851<1:04:35.304048, 0:00:17.071824s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 251/478 | 52.51%\n",
      "[1:11:38.091757<1:04:14.637920, 0:00:17.055920s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 252/478 | 52.72%\n",
      "[1:11:49.742505<1:03:52.774875, 0:00:17.034555s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 253/478 | 52.93%\n",
      "[1:12:01.299270<1:03:30.909536, 0:00:17.012989s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 254/478 | 53.14%\n",
      "[1:12:19.397725<1:03:14.845858, 0:00:17.017246s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 255/478 | 53.35%\n",
      "[1:12:33.734227<1:02:55.503828, 0:00:17.006774s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 256/478 | 53.56%\n",
      "[1:12:51.668156<1:02:39.294422, 0:00:17.010382s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 257/478 | 53.77%\n",
      "[1:13:11.303005<1:02:24.521880, 0:00:17.020554s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 258/478 | 53.97%\n",
      "[1:13:31.772597<1:02:10.417749, 0:00:17.033871s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 259/478 | 54.18%\n",
      "[1:13:47.042918<1:01:51.905184, 0:00:17.027088s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 260/478 | 54.39%\n",
      "[1:14:04.922450<1:01:35.586818, 0:00:17.030354s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 261/478 | 54.60%\n",
      "[1:14:24.923907<1:01:21.005904, 0:00:17.041694s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 262/478 | 54.81%\n",
      "[1:14:41.147104<1:01:03.295130, 0:00:17.038582s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 263/478 | 55.02%\n",
      "[1:14:58.693120<1:00:46.667856, 0:00:17.040504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 264/478 | 55.23%\n",
      "[1:15:20.656183<1:00:33.584040, 0:00:17.059080s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 265/478 | 55.44%\n",
      "[1:15:40.799397<1:00:18.982888, 0:00:17.070674s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 266/478 | 55.65%\n",
      "[1:15:54.239450<0:59:59.043247, 0:00:17.057077s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 267/478 | 55.86%\n",
      "[1:16:14.653402<0:59:44.616420, 0:00:17.069602s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 268/478 | 56.07%\n",
      "[1:16:30.538608<0:59:26.626591, 0:00:17.065199s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 269/478 | 56.28%\n",
      "[1:16:44.050673<0:59:06.824320, 0:00:17.052040s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 270/478 | 56.49%\n",
      "[1:16:59.962913<0:58:48.901638, 0:00:17.047834s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 271/478 | 56.69%\n",
      "[1:17:18.125057<0:58:32.697580, 0:00:17.051930s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 272/478 | 56.90%\n",
      "[1:17:31.161824<0:58:12.630715, 0:00:17.037223s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 273/478 | 57.11%\n",
      "[1:17:44.255278<0:57:52.657116, 0:00:17.022829s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 274/478 | 57.32%\n",
      "[1:18:03.497591<0:57:37.272700, 0:00:17.030900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 275/478 | 57.53%\n",
      "[1:18:18.737746<0:57:18.931224, 0:00:17.024412s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 276/478 | 57.74%\n",
      "[1:18:32.672506<0:56:59.664858, 0:00:17.013258s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 277/478 | 57.95%\n",
      "[1:18:44.087216<0:56:38.623800, 0:00:16.993119s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 278/478 | 58.16%\n",
      "[1:18:55.218438<0:56:17.449691, 0:00:16.972109s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 279/478 | 58.37%\n",
      "[1:19:06.908302<0:55:56.742312, 0:00:16.953244s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 280/478 | 58.58%\n",
      "[1:19:22.989645<0:55:39.177777, 0:00:16.950141s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 281/478 | 58.79%\n",
      "[1:19:38.413468<0:55:21.166884, 0:00:16.944729s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 282/478 | 59.00%\n",
      "[1:19:57.195978<0:55:05.488485, 0:00:16.951223s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 283/478 | 59.21%\n",
      "[1:20:10.732115<0:54:46.204412, 0:00:16.939198s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 284/478 | 59.41%\n",
      "[1:20:30.183112<0:54:30.966123, 0:00:16.948011s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 285/478 | 59.62%\n",
      "[1:20:47.320278<0:54:14.145024, 0:00:16.948672s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 286/478 | 59.83%\n",
      "[1:21:04.807598<0:53:57.554859, 0:00:16.950549s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 287/478 | 60.04%\n",
      "[1:21:16.684002<0:53:37.256890, 0:00:16.932931s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 288/478 | 60.25%\n",
      "[1:21:28.277030<0:53:16.831617, 0:00:16.914453s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 289/478 | 60.46%\n",
      "[1:21:46.583032<0:53:00.819376, 0:00:16.919252s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 290/478 | 60.67%\n",
      "[1:22:05.292798<0:52:45.050735, 0:00:16.925405s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 291/478 | 60.88%\n",
      "[1:22:21.586649<0:52:27.723012, 0:00:16.923242s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 292/478 | 61.09%\n",
      "[1:22:46.635457<0:52:15.930190, 0:00:16.950974s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 293/478 | 61.30%\n",
      "[1:23:04.973275<0:51:59.847144, 0:00:16.955691s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 294/478 | 61.51%\n",
      "[1:23:22.256224<0:51:43.094583, 0:00:16.956801s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 295/478 | 61.72%\n",
      "[1:23:39.544323<0:51:26.341440, 0:00:16.957920s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 296/478 | 61.92%\n",
      "[1:24:03.625528<0:51:13.724624, 0:00:16.981904s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 297/478 | 62.13%\n",
      "[1:24:16.566671<0:50:54.302100, 0:00:16.968345s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 298/478 | 62.34%\n",
      "[1:24:30.616181<0:50:35.586357, 0:00:16.958583s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 299/478 | 62.55%\n",
      "[1:24:46.029375<0:50:17.710718, 0:00:16.953431s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 300/478 | 62.76%\n",
      "[1:25:01.575704<0:49:59.929812, 0:00:16.948756s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 301/478 | 62.97%\n",
      "[1:25:13.121668<0:49:39.832416, 0:00:16.930866s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 302/478 | 63.18%\n",
      "[1:25:24.881422<0:49:19.915000, 0:00:16.913800s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 303/478 | 63.39%\n",
      "[1:25:40.642280<0:49:02.341392, 0:00:16.910008s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 304/478 | 63.60%\n",
      "[1:25:57.943568<0:48:45.653170, 0:00:16.911290s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 305/478 | 63.81%\n",
      "[1:26:16.916004<0:48:29.900472, 0:00:16.918026s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 306/478 | 64.02%\n",
      "[1:26:28.475796<0:48:09.997983, 0:00:16.900573s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 307/478 | 64.23%\n",
      "[1:26:44.056374<0:47:52.368790, 0:00:16.896287s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 308/478 | 64.44%\n",
      "[1:27:00.935841<0:47:35.463208, 0:00:16.896232s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 309/478 | 64.64%\n",
      "[1:27:16.167162<0:47:17.664816, 0:00:16.890862s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 310/478 | 64.85%\n",
      "[1:27:45.916510<0:47:07.678569, 0:00:16.932207s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 311/478 | 65.06%\n",
      "[1:28:02.283667<0:46:50.445736, 0:00:16.930396s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 312/478 | 65.27%\n",
      "[1:28:20.626919<0:46:34.260150, 0:00:16.934910s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 313/478 | 65.48%\n",
      "[1:28:35.771670<0:46:16.390276, 0:00:16.929209s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 314/478 | 65.69%\n",
      "[1:28:59.068824<0:46:02.756275, 0:00:16.949425s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 315/478 | 65.90%\n",
      "[1:29:11.169271<0:45:43.320960, 0:00:16.934080s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 316/478 | 66.11%\n",
      "[1:29:26.665018<0:45:25.656423, 0:00:16.929543s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 317/478 | 66.32%\n",
      "[1:29:43.229452<0:45:08.543200, 0:00:16.928395s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 318/478 | 66.53%\n",
      "[1:29:57.719782<0:44:50.399568, 0:00:16.920752s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 319/478 | 66.74%\n",
      "[1:30:15.382956<0:44:33.845376, 0:00:16.923072s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 320/478 | 66.95%\n",
      "[1:30:30.073159<0:44:15.830212, 0:00:16.916116s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 321/478 | 67.15%\n",
      "[1:31:15.301962<0:44:12.630708, 0:00:17.004043s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 322/478 | 67.36%\n",
      "[1:31:33.356205<0:43:56.130725, 0:00:17.007295s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 323/478 | 67.57%\n",
      "[1:31:48.119471<0:43:38.056826, 0:00:17.000369s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 324/478 | 67.78%\n",
      "[1:32:07.561880<0:43:22.206099, 0:00:17.007883s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 325/478 | 67.99%\n",
      "[1:32:19.279567<0:43:02.731560, 0:00:16.991655s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 326/478 | 68.20%\n",
      "[1:32:35.315073<0:42:45.298381, 0:00:16.988731s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 327/478 | 68.41%\n",
      "[1:32:46.803249<0:42:25.794150, 0:00:16.971961s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 328/478 | 68.62%\n",
      "[1:33:05.495420<0:42:09.601310, 0:00:16.977190s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 329/478 | 68.83%\n",
      "[1:33:23.844556<0:41:53.239356, 0:00:16.981347s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 330/478 | 69.04%\n",
      "[1:33:39.669781<0:41:35.744538, 0:00:16.977854s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 331/478 | 69.25%\n",
      "[1:34:00.330884<0:41:20.386408, 0:00:16.988948s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 332/478 | 69.46%\n",
      "[1:34:15.133698<0:41:02.445535, 0:00:16.982383s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 333/478 | 69.67%\n",
      "[1:34:28.772125<0:40:44.021568, 0:00:16.972372s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 334/478 | 69.87%\n",
      "[1:34:40.711744<0:40:24.900764, 0:00:16.957348s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 335/478 | 70.08%\n",
      "[1:34:54.432011<0:40:06.575388, 0:00:16.947714s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 336/478 | 70.29%\n",
      "[1:35:07.264807<0:39:47.906064, 0:00:16.935504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 337/478 | 70.50%\n",
      "[1:35:22.909404<0:39:30.435900, 0:00:16.931685s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 338/478 | 70.71%\n",
      "[1:35:41.080857<0:39:14.012538, 0:00:16.935342s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 339/478 | 70.92%\n",
      "[1:36:05.683235<0:39:00.189096, 0:00:16.957892s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 340/478 | 71.13%\n",
      "[1:36:26.750117<0:38:44.882054, 0:00:16.969942s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 341/478 | 71.34%\n",
      "[1:36:47.140473<0:38:29.272248, 0:00:16.979943s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 342/478 | 71.55%\n",
      "[1:37:13.526772<0:38:15.994545, 0:00:17.007367s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 343/478 | 71.76%\n",
      "[1:37:29.267328<0:37:58.493656, 0:00:17.003684s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 344/478 | 71.97%\n",
      "[1:37:42.417296<0:37:40.004362, 0:00:16.992514s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 345/478 | 72.18%\n",
      "[1:38:04.245866<0:37:24.856812, 0:00:17.006491s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 346/478 | 72.38%\n",
      "[1:38:22.530882<0:37:08.332925, 0:00:17.010175s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 347/478 | 72.59%\n",
      "[1:38:37.079277<0:36:50.403130, 0:00:17.003101s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 348/478 | 72.80%\n",
      "[1:38:54.001356<0:36:33.370101, 0:00:17.002869s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 349/478 | 73.01%\n",
      "[1:39:08.774017<0:36:15.551616, 0:00:16.996497s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 350/478 | 73.22%\n",
      "[1:39:25.193067<0:35:58.346204, 0:00:16.994852s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 351/478 | 73.43%\n",
      "[1:39:41.710049<0:35:41.180244, 0:00:16.993494s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 352/478 | 73.64%\n",
      "[1:39:57.557948<0:35:23.781125, 0:00:16.990249s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 353/478 | 73.85%\n",
      "[1:40:09.288591<0:35:04.948608, 0:00:16.975392s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 354/478 | 74.06%\n",
      "[1:40:25.943669<0:34:47.862147, 0:00:16.974489s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 355/478 | 74.27%\n",
      "[1:40:42.040689<0:34:30.586928, 0:00:16.972024s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 356/478 | 74.48%\n",
      "[1:41:01.058135<0:34:14.308234, 0:00:16.977754s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 357/478 | 74.69%\n",
      "[1:41:18.651683<0:33:57.536880, 0:00:16.979474s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 358/478 | 74.90%\n",
      "[1:41:30.430506<0:33:38.833453, 0:00:16.964987s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 359/478 | 75.10%\n",
      "[1:41:49.674605<0:33:22.615524, 0:00:16.971318s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 360/478 | 75.31%\n",
      "[1:42:03.497420<0:33:04.623849, 0:00:16.962597s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 361/478 | 75.52%\n",
      "[1:42:21.101045<0:32:47.866688, 0:00:16.964368s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 362/478 | 75.73%\n",
      "[1:42:33.114547<0:32:29.333835, 0:00:16.950729s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 363/478 | 75.94%\n",
      "[1:42:56.666676<0:32:14.450496, 0:00:16.968864s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 364/478 | 76.15%\n",
      "[1:43:09.586838<0:31:56.228236, 0:00:16.957772s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 365/478 | 76.36%\n",
      "[1:43:22.935531<0:31:38.166032, 0:00:16.947911s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 366/478 | 76.57%\n",
      "[1:43:34.726435<0:31:19.658349, 0:00:16.933859s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 367/478 | 76.78%\n",
      "[1:43:46.266993<0:31:01.112440, 0:00:16.919204s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 368/478 | 76.99%\n",
      "[1:43:57.933876<0:30:42.641730, 0:00:16.904970s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 369/478 | 77.20%\n",
      "[1:44:14.869233<0:30:25.745616, 0:00:16.905052s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 370/478 | 77.41%\n",
      "[1:44:28.378916<0:30:07.861300, 0:00:16.895900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 371/478 | 77.62%\n",
      "[1:44:43.049319<0:29:50.331308, 0:00:16.889918s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 372/478 | 77.82%\n",
      "[1:45:02.154995<0:29:34.065090, 0:00:16.895858s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 373/478 | 78.03%\n",
      "[1:45:23.423033<0:29:18.384992, 0:00:16.907548s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 374/478 | 78.24%\n",
      "[1:45:42.322234<0:29:02.024477, 0:00:16.912859s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 375/478 | 78.45%\n",
      "[1:46:02.313265<0:28:45.946692, 0:00:16.921046s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 376/478 | 78.66%\n",
      "[1:46:18.311695<0:28:28.778499, 0:00:16.918599s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 377/478 | 78.87%\n",
      "[1:46:31.985922<0:28:11.001600, 0:00:16.910016s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 378/478 | 79.08%\n",
      "[1:46:51.981171<0:27:54.897444, 0:00:16.918156s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 379/478 | 79.29%\n",
      "[1:47:03.689698<0:27:36.635806, 0:00:16.904447s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 380/478 | 79.50%\n",
      "[1:47:26.465182<0:27:21.226032, 0:00:16.919856s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 381/478 | 79.71%\n",
      "[1:47:45.412946<0:27:04.815840, 0:00:16.925165s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 382/478 | 79.92%\n",
      "[1:47:56.902402<0:26:46.542340, 0:00:16.910972s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 383/478 | 80.13%\n",
      "[1:48:13.261609<0:26:29.496290, 0:00:16.909535s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 384/478 | 80.33%\n",
      "[1:48:24.710917<0:26:11.267829, 0:00:16.895353s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 385/478 | 80.54%\n",
      "[1:48:39.433701<0:25:53.854700, 0:00:16.889725s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 386/478 | 80.75%\n",
      "[1:49:00.274175<0:25:37.893903, 0:00:16.899933s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 387/478 | 80.96%\n",
      "[1:49:16.698582<0:25:20.883720, 0:00:16.898708s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 388/478 | 81.17%\n",
      "[1:49:29.209616<0:25:02.981092, 0:00:16.887428s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 389/478 | 81.38%\n",
      "[1:49:41.411604<0:24:45.036432, 0:00:16.875414s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 390/478 | 81.59%\n",
      "[1:49:59.176144<0:24:28.358856, 0:00:16.877688s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 391/478 | 81.80%\n",
      "[1:50:15.609796<0:24:11.383816, 0:00:16.876556s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 392/478 | 82.01%\n",
      "[1:50:32.273426<0:23:54.461190, 0:00:16.876014s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 393/478 | 82.22%\n",
      "[1:50:48.481286<0:23:37.442712, 0:00:16.874318s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 394/478 | 82.43%\n",
      "[1:51:01.208424<0:23:19.696977, 0:00:16.863819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 395/478 | 82.64%\n",
      "[1:51:14.388738<0:23:02.070394, 0:00:16.854517s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 396/478 | 82.85%\n",
      "[1:51:26.014348<0:22:44.149026, 0:00:16.841346s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 397/478 | 83.05%\n",
      "[1:51:37.669329<0:22:26.265200, 0:00:16.828315s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 398/478 | 83.26%\n",
      "[1:51:58.184056<0:22:10.166766, 0:00:16.837554s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 399/478 | 83.47%\n",
      "[1:52:12.618089<0:21:52.860510, 0:00:16.831545s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 400/478 | 83.68%\n",
      "[1:52:27.954722<0:21:35.741909, 0:00:16.827817s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 401/478 | 83.89%\n",
      "[1:52:41.714378<0:21:18.334060, 0:00:16.820185s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 402/478 | 84.10%\n",
      "[1:53:00.477027<0:21:01.875375, 0:00:16.825005s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 403/478 | 84.31%\n",
      "[1:53:15.915503<0:20:44.796402, 0:00:16.821573s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 404/478 | 84.52%\n",
      "[1:53:28.388350<0:20:27.190955, 0:00:16.810835s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 405/478 | 84.73%\n",
      "[1:53:50.393067<0:20:11.301216, 0:00:16.823628s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 406/478 | 84.94%\n",
      "[1:54:05.009491<0:19:54.092555, 0:00:16.818205s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 407/478 | 85.15%\n",
      "[1:54:16.456098<0:19:36.352730, 0:00:16.805039s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 408/478 | 85.36%\n",
      "[1:54:32.519899<0:19:19.422663, 0:00:16.803227s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 409/478 | 85.56%\n",
      "[1:54:46.175729<0:19:02.097468, 0:00:16.795551s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 410/478 | 85.77%\n",
      "[1:54:57.816987<0:18:44.461670, 0:00:16.783010s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 411/478 | 85.98%\n",
      "[1:55:11.313769<0:18:27.152178, 0:00:16.775033s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 412/478 | 86.19%\n",
      "[1:55:35.392095<0:18:11.526605, 0:00:16.792717s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 413/478 | 86.40%\n",
      "[1:55:46.916026<0:17:53.919360, 0:00:16.779990s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 414/478 | 86.61%\n",
      "[1:56:04.880883<0:17:37.319298, 0:00:16.782846s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 415/478 | 86.82%\n",
      "[1:56:25.512063<0:17:21.109952, 0:00:16.792096s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 416/478 | 87.03%\n",
      "[1:56:43.573659<0:17:04.503601, 0:00:16.795141s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 417/478 | 87.24%\n",
      "[1:57:01.171292<0:16:47.823660, 0:00:16.797061s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 418/478 | 87.45%\n",
      "[1:57:18.291879<0:16:31.072147, 0:00:16.797833s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 419/478 | 87.66%\n",
      "[1:57:38.847406<0:16:14.793240, 0:00:16.806780s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 420/478 | 87.87%\n",
      "[1:57:50.522228<0:15:57.291630, 0:00:16.794590s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 421/478 | 88.08%\n",
      "[1:58:04.057474<0:15:40.064496, 0:00:16.786866s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 422/478 | 88.28%\n",
      "[1:58:15.690429<0:15:22.607510, 0:00:16.774682s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 423/478 | 88.49%\n",
      "[1:58:27.277180<0:15:05.172084, 0:00:16.762446s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 424/478 | 88.70%\n",
      "[1:58:40.381794<0:14:47.953520, 0:00:16.753840s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 425/478 | 88.91%\n",
      "[1:58:52.103896<0:14:30.585456, 0:00:16.742028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 426/478 | 89.12%\n",
      "[1:59:12.087518<0:14:14.230569, 0:00:16.749619s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 427/478 | 89.33%\n",
      "[1:59:25.624882<0:13:57.105700, 0:00:16.742114s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 428/478 | 89.54%\n",
      "[1:59:37.148893<0:13:39.767599, 0:00:16.729951s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 429/478 | 89.75%\n",
      "[1:59:48.964020<0:13:22.489008, 0:00:16.718521s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 430/478 | 89.96%\n",
      "[2:00:05.532696<0:13:05.754131, 0:00:16.718173s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 431/478 | 90.17%\n",
      "[2:00:16.972484<0:12:48.473930, 0:00:16.705955s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 432/478 | 90.38%\n",
      "[2:00:28.541790<0:12:31.234140, 0:00:16.694092s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 433/478 | 90.59%\n",
      "[2:00:39.934663<0:12:14.002588, 0:00:16.681877s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 434/478 | 90.79%\n",
      "[2:00:55.848642<0:11:57.244816, 0:00:16.680112s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 435/478 | 91.00%\n",
      "[2:01:14.554360<0:11:40.759836, 0:00:16.684758s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 436/478 | 91.21%\n",
      "[2:01:30.046055<0:11:23.963148, 0:00:16.682028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 437/478 | 91.42%\n",
      "[2:01:51.525588<0:11:07.719240, 0:00:16.692981s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 438/478 | 91.63%\n",
      "[2:02:05.375835<0:10:50.773695, 0:00:16.686505s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 439/478 | 91.84%\n",
      "[2:02:25.144155<0:10:34.353342, 0:00:16.693509s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 440/478 | 92.05%\n",
      "[2:02:43.376486<0:10:17.788963, 0:00:16.696999s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 441/478 | 92.26%\n",
      "[2:03:00.290598<0:10:01.109640, 0:00:16.697490s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 442/478 | 92.47%\n",
      "[2:03:21.612697<0:09:44.777515, 0:00:16.707929s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 443/478 | 92.68%\n",
      "[2:03:33.354390<0:09:27.689296, 0:00:16.696744s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 444/478 | 92.89%\n",
      "[2:03:44.325498<0:09:10.567974, 0:00:16.683878s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 445/478 | 93.10%\n",
      "[2:04:01.285909<0:08:53.903936, 0:00:16.684498s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 446/478 | 93.31%\n",
      "[2:04:12.910918<0:08:36.868549, 0:00:16.673179s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 447/478 | 93.51%\n",
      "[2:04:29.172895<0:08:20.167830, 0:00:16.672261s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 448/478 | 93.72%\n",
      "[2:04:47.847077<0:08:03.624880, 0:00:16.676720s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 449/478 | 93.93%\n",
      "[2:05:05.176722<0:07:46.988760, 0:00:16.678170s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 450/478 | 94.14%\n",
      "[2:05:23.722518<0:07:30.422424, 0:00:16.682312s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 451/478 | 94.35%\n",
      "[2:05:37.653518<0:07:13.581850, 0:00:16.676225s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 452/478 | 94.56%\n",
      "[2:05:51.580070<0:06:56.753875, 0:00:16.670155s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 453/478 | 94.77%\n",
      "[2:06:03.500049<0:06:39.832608, 0:00:16.659692s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 454/478 | 94.98%\n",
      "[2:06:18.348869<0:06:23.081376, 0:00:16.655712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 455/478 | 95.19%\n",
      "[2:06:31.542401<0:06:06.258618, 0:00:16.648119s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 456/478 | 95.40%\n",
      "[2:06:46.055482<0:05:49.512387, 0:00:16.643447s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 457/478 | 95.61%\n",
      "[2:07:01.141503<0:05:32.800940, 0:00:16.640047s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 458/478 | 95.82%\n",
      "[2:07:18.293871<0:05:16.182097, 0:00:16.641163s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 459/478 | 96.03%\n",
      "[2:07:36.865897<0:04:59.616498, 0:00:16.645361s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 460/478 | 96.23%\n",
      "[2:07:56.320083<0:04:43.074718, 0:00:16.651454s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 461/478 | 96.44%\n",
      "[2:08:14.828573<0:04:26.487568, 0:00:16.655473s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 462/478 | 96.65%\n",
      "[2:08:26.634001<0:04:09.674970, 0:00:16.644998s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 463/478 | 96.86%\n",
      "[2:08:44.258168<0:03:53.059512, 0:00:16.647108s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 464/478 | 97.07%\n",
      "[2:09:03.219955<0:03:36.477118, 0:00:16.652086s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 465/478 | 97.28%\n",
      "[2:09:20.888009<0:03:19.851192, 0:00:16.654266s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 466/478 | 97.49%\n",
      "[2:09:36.901476<0:03:03.181834, 0:00:16.652894s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 467/478 | 97.70%\n",
      "[2:09:54.288794<0:02:46.544630, 0:00:16.654463s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 468/478 | 97.91%\n",
      "[2:10:08.449908<0:02:29.842323, 0:00:16.649147s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 469/478 | 98.12%\n",
      "[2:10:25.093451<0:02:13.193080, 0:00:16.649135s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 470/478 | 98.33%\n",
      "[2:10:38.772961<0:01:56.499810, 0:00:16.642830s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 471/478 | 98.54%\n",
      "[2:10:54.256259<0:01:39.842238, 0:00:16.640373s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 472/478 | 98.74%\n",
      "[2:11:08.799334<0:01:23.179695, 0:00:16.635939s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 473/478 | 98.95%\n",
      "[2:11:20.446315<0:01:06.501656, 0:00:16.625414s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 474/478 | 99.16%\n",
      "[2:11:34.902347<0:00:49.862541, 0:00:16.620847s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 475/478 | 99.37%\n",
      "[2:11:46.903243<0:00:33.222282, 0:00:16.611141s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 476/478 | 99.58%\n",
      "[2:12:06.999204<0:00:16.618447, 0:00:16.618447s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 477/478 | 99.79%\n",
      "[2:12:20.803679<0:00:00, 0:00:16.612560s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 1: 478/478 | 100.00%\n",
      "[0:00:00.000190<0:00:00.090630, 0:00:00.000190s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 1/478 | 0.21%\n",
      "[0:00:11.573689<0:45:54.537744, 0:00:05.786844s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 2/478 | 0.42%\n",
      "[0:00:22.571204<0:59:33.774125, 0:00:07.523735s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 3/478 | 0.63%\n",
      "[0:00:32.202265<1:03:35.968284, 0:00:08.050566s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 4/478 | 0.84%\n",
      "[0:00:42.083970<1:06:21.143562, 0:00:08.416794s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 5/478 | 1.05%\n",
      "[0:00:54.964213<1:12:03.851344, 0:00:09.160702s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 6/478 | 1.26%\n",
      "[0:01:06.115647<1:14:08.638332, 0:00:09.445092s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 7/478 | 1.46%\n",
      "[0:01:17.773840<1:16:09.213100, 0:00:09.721730s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 8/478 | 1.67%\n",
      "[0:01:29.717509<1:17:55.279028, 0:00:09.968612s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 9/478 | 1.88%\n",
      "[0:01:40.418704<1:18:19.595160, 0:00:10.041870s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 10/478 | 2.09%\n",
      "[0:01:52.297664<1:19:27.546493, 0:00:10.208879s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 11/478 | 2.30%\n",
      "[0:02:04.212946<1:20:23.602814, 0:00:10.351079s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 12/478 | 2.51%\n",
      "[0:02:19.167170<1:22:57.902655, 0:00:10.705167s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 13/478 | 2.72%\n",
      "[0:02:31.192191<1:23:30.941088, 0:00:10.799442s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 14/478 | 2.93%\n",
      "[0:02:42.385052<1:23:32.285210, 0:00:10.825670s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 15/478 | 3.14%\n",
      "[0:02:54.894051<1:24:10.065636, 0:00:10.930878s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 16/478 | 3.35%\n",
      "[0:03:08.191688<1:25:03.315639, 0:00:11.070099s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 17/478 | 3.56%\n",
      "[0:03:23.678562<1:26:45.118960, 0:00:11.315476s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 18/478 | 3.77%\n",
      "[0:03:36.851771<1:27:18.682209, 0:00:11.413251s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 19/478 | 3.97%\n",
      "[0:03:49.639055<1:27:38.734474, 0:00:11.481953s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 20/478 | 4.18%\n",
      "[0:04:00.304368<1:27:09.480705, 0:00:11.443065s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 21/478 | 4.39%\n",
      "[0:04:12.527724<1:27:14.211048, 0:00:11.478533s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 22/478 | 4.60%\n",
      "[0:04:25.523858<1:27:32.754780, 0:00:11.544516s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 23/478 | 4.81%\n",
      "[0:04:37.568883<1:27:30.677980, 0:00:11.565370s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 24/478 | 5.02%\n",
      "[0:04:48.934958<1:27:15.501294, 0:00:11.557398s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 25/478 | 5.23%\n",
      "[0:04:58.656647<1:26:32.030888, 0:00:11.486794s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 26/478 | 5.44%\n",
      "[0:05:10.713898<1:26:30.072822, 0:00:11.507922s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 27/478 | 5.65%\n",
      "[0:05:20.505278<1:25:50.977650, 0:00:11.446617s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 28/478 | 5.86%\n",
      "[0:05:31.037284<1:25:25.370471, 0:00:11.415079s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 29/478 | 6.07%\n",
      "[0:05:40.856487<1:24:50.123584, 0:00:11.361883s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 30/478 | 6.28%\n",
      "[0:05:52.600380<1:24:44.270082, 0:00:11.374206s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 31/478 | 6.49%\n",
      "[0:06:04.431219<1:24:39.260296, 0:00:11.388476s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 32/478 | 6.69%\n",
      "[0:06:15.925740<1:24:29.301605, 0:00:11.391689s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 33/478 | 6.90%\n",
      "[0:06:27.739900<1:24:23.427060, 0:00:11.404115s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 34/478 | 7.11%\n",
      "[0:06:40.886744<1:24:34.080801, 0:00:11.453907s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 35/478 | 7.32%\n",
      "[0:06:56.395174<1:25:12.407586, 0:00:11.566533s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 36/478 | 7.53%\n",
      "[0:07:06.957516<1:24:48.871872, 0:00:11.539392s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 37/478 | 7.74%\n",
      "[0:07:20.906826<1:25:05.236840, 0:00:11.602811s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 38/478 | 7.95%\n",
      "[0:07:31.540178<1:24:42.721367, 0:00:11.577953s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 39/478 | 8.16%\n",
      "[0:07:43.871680<1:24:39.394896, 0:00:11.596792s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 40/478 | 8.37%\n",
      "[0:07:55.437230<1:24:27.465110, 0:00:11.596030s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 41/478 | 8.58%\n",
      "[0:08:05.524301<1:24:00.204472, 0:00:11.560102s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 42/478 | 8.79%\n",
      "[0:08:16.687011<1:23:44.624535, 0:00:11.550861s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 43/478 | 9.00%\n",
      "[0:08:28.987581<1:23:40.468600, 0:00:11.567900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 44/478 | 9.21%\n",
      "[0:08:41.637623<1:23:39.313051, 0:00:11.591947s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 45/478 | 9.41%\n",
      "[0:08:51.689468<1:23:13.257744, 0:00:11.558467s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 46/478 | 9.62%\n",
      "[0:09:00.453372<1:22:36.072448, 0:00:11.499008s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 47/478 | 9.83%\n",
      "[0:09:10.469736<1:22:11.291600, 0:00:11.468120s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 48/478 | 10.04%\n",
      "[0:09:20.221555<1:21:44.796897, 0:00:11.433093s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 49/478 | 10.25%\n",
      "[0:09:32.139058<1:21:37.510268, 0:00:11.442781s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 50/478 | 10.46%\n",
      "[0:09:44.300231<1:21:32.082209, 0:00:11.456867s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 51/478 | 10.67%\n",
      "[0:09:53.434076<1:21:01.594644, 0:00:11.412194s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 52/478 | 10.88%\n",
      "[0:10:04.638345<1:20:48.515175, 0:00:11.408271s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 53/478 | 11.09%\n",
      "[0:10:14.054554<1:20:21.465544, 0:00:11.371381s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 54/478 | 11.30%\n",
      "[0:10:26.996007<1:20:22.169121, 0:00:11.399927s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 55/478 | 11.51%\n",
      "[0:10:38.395455<1:20:10.765818, 0:00:11.399919s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 56/478 | 11.72%\n",
      "[0:10:50.638581<1:20:05.593752, 0:00:11.414712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 57/478 | 11.92%\n",
      "[0:11:03.695813<1:20:06.073020, 0:00:11.443031s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 58/478 | 12.13%\n",
      "[0:11:14.263371<1:19:48.412867, 0:00:11.428193s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 59/478 | 12.34%\n",
      "[0:11:26.462158<1:19:42.353048, 0:00:11.441036s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 60/478 | 12.55%\n",
      "[0:11:39.017093<1:19:38.526849, 0:00:11.459297s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 61/478 | 12.76%\n",
      "[0:11:51.071502<1:19:31.060320, 0:00:11.468895s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 62/478 | 12.97%\n",
      "[0:12:03.397760<1:19:25.239160, 0:00:11.482504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 63/478 | 13.18%\n",
      "[0:12:15.303034<1:19:16.491540, 0:00:11.489110s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 64/478 | 13.39%\n",
      "[0:12:27.906542<1:19:12.082902, 0:00:11.506254s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 65/478 | 13.60%\n",
      "[0:12:40.925815<1:19:10.021748, 0:00:11.529179s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 66/478 | 13.81%\n",
      "[0:12:52.323319<1:18:57.684954, 0:00:11.527214s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 67/478 | 14.02%\n",
      "[0:13:07.396523<1:19:07.538010, 0:00:11.579361s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 68/478 | 14.23%\n",
      "[0:13:20.046501<1:19:02.304693, 0:00:11.594877s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 69/478 | 14.44%\n",
      "[0:13:33.475863<1:19:01.402272, 0:00:11.621084s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 70/478 | 14.64%\n",
      "[0:13:46.763805<1:18:59.336327, 0:00:11.644561s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 71/478 | 14.85%\n",
      "[0:13:59.284338<1:18:52.631162, 0:00:11.656727s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 72/478 | 15.06%\n",
      "[0:14:11.961985<1:18:46.638360, 0:00:11.670712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 73/478 | 15.27%\n",
      "[0:14:22.329405<1:18:27.852400, 0:00:11.653100s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 74/478 | 15.48%\n",
      "[0:14:32.440218<1:18:07.912008, 0:00:11.632536s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 75/478 | 15.69%\n",
      "[0:14:43.270531<1:17:52.036362, 0:00:11.621981s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 76/478 | 15.90%\n",
      "[0:14:59.621888<1:18:05.043801, 0:00:11.683401s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 77/478 | 16.11%\n",
      "[0:15:09.981297<1:17:46.570800, 0:00:11.666427s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 78/478 | 16.32%\n",
      "[0:15:23.534719<1:17:44.434887, 0:00:11.690313s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 79/478 | 16.53%\n",
      "[0:15:37.119711<1:17:42.170408, 0:00:11.713996s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 80/478 | 16.74%\n",
      "[0:15:50.115860<1:17:36.740525, 0:00:11.729825s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 81/478 | 16.95%\n",
      "[0:16:02.455974<1:17:27.958128, 0:00:11.737268s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 82/478 | 17.15%\n",
      "[0:16:14.957696<1:17:19.858810, 0:00:11.746478s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 83/478 | 17.36%\n",
      "[0:16:26.671209<1:17:07.957884, 0:00:11.746086s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 84/478 | 17.57%\n",
      "[0:16:36.500053<1:16:47.347290, 0:00:11.723530s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 85/478 | 17.78%\n",
      "[0:16:47.139477<1:16:30.682208, 0:00:11.710924s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 86/478 | 17.99%\n",
      "[0:16:56.774787<1:16:09.643197, 0:00:11.687067s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 87/478 | 18.20%\n",
      "[0:17:09.792814<1:16:03.854490, 0:00:11.702191s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 88/478 | 18.41%\n",
      "[0:17:19.184376<1:15:42.053081, 0:00:11.676229s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 89/478 | 18.62%\n",
      "[0:17:29.237955<1:15:23.381600, 0:00:11.658200s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 90/478 | 18.83%\n",
      "[0:17:38.816109<1:15:02.877354, 0:00:11.635342s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 91/478 | 19.04%\n",
      "[0:17:47.626752<1:14:39.390654, 0:00:11.604639s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 92/478 | 19.25%\n",
      "[0:18:00.106408<1:14:31.408095, 0:00:11.614047s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 93/478 | 19.46%\n",
      "[0:18:12.106685<1:14:21.371904, 0:00:11.618156s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 94/478 | 19.67%\n",
      "[0:18:24.895423<1:14:14.473074, 0:00:11.630478s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 95/478 | 19.87%\n",
      "[0:18:36.676950<1:14:03.443864, 0:00:11.632052s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 96/478 | 20.08%\n",
      "[0:18:46.871364<1:13:46.165011, 0:00:11.617231s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 97/478 | 20.29%\n",
      "[0:18:58.349711<1:13:34.008940, 0:00:11.615813s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 98/478 | 20.50%\n",
      "[0:19:10.682893<1:13:25.139740, 0:00:11.623060s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 99/478 | 20.71%\n",
      "[0:19:21.308864<1:13:09.747642, 0:00:11.613089s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 100/478 | 20.92%\n",
      "[0:19:34.528334<1:13:04.130361, 0:00:11.628993s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 101/478 | 21.13%\n",
      "[0:19:44.580650<1:12:46.689536, 0:00:11.613536s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 102/478 | 21.34%\n",
      "[0:19:56.863057<1:12:37.511250, 0:00:11.620030s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 103/478 | 21.55%\n",
      "[0:20:06.707994<1:12:19.507414, 0:00:11.602961s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 104/478 | 21.76%\n",
      "[0:20:18.216433<1:12:07.568753, 0:00:11.602061s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 105/478 | 21.97%\n",
      "[0:20:32.272798<1:12:04.579980, 0:00:11.625215s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 106/478 | 22.18%\n",
      "[0:20:43.098665<1:11:50.183395, 0:00:11.617745s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 107/478 | 22.38%\n",
      "[0:20:55.528213<1:11:41.346570, 0:00:11.625261s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 108/478 | 22.59%\n",
      "[0:21:05.927499<1:11:25.571166, 0:00:11.614014s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 109/478 | 22.80%\n",
      "[0:21:18.145196<1:11:15.976736, 0:00:11.619502s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 110/478 | 23.01%\n",
      "[0:21:30.748755<1:11:07.610689, 0:00:11.628367s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 111/478 | 23.22%\n",
      "[0:21:44.551190<1:11:03.086748, 0:00:11.647778s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 112/478 | 23.43%\n",
      "[0:21:55.723189<1:10:49.902320, 0:00:11.643568s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 113/478 | 23.64%\n",
      "[0:22:08.126420<1:10:40.684448, 0:00:11.650232s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 114/478 | 23.85%\n",
      "[0:22:21.639204<1:10:34.913364, 0:00:11.666428s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 115/478 | 24.06%\n",
      "[0:22:34.467201<1:10:26.871642, 0:00:11.676441s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 116/478 | 24.27%\n",
      "[0:22:46.603351<1:10:16.613931, 0:00:11.680371s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 117/478 | 24.48%\n",
      "[0:22:58.510145<1:10:05.624040, 0:00:11.682289s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 118/478 | 24.69%\n",
      "[0:23:10.984895<1:09:56.332691, 0:00:11.688949s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 119/478 | 24.90%\n",
      "[0:23:22.709989<1:09:44.751500, 0:00:11.689250s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 120/478 | 25.10%\n",
      "[0:23:33.811049<1:09:31.326873, 0:00:11.684389s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 121/478 | 25.31%\n",
      "[0:23:45.183679<1:09:18.732548, 0:00:11.681833s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 122/478 | 25.52%\n",
      "[0:23:57.182410<1:09:07.965550, 0:00:11.684410s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 123/478 | 25.73%\n",
      "[0:24:06.936113<1:08:50.769360, 0:00:11.668840s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 124/478 | 25.94%\n",
      "[0:24:19.190299<1:08:40.753266, 0:00:11.673522s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 125/478 | 26.15%\n",
      "[0:24:30.405519<1:08:27.799520, 0:00:11.669885s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 126/478 | 26.36%\n",
      "[0:24:42.890922<1:08:18.383406, 0:00:11.676306s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 127/478 | 26.57%\n",
      "[0:24:56.496441<1:08:11.982300, 0:00:11.691378s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 128/478 | 26.78%\n",
      "[0:25:08.638632<1:08:01.510677, 0:00:11.694873s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 129/478 | 26.99%\n",
      "[0:25:22.059243<1:07:54.435504, 0:00:11.708148s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 130/478 | 27.20%\n",
      "[0:25:34.756299<1:07:45.346859, 0:00:11.715697s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 131/478 | 27.41%\n",
      "[0:25:48.342855<1:07:38.535020, 0:00:11.729870s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 132/478 | 27.62%\n",
      "[0:26:01.579525<1:07:30.713655, 0:00:11.741199s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 133/478 | 27.82%\n",
      "[0:26:11.536712<1:07:14.392784, 0:00:11.727886s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 134/478 | 28.03%\n",
      "[0:26:22.211342<1:06:59.988812, 0:00:11.720084s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 135/478 | 28.24%\n",
      "[0:26:34.271706<1:06:49.124412, 0:00:11.722586s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 136/478 | 28.45%\n",
      "[0:26:46.660962<1:06:39.061132, 0:00:11.727452s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 137/478 | 28.66%\n",
      "[0:26:57.084704<1:06:24.121700, 0:00:11.718005s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 138/478 | 28.87%\n",
      "[0:27:07.039309<1:06:08.103141, 0:00:11.705319s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 139/478 | 29.08%\n",
      "[0:27:18.353680<1:05:55.453788, 0:00:11.702526s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 140/478 | 29.29%\n",
      "[0:27:30.674331<1:05:45.228670, 0:00:11.706910s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 141/478 | 29.50%\n",
      "[0:27:41.442114<1:05:31.299792, 0:00:11.700297s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 142/478 | 29.71%\n",
      "[0:27:52.825902<1:05:18.857805, 0:00:11.698083s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 143/478 | 29.92%\n",
      "[0:28:02.818400<1:05:03.203826, 0:00:11.686239s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 144/478 | 30.13%\n",
      "[0:28:12.360886<1:04:46.594182, 0:00:11.671454s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 145/478 | 30.33%\n",
      "[0:28:22.970845<1:04:32.509088, 0:00:11.664184s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 146/478 | 30.54%\n",
      "[0:28:32.928542<1:04:17.002325, 0:00:11.652575s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 147/478 | 30.75%\n",
      "[0:28:43.788264<1:04:03.581940, 0:00:11.647218s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 148/478 | 30.96%\n",
      "[0:28:54.717314<1:03:50.348942, 0:00:11.642398s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 149/478 | 31.17%\n",
      "[0:29:08.321997<1:03:42.997440, 0:00:11.655480s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 150/478 | 31.38%\n",
      "[0:29:22.236104<1:03:36.233226, 0:00:11.670438s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 151/478 | 31.59%\n",
      "[0:29:34.789474<1:03:26.456522, 0:00:11.676247s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 152/478 | 31.80%\n",
      "[0:29:48.051419<1:03:18.148575, 0:00:11.686611s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 153/478 | 32.01%\n",
      "[0:30:01.629502<1:03:10.441332, 0:00:11.698893s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 154/478 | 32.22%\n",
      "[0:30:14.603223<1:03:01.399114, 0:00:11.707118s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 155/478 | 32.43%\n",
      "[0:30:25.743233<1:02:48.521204, 0:00:11.703482s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 156/478 | 32.64%\n",
      "[0:30:39.795917<1:02:41.620845, 0:00:11.718445s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 157/478 | 32.85%\n",
      "[0:30:52.635917<1:02:32.174080, 0:00:11.725544s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 158/478 | 33.05%\n",
      "[0:31:04.108878<1:02:19.941645, 0:00:11.723955s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 159/478 | 33.26%\n",
      "[0:31:15.697904<1:02:07.949616, 0:00:11.723112s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 160/478 | 33.47%\n",
      "[0:31:27.434680<1:01:56.253449, 0:00:11.723197s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 161/478 | 33.68%\n",
      "[0:31:36.825120<1:01:39.979852, 0:00:11.708797s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 162/478 | 33.89%\n",
      "[0:31:49.749063<1:01:30.619380, 0:00:11.716252s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 163/478 | 34.10%\n",
      "[0:32:01.899804<1:01:19.734914, 0:00:11.718901s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 164/478 | 34.31%\n",
      "[0:32:14.703685<1:01:10.074301, 0:00:11.725477s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 165/478 | 34.52%\n",
      "[0:32:24.683703<1:00:55.068144, 0:00:11.714962s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 166/478 | 34.73%\n",
      "[0:32:36.831866<1:00:44.159916, 0:00:11.717556s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 167/478 | 34.94%\n",
      "[0:32:47.771759<1:00:31.007370, 0:00:11.712927s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 168/478 | 35.15%\n",
      "[0:33:00.023654<1:00:20.279844, 0:00:11.716116s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 169/478 | 35.36%\n",
      "[0:33:10.058805<1:00:05.518224, 0:00:11.706228s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 170/478 | 35.56%\n",
      "[0:33:21.923018<0:59:54.095664, 0:00:11.707152s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 171/478 | 35.77%\n",
      "[0:33:36.001052<0:59:46.606416, 0:00:11.720936s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 172/478 | 35.98%\n",
      "[0:33:50.249242<0:59:39.341225, 0:00:11.735545s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 173/478 | 36.19%\n",
      "[0:34:00.717237<0:59:25.391040, 0:00:11.728260s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 174/478 | 36.40%\n",
      "[0:34:12.428035<0:59:13.632480, 0:00:11.728160s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 175/478 | 36.61%\n",
      "[0:34:23.143670<0:59:00.166914, 0:00:11.722407s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 176/478 | 36.82%\n",
      "[0:34:34.086222<0:58:47.118301, 0:00:11.718001s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 177/478 | 37.03%\n",
      "[0:34:45.464366<0:58:34.827600, 0:00:11.716092s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 178/478 | 37.24%\n",
      "[0:34:58.162270<0:58:24.751523, 0:00:11.721577s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 179/478 | 37.45%\n",
      "[0:35:09.428013<0:58:12.275410, 0:00:11.719045s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 180/478 | 37.66%\n",
      "[0:35:19.116101<0:57:57.223728, 0:00:11.707824s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 181/478 | 37.87%\n",
      "[0:35:31.166400<0:57:46.072680, 0:00:11.709705s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 182/478 | 38.08%\n",
      "[0:35:44.097012<0:57:36.331215, 0:00:11.716377s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 183/478 | 38.28%\n",
      "[0:35:56.435574<0:57:25.609146, 0:00:11.719759s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 184/478 | 38.49%\n",
      "[0:36:08.018378<0:57:13.672274, 0:00:11.719018s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 185/478 | 38.70%\n",
      "[0:36:20.750917<0:57:03.544364, 0:00:11.724467s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 186/478 | 38.91%\n",
      "[0:36:31.810233<0:56:50.784810, 0:00:11.720910s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 187/478 | 39.12%\n",
      "[0:36:44.070252<0:56:39.895620, 0:00:11.723778s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 188/478 | 39.33%\n",
      "[0:36:55.154172<0:56:27.193288, 0:00:11.720392s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 189/478 | 39.54%\n",
      "[0:37:07.072984<0:56:15.773856, 0:00:11.721437s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 190/478 | 39.75%\n",
      "[0:37:18.764379<0:56:04.007073, 0:00:11.721279s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 191/478 | 39.96%\n",
      "[0:37:30.702254<0:55:52.608688, 0:00:11.722408s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 192/478 | 40.17%\n",
      "[0:37:44.336807<0:55:43.709775, 0:00:11.732315s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 193/478 | 40.38%\n",
      "[0:37:57.590989<0:55:34.205440, 0:00:11.740160s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 194/478 | 40.59%\n",
      "[0:38:09.811985<0:55:23.163158, 0:00:11.742626s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 195/478 | 40.79%\n",
      "[0:38:25.378662<0:55:16.922352, 0:00:11.762136s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 196/478 | 41.00%\n",
      "[0:38:42.345727<0:55:12.584517, 0:00:11.788557s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 197/478 | 41.21%\n",
      "[0:38:55.636658<0:55:02.920600, 0:00:11.796145s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 198/478 | 41.42%\n",
      "[0:39:05.989740<0:54:49.101147, 0:00:11.788893s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 199/478 | 41.63%\n",
      "[0:39:15.921238<0:54:34.730468, 0:00:11.779606s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 200/478 | 41.84%\n",
      "[0:39:30.062616<0:54:26.205612, 0:00:11.791356s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 201/478 | 42.05%\n",
      "[0:39:41.422995<0:54:13.825548, 0:00:11.789223s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 202/478 | 42.26%\n",
      "[0:39:53.871925<0:54:02.930075, 0:00:11.792473s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 203/478 | 42.47%\n",
      "[0:40:06.510339<0:53:52.273606, 0:00:11.796619s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 204/478 | 42.68%\n",
      "[0:40:20.727817<0:53:43.700844, 0:00:11.808428s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 205/478 | 42.89%\n",
      "[0:40:31.950773<0:53:31.119392, 0:00:11.805586s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 206/478 | 43.10%\n",
      "[0:40:44.674243<0:53:20.515420, 0:00:11.810020s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 207/478 | 43.31%\n",
      "[0:40:57.273936<0:53:09.730590, 0:00:11.813817s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 208/478 | 43.51%\n",
      "[0:41:10.132236<0:52:59.261235, 0:00:11.818815s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 209/478 | 43.72%\n",
      "[0:41:20.320936<0:52:45.361936, 0:00:11.811052s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 210/478 | 43.93%\n",
      "[0:41:32.964602<0:52:34.604466, 0:00:11.814998s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 211/478 | 44.14%\n",
      "[0:41:45.939506<0:52:24.244754, 0:00:11.820469s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 212/478 | 44.35%\n",
      "[0:41:57.361439<0:52:11.928470, 0:00:11.818598s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 213/478 | 44.56%\n",
      "[0:42:09.876506<0:52:00.969192, 0:00:11.821853s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 214/478 | 44.77%\n",
      "[0:42:22.838246<0:51:50.541765, 0:00:11.827155s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 215/478 | 44.98%\n",
      "[0:42:32.808776<0:51:36.462458, 0:00:11.818559s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 216/478 | 45.19%\n",
      "[0:42:47.953167<0:51:28.644246, 0:00:11.833886s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 217/478 | 45.40%\n",
      "[0:42:58.428164<0:51:15.189520, 0:00:11.827652s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 218/478 | 45.61%\n",
      "[0:43:08.996045<0:51:01.872100, 0:00:11.821900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 219/478 | 45.82%\n",
      "[0:43:19.932456<0:50:49.011750, 0:00:11.817875s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 220/478 | 46.03%\n",
      "[0:43:33.906644<0:50:39.701424, 0:00:11.827632s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 221/478 | 46.23%\n",
      "[0:43:47.581918<0:50:30.004480, 0:00:11.835955s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 222/478 | 46.44%\n",
      "[0:44:00.801413<0:50:19.750545, 0:00:11.842159s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 223/478 | 46.65%\n",
      "[0:44:12.123838<0:50:07.319106, 0:00:11.839839s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 224/478 | 46.86%\n",
      "[0:44:23.452278<0:49:54.904198, 0:00:11.837566s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 225/478 | 47.07%\n",
      "[0:44:37.709860<0:49:45.765048, 0:00:11.848274s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 226/478 | 47.28%\n",
      "[0:44:55.542964<0:49:40.534389, 0:00:11.874639s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 227/478 | 47.49%\n",
      "[0:45:08.175121<0:49:29.490250, 0:00:11.877961s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 228/478 | 47.70%\n",
      "[0:45:19.681344<0:49:17.208162, 0:00:11.876338s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 229/478 | 47.91%\n",
      "[0:45:33.577503<0:49:07.509760, 0:00:11.885120s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 230/478 | 48.12%\n",
      "[0:45:47.602025<0:48:57.912107, 0:00:11.894381s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 231/478 | 48.33%\n",
      "[0:45:58.262674<0:48:44.709498, 0:00:11.889063s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 232/478 | 48.54%\n",
      "[0:46:09.890412<0:48:32.545790, 0:00:11.887942s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 233/478 | 48.74%\n",
      "[0:46:25.920978<0:48:24.977380, 0:00:11.905645s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 234/478 | 48.95%\n",
      "[0:46:38.270595<0:48:13.530762, 0:00:11.907534s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 235/478 | 49.16%\n",
      "[0:46:50.592717<0:48:02.048422, 0:00:11.909291s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 236/478 | 49.37%\n",
      "[0:47:01.378176<0:47:48.996309, 0:00:11.904549s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 237/478 | 49.58%\n",
      "[0:47:11.936741<0:47:35.734560, 0:00:11.898894s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 238/478 | 49.79%\n",
      "[0:47:22.618546<0:47:22.618439, 0:00:11.893801s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 239/478 | 50.00%\n",
      "[0:47:34.660187<0:47:10.871246, 0:00:11.894417s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 240/478 | 50.21%\n",
      "[0:47:44.557567<0:46:57.013047, 0:00:11.886131s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 241/478 | 50.42%\n",
      "[0:47:58.330611<0:46:46.967008, 0:00:11.893928s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 242/478 | 50.63%\n",
      "[0:48:09.552154<0:46:34.422835, 0:00:11.891161s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 243/478 | 50.84%\n",
      "[0:48:22.409631<0:46:23.458314, 0:00:11.895121s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 244/478 | 51.05%\n",
      "[0:48:33.388651<0:46:10.692006, 0:00:11.891382s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 245/478 | 51.26%\n",
      "[0:48:47.412684<0:46:00.812064, 0:00:11.900052s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 246/478 | 51.46%\n",
      "[0:49:00.602106<0:45:50.117832, 0:00:11.905272s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 247/478 | 51.67%\n",
      "[0:49:14.606639<0:45:40.159280, 0:00:11.913736s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 248/478 | 51.88%\n",
      "[0:49:30.025973<0:45:31.469635, 0:00:11.927815s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 249/478 | 52.09%\n",
      "[0:49:41.182227<0:45:18.838212, 0:00:11.924729s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 250/478 | 52.30%\n",
      "[0:49:52.798141<0:45:06.634273, 0:00:11.923499s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 251/478 | 52.51%\n",
      "[0:50:03.609067<0:44:53.712984, 0:00:11.919084s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 252/478 | 52.72%\n",
      "[0:50:14.143073<0:44:40.562025, 0:00:11.913609s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 253/478 | 52.93%\n",
      "[0:50:24.122098<0:44:26.942432, 0:00:11.905993s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 254/478 | 53.14%\n",
      "[0:50:37.927616<0:44:16.697566, 0:00:11.913442s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 255/478 | 53.35%\n",
      "[0:50:50.271883<0:44:05.157750, 0:00:11.915125s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 256/478 | 53.56%\n",
      "[0:51:02.444538<0:43:53.464067, 0:00:11.916127s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 257/478 | 53.77%\n",
      "[0:51:14.406232<0:43:41.586660, 0:00:11.916303s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 258/478 | 53.97%\n",
      "[0:51:30.616079<0:43:33.300939, 0:00:11.932881s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 259/478 | 54.18%\n",
      "[0:51:43.611991<0:43:22.259242, 0:00:11.936969s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 260/478 | 54.39%\n",
      "[0:51:56.024310<0:43:10.717430, 0:00:11.938790s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 261/478 | 54.60%\n",
      "[0:52:10.478416<0:43:00.852456, 0:00:11.948391s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 262/478 | 54.81%\n",
      "[0:52:22.279053<0:42:48.783235, 0:00:11.947829s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 263/478 | 55.02%\n",
      "[0:52:37.078592<0:42:39.147034, 0:00:11.958631s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 264/478 | 55.23%\n",
      "[0:52:51.320314<0:42:29.023398, 0:00:11.967246s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 265/478 | 55.44%\n",
      "[0:53:03.939500<0:42:17.575764, 0:00:11.969697s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 266/478 | 55.65%\n",
      "[0:53:16.184369<0:42:05.823608, 0:00:11.970728s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 267/478 | 55.86%\n",
      "[0:53:28.077735<0:41:53.792190, 0:00:11.970439s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 268/478 | 56.07%\n",
      "[0:53:40.959399<0:41:42.529843, 0:00:11.973827s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 269/478 | 56.28%\n",
      "[0:53:53.054596<0:41:30.649408, 0:00:11.974276s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 270/478 | 56.49%\n",
      "[0:54:06.072154<0:41:19.472082, 0:00:11.978126s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 271/478 | 56.69%\n",
      "[0:54:20.005360<0:41:08.974684, 0:00:11.985314s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 272/478 | 56.90%\n",
      "[0:54:33.327368<0:40:57.993050, 0:00:11.990210s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 273/478 | 57.11%\n",
      "[0:54:44.186517<0:40:45.160728, 0:00:11.986082s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 274/478 | 57.32%\n",
      "[0:54:55.934101<0:40:32.998645, 0:00:11.985215s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 275/478 | 57.53%\n",
      "[0:55:06.321321<0:40:19.843850, 0:00:11.979425s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 276/478 | 57.74%\n",
      "[0:55:16.593914<0:40:06.625863, 0:00:11.973263s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 277/478 | 57.95%\n",
      "[0:55:27.035256<0:39:53.550600, 0:00:11.967753s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 278/478 | 58.16%\n",
      "[0:55:37.393259<0:39:40.434617, 0:00:11.961983s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 279/478 | 58.37%\n",
      "[0:55:47.760748<0:39:27.345024, 0:00:11.956288s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 280/478 | 58.58%\n",
      "[0:56:00.892512<0:39:16.212984, 0:00:11.960472s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 281/478 | 58.79%\n",
      "[0:56:13.662602<0:39:04.815228, 0:00:11.963343s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 282/478 | 59.00%\n",
      "[0:56:25.337656<0:38:52.653180, 0:00:11.962324s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 283/478 | 59.21%\n",
      "[0:56:36.817137<0:38:40.361056, 0:00:11.960624s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 284/478 | 59.41%\n",
      "[0:56:49.876350<0:38:29.144254, 0:00:11.964478s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 285/478 | 59.62%\n",
      "[0:57:01.070352<0:38:16.662528, 0:00:11.961784s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 286/478 | 59.83%\n",
      "[0:57:14.844053<0:38:05.906718, 0:00:11.968098s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 287/478 | 60.04%\n",
      "[0:57:25.833802<0:37:53.293190, 0:00:11.964701s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 288/478 | 60.25%\n",
      "[0:57:35.353285<0:37:39.729360, 0:00:11.956240s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 289/478 | 60.46%\n",
      "[0:57:47.712690<0:37:28.034440, 0:00:11.957630s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 290/478 | 60.67%\n",
      "[0:58:00.009182<0:37:16.294478, 0:00:11.958794s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 291/478 | 60.88%\n",
      "[0:58:12.058159<0:37:04.393158, 0:00:11.959103s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 292/478 | 61.09%\n",
      "[0:58:24.798257<0:36:52.927265, 0:00:11.961769s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 293/478 | 61.30%\n",
      "[0:58:36.933721<0:36:41.074240, 0:00:11.962360s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 294/478 | 61.51%\n",
      "[0:58:48.502016<0:36:28.867392, 0:00:11.961024s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 295/478 | 61.72%\n",
      "[0:59:02.122574<0:36:17.926660, 0:00:11.966630s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 296/478 | 61.92%\n",
      "[0:59:13.076165<0:36:05.342639, 0:00:11.963219s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 297/478 | 62.13%\n",
      "[0:59:23.324004<0:35:52.343340, 0:00:11.957463s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 298/478 | 62.34%\n",
      "[0:59:34.591772<0:35:39.972924, 0:00:11.955156s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 299/478 | 62.55%\n",
      "[0:59:48.925695<0:35:29.429308, 0:00:11.963086s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 300/478 | 62.76%\n",
      "[1:00:02.445164<0:35:18.381312, 0:00:11.968256s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 301/478 | 62.97%\n",
      "[1:00:12.183305<0:35:05.113472, 0:00:11.960872s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 302/478 | 63.18%\n",
      "[1:00:22.772314<0:34:52.360200, 0:00:11.956344s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 303/478 | 63.39%\n",
      "[1:00:34.191885<0:34:40.096746, 0:00:11.954579s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 304/478 | 63.60%\n",
      "[1:00:46.661722<0:34:28.434364, 0:00:11.956268s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 305/478 | 63.81%\n",
      "[1:00:56.933998<0:34:15.531580, 0:00:11.950765s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 306/478 | 64.02%\n",
      "[1:01:06.920953<0:34:02.486928, 0:00:11.944368s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 307/478 | 64.23%\n",
      "[1:01:18.605012<0:33:50.398910, 0:00:11.943523s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 308/478 | 64.44%\n",
      "[1:01:31.787675<0:33:39.133077, 0:00:11.947533s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 309/478 | 64.64%\n",
      "[1:01:42.463837<0:33:26.496576, 0:00:11.943432s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 310/478 | 64.85%\n",
      "[1:01:53.569725<0:33:14.103413, 0:00:11.940739s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 311/478 | 65.06%\n",
      "[1:02:05.677658<0:33:02.251650, 0:00:11.941275s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 312/478 | 65.27%\n",
      "[1:02:19.053998<0:32:51.066735, 0:00:11.945859s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 313/478 | 65.48%\n",
      "[1:02:29.700744<0:32:38.442408, 0:00:11.941722s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 314/478 | 65.69%\n",
      "[1:02:43.725096<0:32:27.578442, 0:00:11.948334s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 315/478 | 65.90%\n",
      "[1:02:54.079245<0:32:14.812818, 0:00:11.943289s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 316/478 | 66.11%\n",
      "[1:03:04.136341<0:32:01.911579, 0:00:11.937339s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 317/478 | 66.32%\n",
      "[1:03:17.560358<0:31:50.722240, 0:00:11.942014s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 318/478 | 66.53%\n",
      "[1:03:27.436198<0:31:37.750383, 0:00:11.935537s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 319/478 | 66.74%\n",
      "[1:03:38.651298<0:31:25.459030, 0:00:11.933285s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 320/478 | 66.95%\n",
      "[1:03:50.320968<0:31:13.396848, 0:00:11.932464s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 321/478 | 67.15%\n",
      "[1:04:03.129512<0:31:01.888860, 0:00:11.935185s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 322/478 | 67.36%\n",
      "[1:04:16.253721<0:30:50.524230, 0:00:11.938866s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 323/478 | 67.57%\n",
      "[1:04:27.420210<0:30:38.218228, 0:00:11.936482s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 324/478 | 67.78%\n",
      "[1:04:39.310912<0:30:26.260173, 0:00:11.936341s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 325/478 | 67.99%\n",
      "[1:04:49.231473<0:30:13.384016, 0:00:11.930158s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 326/478 | 68.20%\n",
      "[1:05:00.579536<0:30:01.185078, 0:00:11.928378s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 327/478 | 68.41%\n",
      "[1:05:10.881663<0:29:48.513000, 0:00:11.923420s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 328/478 | 68.62%\n",
      "[1:05:23.870807<0:29:37.072191, 0:00:11.926659s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 329/478 | 68.83%\n",
      "[1:05:36.724574<0:29:25.561264, 0:00:11.929468s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 330/478 | 69.04%\n",
      "[1:05:46.783063<0:29:12.800952, 0:00:11.923816s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 331/478 | 69.25%\n",
      "[1:05:59.591244<0:29:01.266080, 0:00:11.926480s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 332/478 | 69.46%\n",
      "[1:06:10.151822<0:28:48.744810, 0:00:11.922378s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 333/478 | 69.67%\n",
      "[1:06:20.379434<0:28:36.091776, 0:00:11.917304s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 334/478 | 69.87%\n",
      "[1:06:30.124221<0:28:23.247117, 0:00:11.910819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 335/478 | 70.08%\n",
      "[1:06:40.983892<0:28:10.891980, 0:00:11.907690s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 336/478 | 70.29%\n",
      "[1:06:53.394364<0:27:59.194662, 0:00:11.909182s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 337/478 | 70.50%\n",
      "[1:07:04.365714<0:27:46.896980, 0:00:11.906407s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 338/478 | 70.71%\n",
      "[1:07:17.124700<0:27:35.340158, 0:00:11.908922s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 339/478 | 70.92%\n",
      "[1:07:30.411625<0:27:23.990550, 0:00:11.912975s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 340/478 | 71.13%\n",
      "[1:07:44.541015<0:27:12.968075, 0:00:11.919475s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 341/478 | 71.34%\n",
      "[1:07:55.354452<0:27:00.608776, 0:00:11.916241s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 342/478 | 71.55%\n",
      "[1:08:07.192866<0:26:48.661890, 0:00:11.916014s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 343/478 | 71.76%\n",
      "[1:08:18.140295<0:26:36.368666, 0:00:11.913199s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 344/478 | 71.97%\n",
      "[1:08:31.530963<0:26:25.024973, 0:00:11.917481s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 345/478 | 72.18%\n",
      "[1:08:41.136842<0:26:12.225600, 0:00:11.910800s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 346/478 | 72.38%\n",
      "[1:08:53.554930<0:26:00.506322, 0:00:11.912262s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 347/478 | 72.59%\n",
      "[1:09:05.151252<0:25:48.476020, 0:00:11.911354s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 348/478 | 72.80%\n",
      "[1:09:15.445373<0:25:35.966880, 0:00:11.906720s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 349/478 | 73.01%\n",
      "[1:09:26.693414<0:25:23.819264, 0:00:11.904838s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 350/478 | 73.22%\n",
      "[1:09:40.498839<0:25:12.602131, 0:00:11.910253s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 351/478 | 73.43%\n",
      "[1:09:50.845401<0:25:00.132186, 0:00:11.905811s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 352/478 | 73.64%\n",
      "[1:10:00.896621<0:24:47.569625, 0:00:11.900557s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 353/478 | 73.85%\n",
      "[1:10:10.541535<0:24:34.878940, 0:00:11.894185s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 354/478 | 74.06%\n",
      "[1:10:21.841131<0:24:22.778730, 0:00:11.892510s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 355/478 | 74.27%\n",
      "[1:10:33.335959<0:24:10.749946, 0:00:11.891393s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 356/478 | 74.48%\n",
      "[1:10:45.887552<0:23:59.082282, 0:00:11.893242s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 357/478 | 74.69%\n",
      "[1:10:59.171118<0:23:47.655120, 0:00:11.897126s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 358/478 | 74.90%\n",
      "[1:11:09.150708<0:23:35.122415, 0:00:11.891785s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 359/478 | 75.10%\n",
      "[1:11:23.496205<0:23:24.034918, 0:00:11.898601s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 360/478 | 75.31%\n",
      "[1:11:34.895275<0:23:11.974389, 0:00:11.897217s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 361/478 | 75.52%\n",
      "[1:11:47.807067<0:23:00.402320, 0:00:11.900020s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 362/478 | 75.73%\n",
      "[1:11:58.562933<0:22:48.139820, 0:00:11.896868s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 363/478 | 75.94%\n",
      "[1:12:10.545743<0:22:36.269856, 0:00:11.897104s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 364/478 | 76.15%\n",
      "[1:12:20.564991<0:22:23.791367, 0:00:11.891959s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 365/478 | 76.36%\n",
      "[1:12:32.621744<0:22:11.949808, 0:00:11.892409s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 366/478 | 76.57%\n",
      "[1:12:42.002208<0:21:59.297715, 0:00:11.885565s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 367/478 | 76.78%\n",
      "[1:12:52.902846<0:21:47.117680, 0:00:11.882888s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 368/478 | 76.99%\n",
      "[1:13:02.862690<0:21:34.666793, 0:00:11.877677s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 369/478 | 77.20%\n",
      "[1:13:15.650660<0:21:23.054796, 0:00:11.880137s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 370/478 | 77.41%\n",
      "[1:13:25.590668<0:21:10.615049, 0:00:11.874907s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 371/478 | 77.62%\n",
      "[1:13:36.420249<0:20:58.442282, 0:00:11.872097s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 372/478 | 77.82%\n",
      "[1:13:49.395449<0:20:46.880775, 0:00:11.875055s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 373/478 | 78.03%\n",
      "[1:14:03.232458<0:20:35.551304, 0:00:11.880301s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 374/478 | 78.24%\n",
      "[1:14:15.988270<0:20:23.911405, 0:00:11.882635s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 375/478 | 78.45%\n",
      "[1:14:28.886690<0:20:12.304374, 0:00:11.885337s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 376/478 | 78.66%\n",
      "[1:14:39.674286<0:20:00.124925, 0:00:11.882425s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 377/478 | 78.87%\n",
      "[1:14:51.163247<0:19:48.138400, 0:00:11.881384s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 378/478 | 79.08%\n",
      "[1:15:05.376716<0:19:36.866262, 0:00:11.887538s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 379/478 | 79.29%\n",
      "[1:15:15.349596<0:19:24.484902, 0:00:11.882499s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 380/478 | 79.50%\n",
      "[1:15:27.796798<0:19:12.746157, 0:00:11.883981s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 381/478 | 79.71%\n",
      "[1:15:42.131777<0:19:01.478112, 0:00:11.890397s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 382/478 | 79.92%\n",
      "[1:15:51.592561<0:18:48.985130, 0:00:11.884054s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 383/478 | 80.13%\n",
      "[1:16:05.953187<0:18:37.707282, 0:00:11.890503s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 384/478 | 80.33%\n",
      "[1:16:15.474436<0:18:25.244457, 0:00:11.884349s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 385/478 | 80.54%\n",
      "[1:16:27.405271<0:18:13.371240, 0:00:11.884470s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 386/478 | 80.75%\n",
      "[1:16:39.006590<0:18:01.420158, 0:00:11.883738s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 387/478 | 80.96%\n",
      "[1:16:51.368449<0:17:49.647300, 0:00:11.884970s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 388/478 | 81.17%\n",
      "[1:17:02.023078<0:17:37.480823, 0:00:11.881807s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 389/478 | 81.38%\n",
      "[1:17:12.031610<0:17:25.176352, 0:00:11.877004s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 390/478 | 81.59%\n",
      "[1:17:22.722310<0:17:13.035390, 0:00:11.873970s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 391/478 | 81.80%\n",
      "[1:17:34.388332<0:17:01.115840, 0:00:11.873440s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 392/478 | 82.01%\n",
      "[1:17:48.152976<0:16:49.651420, 0:00:11.878252s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 393/478 | 82.22%\n",
      "[1:18:00.107773<0:16:37.789464, 0:00:11.878446s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 394/478 | 82.43%\n",
      "[1:18:11.760702<0:16:25.863625, 0:00:11.877875s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 395/478 | 82.64%\n",
      "[1:18:23.093512<0:16:13.872918, 0:00:11.876499s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 396/478 | 82.85%\n",
      "[1:18:33.408909<0:16:01.677927, 0:00:11.872567s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 397/478 | 83.05%\n",
      "[1:18:43.346764<0:15:49.416400, 0:00:11.867705s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 398/478 | 83.26%\n",
      "[1:18:56.093097<0:15:37.722732, 0:00:11.869908s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 399/478 | 83.47%\n",
      "[1:19:09.092368<0:15:26.073018, 0:00:11.872731s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 400/478 | 83.68%\n",
      "[1:19:22.193137<0:15:14.436061, 0:00:11.875793s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 401/478 | 83.89%\n",
      "[1:19:34.163413<0:15:02.578128, 0:00:11.876028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 402/478 | 84.10%\n",
      "[1:19:47.959691<0:14:51.059475, 0:00:11.880793s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 403/478 | 84.31%\n",
      "[1:19:58.615119<0:14:38.954240, 0:00:11.877760s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 404/478 | 84.52%\n",
      "[1:20:08.924531<0:14:26.793824, 0:00:11.873888s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 405/478 | 84.73%\n",
      "[1:20:22.777587<0:14:15.270936, 0:00:11.878763s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 406/478 | 84.94%\n",
      "[1:20:35.493204<0:14:03.538149, 0:00:11.880819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 407/478 | 85.15%\n",
      "[1:20:45.356177<0:13:51.311110, 0:00:11.875873s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 408/478 | 85.36%\n",
      "[1:20:57.719694<0:13:39.517485, 0:00:11.877065s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 409/478 | 85.56%\n",
      "[1:21:09.271221<0:13:27.586428, 0:00:11.876271s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 410/478 | 85.77%\n",
      "[1:21:19.404957<0:13:15.426144, 0:00:11.872032s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 411/478 | 85.98%\n",
      "[1:21:33.891459<0:13:03.972882, 0:00:11.878377s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 412/478 | 86.19%\n",
      "[1:21:46.584523<0:12:52.222750, 0:00:11.880350s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 413/478 | 86.40%\n",
      "[1:21:58.501301<0:12:40.348032, 0:00:11.880438s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 414/478 | 86.61%\n",
      "[1:22:14.349354<0:12:29.069874, 0:00:11.889998s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 415/478 | 86.82%\n",
      "[1:22:27.675097<0:12:17.393900, 0:00:11.893450s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 416/478 | 87.03%\n",
      "[1:22:40.475804<0:12:05.633125, 0:00:11.895625s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 417/478 | 87.24%\n",
      "[1:22:52.251036<0:11:53.720220, 0:00:11.895337s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 418/478 | 87.45%\n",
      "[1:23:02.952842<0:11:41.656851, 0:00:11.892489s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 419/478 | 87.66%\n",
      "[1:23:13.926357<0:11:29.637458, 0:00:11.890301s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 420/478 | 87.87%\n",
      "[1:23:23.456250<0:11:17.427558, 0:00:11.884694s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 421/478 | 88.08%\n",
      "[1:23:36.550353<0:11:05.703360, 0:00:11.887560s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 422/478 | 88.28%\n",
      "[1:23:46.297538<0:10:53.537500, 0:00:11.882500s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 423/478 | 88.49%\n",
      "[1:23:55.777936<0:10:41.349090, 0:00:11.876835s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 424/478 | 88.70%\n",
      "[1:24:07.554787<0:10:29.459747, 0:00:11.876599s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 425/478 | 88.91%\n",
      "[1:24:17.088810<0:10:17.297200, 0:00:11.871100s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 426/478 | 89.12%\n",
      "[1:24:30.427961<0:10:05.601489, 0:00:11.874539s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 427/478 | 89.33%\n",
      "[1:24:40.407947<0:09:53.505600, 0:00:11.870112s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 428/478 | 89.54%\n",
      "[1:24:50.087213<0:09:41.385245, 0:00:11.865005s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 429/478 | 89.75%\n",
      "[1:25:00.516496<0:09:29.359968, 0:00:11.861666s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 430/478 | 89.96%\n",
      "[1:25:13.376498<0:09:17.607201, 0:00:11.863983s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 431/478 | 90.17%\n",
      "[1:25:25.079172<0:09:05.726014, 0:00:11.863609s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 432/478 | 90.38%\n",
      "[1:25:34.605932<0:08:53.619540, 0:00:11.858212s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 433/478 | 90.59%\n",
      "[1:25:44.113190<0:08:41.522980, 0:00:11.852795s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 434/478 | 90.79%\n",
      "[1:25:56.932354<0:08:29.765731, 0:00:11.855017s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 435/478 | 91.00%\n",
      "[1:26:10.497069<0:08:18.075396, 0:00:11.858938s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 436/478 | 91.21%\n",
      "[1:26:23.117731<0:08:06.287921, 0:00:11.860681s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 437/478 | 91.42%\n",
      "[1:26:34.419273<0:07:54.376200, 0:00:11.859405s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 438/478 | 91.63%\n",
      "[1:26:47.307903<0:07:42.608211, 0:00:11.861749s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 439/478 | 91.84%\n",
      "[1:26:58.444866<0:07:30.683876, 0:00:11.860102s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 440/478 | 92.05%\n",
      "[1:27:09.185134<0:07:18.729831, 0:00:11.857563s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 441/478 | 92.26%\n",
      "[1:27:23.119420<0:07:07.041396, 0:00:11.862261s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 442/478 | 92.47%\n",
      "[1:27:37.709717<0:06:55.394665, 0:00:11.868419s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 443/478 | 92.68%\n",
      "[1:27:46.585662<0:06:43.297086, 0:00:11.861679s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 444/478 | 92.89%\n",
      "[1:27:55.404078<0:06:31.209753, 0:00:11.854841s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 445/478 | 93.10%\n",
      "[1:28:10.185183<0:06:19.564864, 0:00:11.861402s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 446/478 | 93.31%\n",
      "[1:28:20.228914<0:06:07.577385, 0:00:11.857335s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 447/478 | 93.51%\n",
      "[1:28:32.828372<0:05:55.769760, 0:00:11.858992s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 448/478 | 93.72%\n",
      "[1:28:45.623064<0:05:43.971204, 0:00:11.861076s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 449/478 | 93.93%\n",
      "[1:28:57.775206<0:05:32.128244, 0:00:11.861723s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 450/478 | 94.14%\n",
      "[1:29:09.489173<0:05:20.257665, 0:00:11.861395s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 451/478 | 94.35%\n",
      "[1:29:21.496138<0:05:08.404642, 0:00:11.861717s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 452/478 | 94.56%\n",
      "[1:29:32.451363<0:04:56.492900, 0:00:11.859716s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 453/478 | 94.77%\n",
      "[1:29:44.419851<0:04:44.638944, 0:00:11.859956s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 454/478 | 94.98%\n",
      "[1:29:56.739273<0:04:32.802195, 0:00:11.860965s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 455/478 | 95.19%\n",
      "[1:30:11.353859<0:04:21.074088, 0:00:11.867004s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 456/478 | 95.40%\n",
      "[1:30:23.328808<0:04:09.212040, 0:00:11.867240s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 457/478 | 95.61%\n",
      "[1:30:34.613857<0:03:57.319380, 0:00:11.865969s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 458/478 | 95.82%\n",
      "[1:30:50.482573<0:03:45.619110, 0:00:11.874690s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 459/478 | 96.03%\n",
      "[1:31:02.531358<0:03:33.751224, 0:00:11.875068s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 460/478 | 96.23%\n",
      "[1:31:16.942354<0:03:21.969673, 0:00:11.880569s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 461/478 | 96.44%\n",
      "[1:31:29.122147<0:03:10.099472, 0:00:11.881217s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 462/478 | 96.65%\n",
      "[1:31:39.925100<0:02:58.183320, 0:00:11.878888s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 463/478 | 96.86%\n",
      "[1:31:54.278980<0:02:46.379108, 0:00:11.884222s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 464/478 | 97.07%\n",
      "[1:32:05.919019<0:02:34.488061, 0:00:11.883697s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 465/478 | 97.28%\n",
      "[1:32:17.054812<0:02:22.585104, 0:00:11.882092s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 466/478 | 97.49%\n",
      "[1:32:26.695483<0:02:10.650212, 0:00:11.877292s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 467/478 | 97.70%\n",
      "[1:32:40.288182<0:01:58.809580, 0:00:11.880958s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 468/478 | 97.91%\n",
      "[1:32:51.376976<0:01:46.913421, 0:00:11.879269s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 469/478 | 98.12%\n",
      "[1:33:00.300426<0:01:34.983840, 0:00:11.872980s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 470/478 | 98.33%\n",
      "[1:33:09.905206<0:01:23.077148, 0:00:11.868164s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 471/478 | 98.54%\n",
      "[1:33:20.806295<0:01:11.196690, 0:00:11.866115s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 472/478 | 98.74%\n",
      "[1:33:34.390352<0:00:59.348735, 0:00:11.869747s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 473/478 | 98.95%\n",
      "[1:33:43.907371<0:00:47.459132, 0:00:11.864783s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 474/478 | 99.16%\n",
      "[1:33:57.555130<0:00:35.605611, 0:00:11.868537s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 475/478 | 99.37%\n",
      "[1:34:07.932826<0:00:23.730810, 0:00:11.865405s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 476/478 | 99.58%\n",
      "[1:34:20.337906<0:00:11.866536, 0:00:11.866536s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 477/478 | 99.79%\n",
      "[1:34:30.434481<0:00:00, 0:00:11.862834s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 2: 478/478 | 100.00%\n",
      "[0:00:00.000208<0:00:00.099216, 0:00:00.000208s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 1/478 | 0.21%\n",
      "[0:00:16.530874<1:05:34.348012, 0:00:08.265437s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 2/478 | 0.42%\n",
      "[0:00:32.729805<1:26:22.219125, 0:00:10.909935s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 3/478 | 0.63%\n",
      "[0:00:44.459932<1:27:48.501942, 0:00:11.114983s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 4/478 | 0.84%\n",
      "[0:00:56.172122<1:28:33.882552, 0:00:11.234424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 5/478 | 1.05%\n",
      "[0:01:08.654602<1:30:00.828848, 0:00:11.442434s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 6/478 | 1.26%\n",
      "[0:01:26.998509<1:37:33.756618, 0:00:12.428358s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 7/478 | 1.46%\n",
      "[0:01:44.596408<1:42:25.038970, 0:00:13.074551s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 8/478 | 1.67%\n",
      "[0:02:04.009011<1:47:42.247351, 0:00:13.778779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 9/478 | 1.88%\n",
      "[0:02:23.307761<1:51:46.803168, 0:00:14.330776s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 10/478 | 2.09%\n",
      "[0:02:39.947288<1:53:10.489621, 0:00:14.540663s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 11/478 | 2.30%\n",
      "[0:02:54.689504<1:53:03.775894, 0:00:14.557459s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 12/478 | 2.51%\n",
      "[0:03:12.052934<1:54:29.585895, 0:00:14.773303s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 13/478 | 2.72%\n",
      "[0:03:26.367440<1:53:59.606384, 0:00:14.740531s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 14/478 | 2.93%\n",
      "[0:03:43.445718<1:54:57.024403, 0:00:14.896381s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 15/478 | 3.14%\n",
      "[0:03:59.871452<1:55:26.288292, 0:00:14.991966s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 16/478 | 3.35%\n",
      "[0:04:14.515939<1:55:01.873486, 0:00:14.971526s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 17/478 | 3.56%\n",
      "[0:04:32.263313<1:55:57.840400, 0:00:15.125740s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 18/478 | 3.77%\n",
      "[0:04:48.114714<1:56:00.244788, 0:00:15.163932s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 19/478 | 3.97%\n",
      "[0:05:03.356503<1:55:46.863850, 0:00:15.167825s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 20/478 | 4.18%\n",
      "[0:05:32.882878<2:00:44.165662, 0:00:15.851566s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 21/478 | 4.39%\n",
      "[0:05:51.015289<2:01:15.589440, 0:00:15.955240s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 22/478 | 4.60%\n",
      "[0:06:04.505071<2:00:10.861385, 0:00:15.848047s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 23/478 | 4.81%\n",
      "[0:06:20.016237<1:59:48.640540, 0:00:15.834010s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 24/478 | 5.02%\n",
      "[0:06:40.964347<2:01:05.474022, 0:00:16.038574s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 25/478 | 5.23%\n",
      "[0:06:52.852256<1:59:37.277716, 0:00:15.878933s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 26/478 | 5.44%\n",
      "[0:07:07.333399<1:58:58.050513, 0:00:15.827163s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 27/478 | 5.65%\n",
      "[0:07:18.833000<1:57:32.673150, 0:00:15.672607s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 28/478 | 5.86%\n",
      "[0:07:32.041801<1:56:38.853952, 0:00:15.587648s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 29/478 | 6.07%\n",
      "[0:07:43.768557<1:55:25.610496, 0:00:15.458952s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 30/478 | 6.28%\n",
      "[0:08:02.884937<1:56:02.889051, 0:00:15.576933s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 31/478 | 6.49%\n",
      "[0:08:23.735542<1:57:00.814256, 0:00:15.741736s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 32/478 | 6.69%\n",
      "[0:08:39.266829<1:56:42.234310, 0:00:15.735358s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 33/478 | 6.90%\n",
      "[0:08:52.936035<1:55:59.517516, 0:00:15.674589s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 34/478 | 7.11%\n",
      "[0:09:08.865307<1:55:47.066638, 0:00:15.681866s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 35/478 | 7.32%\n",
      "[0:09:37.430716<1:58:09.565964, 0:00:16.039742s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 36/478 | 7.53%\n",
      "[0:09:54.397469<1:58:04.575036, 0:00:16.064796s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 37/478 | 7.74%\n",
      "[0:10:15.447621<1:58:46.235600, 0:00:16.195990s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 38/478 | 7.95%\n",
      "[0:10:31.684603<1:58:30.500999, 0:00:16.197041s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 39/478 | 8.16%\n",
      "[0:10:49.301277<1:58:29.849016, 0:00:16.232532s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 40/478 | 8.37%\n",
      "[0:11:05.836986<1:58:16.847662, 0:00:16.239926s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 41/478 | 8.58%\n",
      "[0:11:17.069902<1:57:08.630432, 0:00:16.120712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 42/478 | 8.79%\n",
      "[0:11:31.204706<1:56:32.419680, 0:00:16.074528s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 43/478 | 9.00%\n",
      "[0:11:48.549773<1:56:28.877336, 0:00:16.103404s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 44/478 | 9.21%\n",
      "[0:12:04.356872<1:56:09.922627, 0:00:16.096819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 45/478 | 9.41%\n",
      "[0:12:16.225612<1:55:14.118960, 0:00:16.004905s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 46/478 | 9.62%\n",
      "[0:12:31.945544<1:54:55.500471, 0:00:15.998841s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 47/478 | 9.83%\n",
      "[0:12:47.114288<1:54:32.065640, 0:00:15.981548s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 48/478 | 10.04%\n",
      "[0:12:58.823747<1:53:38.681298, 0:00:15.894362s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 49/478 | 10.25%\n",
      "[0:13:14.237097<1:53:18.669576, 0:00:15.884742s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 50/478 | 10.46%\n",
      "[0:13:33.379605<1:53:30.060740, 0:00:15.948620s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 51/478 | 10.67%\n",
      "[0:13:45.088255<1:52:39.376932, 0:00:15.867082s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 52/478 | 10.88%\n",
      "[0:14:05.638020<1:53:01.059450, 0:00:15.955434s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 53/478 | 11.09%\n",
      "[0:14:16.982769<1:52:08.901624, 0:00:15.870051s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 54/478 | 11.30%\n",
      "[0:14:43.195375<1:53:12.575454, 0:00:16.058098s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 55/478 | 11.51%\n",
      "[0:14:55.945399<1:52:31.588550, 0:00:15.999025s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 56/478 | 11.72%\n",
      "[0:15:15.636586<1:52:42.859800, 0:00:16.063800s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 57/478 | 11.92%\n",
      "[0:15:34.631757<1:52:48.023220, 0:00:16.114341s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 58/478 | 12.13%\n",
      "[0:15:49.444256<1:52:22.663644, 0:00:16.092276s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 59/478 | 12.34%\n",
      "[0:16:02.742670<1:51:47.107198, 0:00:16.045711s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 60/478 | 12.55%\n",
      "[0:16:19.724127<1:51:37.458267, 0:00:16.061051s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 61/478 | 12.76%\n",
      "[0:16:39.922213<1:51:49.155648, 0:00:16.127778s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 62/478 | 12.97%\n",
      "[0:16:56.566869<1:51:36.432530, 0:00:16.135982s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 63/478 | 13.18%\n",
      "[0:17:19.845706<1:52:06.501846, 0:00:16.247589s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 64/478 | 13.39%\n",
      "[0:17:38.677266<1:52:06.672659, 0:00:16.287343s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 65/478 | 13.60%\n",
      "[0:17:55.747151<1:51:55.269988, 0:00:16.299199s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 66/478 | 13.81%\n",
      "[0:18:14.290823<1:51:52.739289, 0:00:16.332699s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 67/478 | 14.02%\n",
      "[0:18:43.814333<1:52:55.939210, 0:00:16.526681s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 68/478 | 14.23%\n",
      "[0:19:10.663146<1:53:40.597293, 0:00:16.676277s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 69/478 | 14.44%\n",
      "[0:19:28.190704<1:53:28.883112, 0:00:16.688439s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 70/478 | 14.64%\n",
      "[0:19:46.223763<1:53:19.902439, 0:00:16.707377s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 71/478 | 14.85%\n",
      "[0:20:05.413932<1:53:17.195160, 0:00:16.741860s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 72/478 | 15.06%\n",
      "[0:20:23.069433<1:53:05.522280, 0:00:16.754376s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 73/478 | 15.27%\n",
      "[0:20:34.809829<1:52:21.394076, 0:00:16.686619s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 74/478 | 15.48%\n",
      "[0:20:48.447947<1:51:48.327119, 0:00:16.645973s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 75/478 | 15.69%\n",
      "[0:21:02.065246<1:51:15.661044, 0:00:16.606122s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 76/478 | 15.90%\n",
      "[0:21:20.605898<1:51:09.129245, 0:00:16.631245s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 77/478 | 16.11%\n",
      "[0:21:34.975007<1:50:40.897600, 0:00:16.602244s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 78/478 | 16.32%\n",
      "[0:21:49.059684<1:50:11.580024, 0:00:16.570376s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 79/478 | 16.53%\n",
      "[0:22:08.219802<1:50:07.893704, 0:00:16.602748s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 80/478 | 16.74%\n",
      "[0:22:24.834328<1:49:51.348521, 0:00:16.602893s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 81/478 | 16.95%\n",
      "[0:22:43.805495<1:49:46.182504, 0:00:16.631774s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 82/478 | 17.15%\n",
      "[0:22:56.564909<1:49:11.122005, 0:00:16.585119s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 83/478 | 17.36%\n",
      "[0:23:12.249621<1:48:50.313600, 0:00:16.574400s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 84/478 | 17.57%\n",
      "[0:23:23.732522<1:48:10.198500, 0:00:16.514500s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 85/478 | 17.78%\n",
      "[0:23:35.556799<1:47:32.305496, 0:00:16.459963s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 86/478 | 17.99%\n",
      "[0:23:47.249498<1:46:54.420297, 0:00:16.405167s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 87/478 | 18.20%\n",
      "[0:24:03.997458<1:46:39.534180, 0:00:16.409062s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 88/478 | 18.41%\n",
      "[0:24:16.242894<1:46:04.926920, 0:00:16.362280s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 89/478 | 18.62%\n",
      "[0:24:28.154147<1:45:29.375712, 0:00:16.312824s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 90/478 | 18.83%\n",
      "[0:24:39.176825<1:44:50.565030, 0:00:16.254690s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 91/478 | 19.04%\n",
      "[0:24:50.638003<1:44:14.198582, 0:00:16.202587s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 92/478 | 19.25%\n",
      "[0:25:08.097463<1:44:03.199270, 0:00:16.216102s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 93/478 | 19.46%\n",
      "[0:25:25.142134<1:43:50.367744, 0:00:16.224916s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 94/478 | 19.67%\n",
      "[0:25:39.663585<1:43:27.275255, 0:00:16.206985s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 95/478 | 19.87%\n",
      "[0:25:57.701966<1:43:18.355684, 0:00:16.226062s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 96/478 | 20.08%\n",
      "[0:26:12.468610<1:42:56.397477, 0:00:16.211017s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 97/478 | 20.29%\n",
      "[0:26:32.539932<1:42:55.154660, 0:00:16.250407s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 98/478 | 20.50%\n",
      "[0:26:47.870400<1:42:35.382585, 0:00:16.241115s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 99/478 | 20.71%\n",
      "[0:27:00.390273<1:42:05.075334, 0:00:16.203903s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 100/478 | 20.92%\n",
      "[0:27:17.767838<1:41:53.252171, 0:00:16.215523s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 101/478 | 21.13%\n",
      "[0:27:29.225366<1:41:19.497376, 0:00:16.168876s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 102/478 | 21.34%\n",
      "[0:27:44.071654<1:40:58.513125, 0:00:16.156035s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 103/478 | 21.55%\n",
      "[0:27:57.643309<1:40:33.063564, 0:00:16.131186s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 104/478 | 21.76%\n",
      "[0:28:12.717866<1:40:13.178879, 0:00:16.121123s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 105/478 | 21.97%\n",
      "[0:28:32.287358<1:40:09.159288, 0:00:16.153654s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 106/478 | 22.18%\n",
      "[0:28:45.643752<1:39:43.306952, 0:00:16.127512s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 107/478 | 22.38%\n",
      "[0:29:03.687010<1:39:33.742500, 0:00:16.145250s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 108/478 | 22.59%\n",
      "[0:29:18.545092<1:39:13.239729, 0:00:16.133441s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 109/478 | 22.80%\n",
      "[0:29:37.074292<1:39:05.121328, 0:00:16.155221s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 110/478 | 23.01%\n",
      "[0:29:53.024821<1:38:48.289359, 0:00:16.153377s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 111/478 | 23.22%\n",
      "[0:30:10.997846<1:38:38.082384, 0:00:16.169624s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 112/478 | 23.43%\n",
      "[0:30:26.925752<1:38:21.132025, 0:00:16.167485s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 113/478 | 23.64%\n",
      "[0:30:43.610685<1:38:06.616736, 0:00:16.172024s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 114/478 | 23.85%\n",
      "[0:31:04.563353<1:38:05.534622, 0:00:16.213594s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 115/478 | 24.06%\n",
      "[0:31:21.220863<1:37:50.706402, 0:00:16.217421s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 116/478 | 24.27%\n",
      "[0:31:35.666406<1:37:29.021997, 0:00:16.202277s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 117/478 | 24.48%\n",
      "[0:31:51.171986<1:37:10.694280, 0:00:16.196373s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 118/478 | 24.69%\n",
      "[0:32:08.828287<1:36:58.902119, 0:00:16.208641s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 119/478 | 24.90%\n",
      "[0:32:23.353729<1:36:37.671812, 0:00:16.194614s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 120/478 | 25.10%\n",
      "[0:32:36.654637<1:36:12.939543, 0:00:16.170699s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 121/478 | 25.31%\n",
      "[0:32:51.413162<1:35:52.648144, 0:00:16.159124s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 122/478 | 25.52%\n",
      "[0:33:07.104197<1:35:35.138245, 0:00:16.155319s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 123/478 | 25.73%\n",
      "[0:33:18.894090<1:35:06.520356, 0:00:16.120114s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 124/478 | 25.94%\n",
      "[0:33:35.508021<1:34:51.794592, 0:00:16.124064s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 125/478 | 26.15%\n",
      "[0:33:52.793074<1:34:38.913856, 0:00:16.133278s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 126/478 | 26.36%\n",
      "[0:34:08.909175<1:34:22.733193, 0:00:16.133143s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 127/478 | 26.57%\n",
      "[0:34:30.766462<1:34:22.252050, 0:00:16.177863s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 128/478 | 26.78%\n",
      "[0:34:56.927835<1:34:33.083995, 0:00:16.255255s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 129/478 | 26.99%\n",
      "[0:35:13.307621<1:34:17.161776, 0:00:16.256212s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 130/478 | 27.20%\n",
      "[0:35:30.352342<1:34:02.994504, 0:00:16.262232s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 131/478 | 27.41%\n",
      "[0:35:48.556487<1:33:51.822278, 0:00:16.276943s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 132/478 | 27.62%\n",
      "[0:36:06.925821<1:33:40.972875, 0:00:16.292675s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 133/478 | 27.82%\n",
      "[0:36:18.386442<1:33:12.275560, 0:00:16.256615s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 134/478 | 28.03%\n",
      "[0:36:32.179251<1:32:49.759195, 0:00:16.238365s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 135/478 | 28.24%\n",
      "[0:36:54.907813<1:32:49.841754, 0:00:16.286087s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 136/478 | 28.45%\n",
      "[0:37:13.125663<1:32:38.363767, 0:00:16.300187s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 137/478 | 28.66%\n",
      "[0:37:25.574557<1:32:12.574860, 0:00:16.272279s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 138/478 | 28.87%\n",
      "[0:37:37.329338<1:31:45.285081, 0:00:16.239779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 139/478 | 29.08%\n",
      "[0:37:55.788360<1:31:34.403278, 0:00:16.255631s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 140/478 | 29.29%\n",
      "[0:38:15.135294<1:31:25.536035, 0:00:16.277555s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 141/478 | 29.50%\n",
      "[0:38:29.050906<1:31:03.669792, 0:00:16.260922s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 142/478 | 29.71%\n",
      "[0:38:45.297486<1:30:47.375370, 0:00:16.260822s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 143/478 | 29.92%\n",
      "[0:38:56.767279<1:30:20.002034, 0:00:16.227551s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 144/478 | 30.13%\n",
      "[0:39:08.406611<1:29:53.237364, 0:00:16.195908s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 145/478 | 30.33%\n",
      "[0:39:22.856809<1:29:33.071732, 0:00:16.183951s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 146/478 | 30.54%\n",
      "[0:39:34.462779<1:29:06.579448, 0:00:16.152808s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 147/478 | 30.75%\n",
      "[0:39:48.376859<1:28:45.434730, 0:00:16.137681s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 148/478 | 30.96%\n",
      "[0:40:01.488024<1:28:22.614401, 0:00:16.117369s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 149/478 | 31.17%\n",
      "[0:40:16.996576<1:28:05.166008, 0:00:16.113311s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 150/478 | 31.38%\n",
      "[0:40:35.764275<1:27:54.800703, 0:00:16.130889s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 151/478 | 31.59%\n",
      "[0:40:56.018398<1:27:47.513216, 0:00:16.158016s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 152/478 | 31.80%\n",
      "[0:41:19.740333<1:27:47.422225, 0:00:16.207453s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 153/478 | 32.01%\n",
      "[0:41:37.881562<1:27:35.283240, 0:00:16.220010s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 154/478 | 32.22%\n",
      "[0:41:57.397992<1:27:25.932471, 0:00:16.241277s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 155/478 | 32.43%\n",
      "[0:42:18.197203<1:27:19.099390, 0:00:16.270495s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 156/478 | 32.64%\n",
      "[0:42:40.544058<1:27:15.252558, 0:00:16.309198s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 157/478 | 32.85%\n",
      "[0:43:00.742661<1:27:06.820480, 0:00:16.333814s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 158/478 | 33.05%\n",
      "[0:43:13.379199<1:26:43.068959, 0:00:16.310561s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 159/478 | 33.26%\n",
      "[0:43:28.726719<1:26:24.844356, 0:00:16.304542s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 160/478 | 33.47%\n",
      "[0:43:50.016204<1:26:18.354768, 0:00:16.335504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 161/478 | 33.68%\n",
      "[0:44:01.670840<1:25:52.888760, 0:00:16.306610s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 162/478 | 33.89%\n",
      "[0:44:23.323997<1:25:46.914465, 0:00:16.339411s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 163/478 | 34.10%\n",
      "[0:44:39.049633<1:25:29.399752, 0:00:16.335668s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 164/478 | 34.31%\n",
      "[0:44:57.243141<1:25:16.588464, 0:00:16.346928s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 165/478 | 34.52%\n",
      "[0:45:08.425923<1:24:50.535528, 0:00:16.315819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 166/478 | 34.73%\n",
      "[0:45:22.292549<1:24:29.658583, 0:00:16.301153s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 167/478 | 34.94%\n",
      "[0:45:35.077895<1:24:06.870060, 0:00:16.280226s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 168/478 | 35.15%\n",
      "[0:45:53.087046<1:23:53.750904, 0:00:16.290456s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 169/478 | 35.36%\n",
      "[0:46:05.625298<1:23:30.662272, 0:00:16.268384s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 170/478 | 35.56%\n",
      "[0:46:18.651084<1:23:08.572554, 0:00:16.249422s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 171/478 | 35.77%\n",
      "[0:46:38.050069<1:22:57.926298, 0:00:16.267733s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 172/478 | 35.98%\n",
      "[0:47:02.170617<1:22:55.503125, 0:00:16.313125s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 173/478 | 36.19%\n",
      "[0:47:16.521872<1:22:35.762400, 0:00:16.301850s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 174/478 | 36.40%\n",
      "[0:47:32.053164<1:22:18.126441, 0:00:16.297447s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 175/478 | 36.61%\n",
      "[0:47:50.208571<1:22:05.016906, 0:00:16.308003s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 176/478 | 36.82%\n",
      "[0:48:03.944579<1:21:44.335072, 0:00:16.293472s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 177/478 | 37.03%\n",
      "[0:48:23.536805<1:21:33.601500, 0:00:16.312005s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 178/478 | 37.24%\n",
      "[0:48:37.571188<1:21:13.484720, 0:00:16.299280s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 179/478 | 37.45%\n",
      "[0:48:56.390861<1:21:01.358334, 0:00:16.313283s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 180/478 | 37.66%\n",
      "[0:49:10.593508<1:20:41.581734, 0:00:16.301622s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 181/478 | 37.87%\n",
      "[0:49:24.927629<1:20:22.080056, 0:00:16.290811s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 182/478 | 38.08%\n",
      "[0:49:40.918558<1:20:05.305740, 0:00:16.289172s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 183/478 | 38.28%\n",
      "[0:49:59.299942<1:19:52.359642, 0:00:16.300543s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 184/478 | 38.49%\n",
      "[0:50:10.804676<1:19:28.463660, 0:00:16.274620s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 185/478 | 38.70%\n",
      "[0:50:27.844627<1:19:13.390620, 0:00:16.278735s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 186/478 | 38.91%\n",
      "[0:50:44.299857<1:18:57.386298, 0:00:16.279678s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 187/478 | 39.12%\n",
      "[0:51:03.762853<1:18:46.017190, 0:00:16.296611s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 188/478 | 39.33%\n",
      "[0:51:22.924446<1:18:34.101530, 0:00:16.311770s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 189/478 | 39.54%\n",
      "[0:51:39.156700<1:18:17.669088, 0:00:16.311351s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 190/478 | 39.75%\n",
      "[0:51:54.440417<1:17:59.813677, 0:00:16.305971s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 191/478 | 39.96%\n",
      "[0:52:08.104138<1:17:39.571774, 0:00:16.292209s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 192/478 | 40.17%\n",
      "[0:52:23.070685<1:17:21.321900, 0:00:16.285340s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 193/478 | 40.38%\n",
      "[0:52:39.953932<1:17:05.911848, 0:00:16.288422s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 194/478 | 40.59%\n",
      "[0:52:56.331462<1:16:49.752757, 0:00:16.288879s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 195/478 | 40.79%\n",
      "[0:53:13.814227<1:16:35.181822, 0:00:16.294971s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 196/478 | 41.00%\n",
      "[0:53:46.118284<1:16:41.722035, 0:00:16.376235s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 197/478 | 41.21%\n",
      "[0:54:03.915187<1:16:27.354800, 0:00:16.383410s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 198/478 | 41.42%\n",
      "[0:54:17.871621<1:16:07.568706, 0:00:16.371214s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 199/478 | 41.63%\n",
      "[0:54:29.456908<1:15:44.545230, 0:00:16.347285s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 200/478 | 41.84%\n",
      "[0:54:46.823832<1:15:29.602889, 0:00:16.352357s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 201/478 | 42.05%\n",
      "[0:54:58.539223<1:15:06.914952, 0:00:16.329402s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 202/478 | 42.26%\n",
      "[0:55:16.187800<1:14:52.372500, 0:00:16.335900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 203/478 | 42.47%\n",
      "[0:55:30.373640<1:14:33.148914, 0:00:16.325361s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 204/478 | 42.68%\n",
      "[0:55:43.938759<1:14:13.147608, 0:00:16.311896s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 205/478 | 42.89%\n",
      "[0:55:57.410057<1:13:53.085104, 0:00:16.298107s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 206/478 | 43.10%\n",
      "[0:56:12.656030<1:13:35.409504, 0:00:16.293024s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 207/478 | 43.31%\n",
      "[0:56:28.807589<1:13:18.932880, 0:00:16.292344s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 208/478 | 43.51%\n",
      "[0:56:46.019776<1:13:03.824405, 0:00:16.296745s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 209/478 | 43.72%\n",
      "[0:56:57.545882<1:12:41.439504, 0:00:16.274028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 210/478 | 43.93%\n",
      "[0:57:16.923854<1:12:29.093313, 0:00:16.288739s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 211/478 | 44.14%\n",
      "[0:57:32.661150<1:12:12.112708, 0:00:16.286138s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 212/478 | 44.35%\n",
      "[0:57:47.923509<1:11:54.552715, 0:00:16.281331s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 213/478 | 44.56%\n",
      "[0:58:04.431112<1:11:38.550432, 0:00:16.282388s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 214/478 | 44.77%\n",
      "[0:58:18.769515<1:11:19.890261, 0:00:16.273347s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 215/478 | 44.98%\n",
      "[0:58:30.168238<1:10:57.704098, 0:00:16.250779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 216/478 | 45.19%\n",
      "[0:58:48.891961<1:10:44.427675, 0:00:16.262175s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 217/478 | 45.40%\n",
      "[0:59:00.795123<1:10:22.966540, 0:00:16.242179s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 218/478 | 45.61%\n",
      "[0:59:12.321685<1:10:01.147573, 0:00:16.220647s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 219/478 | 45.82%\n",
      "[0:59:24.082213<1:09:39.696492, 0:00:16.200374s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 220/478 | 46.03%\n",
      "[0:59:38.007871<1:09:20.850817, 0:00:16.190081s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 221/478 | 46.23%\n",
      "[0:59:54.430485<1:09:04.928768, 0:00:16.191128s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 222/478 | 46.44%\n",
      "[1:00:13.650125<1:08:52.200795, 0:00:16.204709s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 223/478 | 46.65%\n",
      "[1:00:26.631478<1:08:32.341026, 0:00:16.190319s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 224/478 | 46.86%\n",
      "[1:00:40.259658<1:08:13.269796, 0:00:16.178932s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 225/478 | 47.07%\n",
      "[1:00:54.747202<1:07:55.204896, 0:00:16.171448s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 226/478 | 47.28%\n",
      "[1:01:11.713770<1:07:39.912701, 0:00:16.174951s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 227/478 | 47.49%\n",
      "[1:01:25.283299<1:07:20.880750, 0:00:16.163523s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 228/478 | 47.70%\n",
      "[1:01:38.165156<1:07:01.149057, 0:00:16.149193s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 229/478 | 47.91%\n",
      "[1:01:54.210020<1:06:44.887272, 0:00:16.148739s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 230/478 | 48.12%\n",
      "[1:02:13.920056<1:06:32.546532, 0:00:16.164156s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 231/478 | 48.33%\n",
      "[1:02:25.863880<1:06:11.907390, 0:00:16.145965s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 232/478 | 48.54%\n",
      "[1:02:39.117947<1:05:52.720485, 0:00:16.133553s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 233/478 | 48.74%\n",
      "[1:02:57.149886<1:05:38.566504, 0:00:16.141666s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 234/478 | 48.95%\n",
      "[1:03:11.004327<1:05:20.059719, 0:00:16.131933s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 235/478 | 49.16%\n",
      "[1:03:29.659589<1:05:06.515250, 0:00:16.142625s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 236/478 | 49.37%\n",
      "[1:03:47.906482<1:04:52.512464, 0:00:16.151504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 237/478 | 49.58%\n",
      "[1:04:00.870603<1:04:33.146880, 0:00:16.138112s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 238/478 | 49.79%\n",
      "[1:04:14.972630<1:04:14.972727, 0:00:16.129593s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 239/478 | 50.00%\n",
      "[1:04:30.565599<1:03:58.310966, 0:00:16.127357s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 240/478 | 50.21%\n",
      "[1:04:41.692181<1:03:37.265859, 0:00:16.106607s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 241/478 | 50.42%\n",
      "[1:04:59.973593<1:03:23.279948, 0:00:16.115593s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 242/478 | 50.63%\n",
      "[1:05:14.048599<1:03:05.191060, 0:00:16.107196s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 243/478 | 50.84%\n",
      "[1:05:31.212206<1:02:50.096850, 0:00:16.111525s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 244/478 | 51.05%\n",
      "[1:05:44.852417<1:02:31.635054, 0:00:16.101438s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 245/478 | 51.26%\n",
      "[1:06:05.943796<1:02:20.239736, 0:00:16.121723s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 246/478 | 51.46%\n",
      "[1:06:21.210570<1:02:03.318291, 0:00:16.118261s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 247/478 | 51.67%\n",
      "[1:06:35.533081<1:01:45.534600, 0:00:16.111020s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 248/478 | 51.88%\n",
      "[1:06:48.873269<1:01:26.875497, 0:00:16.099893s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 249/478 | 52.09%\n",
      "[1:07:00.993232<1:01:07.145844, 0:00:16.083973s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 250/478 | 52.30%\n",
      "[1:07:15.491507<1:00:49.627685, 0:00:16.077655s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 251/478 | 52.51%\n",
      "[1:07:28.586120<1:00:30.874868, 0:00:16.065818s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 252/478 | 52.72%\n",
      "[1:07:40.234938<1:00:10.880775, 0:00:16.048359s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 253/478 | 52.93%\n",
      "[1:07:51.783028<0:59:50.863808, 0:00:16.030642s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 254/478 | 53.14%\n",
      "[1:08:09.874899<0:59:36.635675, 0:00:16.038725s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 255/478 | 53.35%\n",
      "[1:08:24.218807<0:59:19.127310, 0:00:16.032105s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 256/478 | 53.56%\n",
      "[1:08:42.184609<0:59:04.758009, 0:00:16.039629s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 257/478 | 53.77%\n",
      "[1:09:01.947141<0:58:51.892980, 0:00:16.054059s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 258/478 | 53.97%\n",
      "[1:09:22.539461<0:58:39.676239, 0:00:16.071581s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 259/478 | 54.18%\n",
      "[1:09:37.869758<0:58:22.983140, 0:00:16.068730s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 260/478 | 54.39%\n",
      "[1:09:55.795938<0:58:08.458799, 0:00:16.075847s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 261/478 | 54.60%\n",
      "[1:10:15.849247<0:57:55.662048, 0:00:16.091028s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 262/478 | 54.81%\n",
      "[1:10:32.065293<0:57:39.673145, 0:00:16.091503s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 263/478 | 55.02%\n",
      "[1:10:49.680721<0:57:24.816850, 0:00:16.097275s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 264/478 | 55.23%\n",
      "[1:11:11.750347<0:57:13.520169, 0:00:16.119813s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 265/478 | 55.44%\n",
      "[1:11:31.920729<0:57:00.628480, 0:00:16.135040s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 266/478 | 55.65%\n",
      "[1:11:45.360209<0:56:42.363395, 0:00:16.124945s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 267/478 | 55.86%\n",
      "[1:12:05.706096<0:56:29.545740, 0:00:16.140694s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 268/478 | 56.07%\n",
      "[1:12:21.589185<0:56:13.205033, 0:00:16.139737s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 269/478 | 56.28%\n",
      "[1:12:35.107043<0:55:55.045408, 0:00:16.130026s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 270/478 | 56.49%\n",
      "[1:12:51.030760<0:55:38.757855, 0:00:16.129265s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 271/478 | 56.69%\n",
      "[1:13:09.162680<0:55:24.145368, 0:00:16.136628s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 272/478 | 56.90%\n",
      "[1:13:22.235149<0:55:05.707615, 0:00:16.125403s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 273/478 | 57.11%\n",
      "[1:13:35.345713<0:54:47.337600, 0:00:16.114400s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 274/478 | 57.32%\n",
      "[1:13:54.615735<0:54:33.552625, 0:00:16.125875s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 275/478 | 57.53%\n",
      "[1:14:09.954359<0:54:16.850646, 0:00:16.123023s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 276/478 | 57.74%\n",
      "[1:14:23.943305<0:53:59.179119, 0:00:16.115319s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 277/478 | 57.95%\n",
      "[1:14:35.418274<0:53:39.725400, 0:00:16.098627s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 278/478 | 58.16%\n",
      "[1:14:46.610176<0:53:20.126960, 0:00:16.081040s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 279/478 | 58.37%\n",
      "[1:14:58.351555<0:53:00.977118, 0:00:16.065541s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 280/478 | 58.58%\n",
      "[1:15:14.516844<0:52:44.981512, 0:00:16.065896s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 281/478 | 58.79%\n",
      "[1:15:29.972276<0:52:28.491276, 0:00:16.063731s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 282/478 | 59.00%\n",
      "[1:15:48.762844<0:52:14.306565, 0:00:16.073367s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 283/478 | 59.21%\n",
      "[1:16:02.338052<0:51:56.526774, 0:00:16.064571s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 284/478 | 59.41%\n",
      "[1:16:21.815867<0:51:42.773571, 0:00:16.076547s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 285/478 | 59.62%\n",
      "[1:16:38.964914<0:51:27.417024, 0:00:16.080297s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 286/478 | 59.83%\n",
      "[1:16:56.502690<0:51:12.306625, 0:00:16.085375s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 287/478 | 60.04%\n",
      "[1:17:08.434021<0:50:53.480690, 0:00:16.070951s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 288/478 | 60.25%\n",
      "[1:17:20.087578<0:50:34.520874, 0:00:16.055666s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 289/478 | 60.46%\n",
      "[1:17:38.495802<0:50:19.990452, 0:00:16.063779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 290/478 | 60.67%\n",
      "[1:17:57.308978<0:50:05.693449, 0:00:16.073227s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 291/478 | 60.88%\n",
      "[1:18:13.553817<0:49:49.729404, 0:00:16.073814s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 292/478 | 61.09%\n",
      "[1:18:38.630531<0:49:39.340085, 0:00:16.104541s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 293/478 | 61.30%\n",
      "[1:18:57.010061<0:49:24.659336, 0:00:16.112279s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 294/478 | 61.51%\n",
      "[1:19:14.303978<0:49:09.280155, 0:00:16.116285s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 295/478 | 61.72%\n",
      "[1:19:31.584161<0:48:53.879494, 0:00:16.120217s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 296/478 | 61.92%\n",
      "[1:19:55.751036<0:48:42.663110, 0:00:16.147310s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 297/478 | 62.13%\n",
      "[1:20:08.775753<0:48:24.629580, 0:00:16.136831s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 298/478 | 62.34%\n",
      "[1:20:22.887187<0:48:07.280203, 0:00:16.130057s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 299/478 | 62.55%\n",
      "[1:20:38.397805<0:47:50.782754, 0:00:16.127993s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 300/478 | 62.76%\n",
      "[1:20:53.948977<0:47:34.315452, 0:00:16.126076s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 301/478 | 62.97%\n",
      "[1:21:05.506269<0:47:15.526848, 0:00:16.110948s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 302/478 | 63.18%\n",
      "[1:21:17.308148<0:46:56.927225, 0:00:16.096727s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 303/478 | 63.39%\n",
      "[1:21:33.069075<0:46:40.638228, 0:00:16.095622s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 304/478 | 63.60%\n",
      "[1:21:50.459017<0:46:25.276818, 0:00:16.099866s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 305/478 | 63.81%\n",
      "[1:22:09.519091<0:46:10.840880, 0:00:16.109540s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 306/478 | 64.02%\n",
      "[1:22:21.137100<0:45:52.229439, 0:00:16.094909s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 307/478 | 64.23%\n",
      "[1:22:36.772095<0:45:35.880720, 0:00:16.093416s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 308/478 | 64.44%\n",
      "[1:22:53.751745<0:45:20.271996, 0:00:16.096284s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 309/478 | 64.64%\n",
      "[1:23:09.001394<0:45:03.716904, 0:00:16.093553s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 310/478 | 64.85%\n",
      "[1:23:38.754863<0:44:54.958325, 0:00:16.137475s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 311/478 | 65.06%\n",
      "[1:23:55.145212<0:44:38.955476, 0:00:16.138286s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 312/478 | 65.27%\n",
      "[1:24:13.519043<0:44:23.995620, 0:00:16.145428s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 313/478 | 65.48%\n",
      "[1:24:28.731440<0:44:07.362948, 0:00:16.142457s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 314/478 | 65.69%\n",
      "[1:24:52.102326<0:43:54.960852, 0:00:16.165404s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 315/478 | 65.90%\n",
      "[1:25:04.240762<0:43:36.731082, 0:00:16.152661s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 316/478 | 66.11%\n",
      "[1:25:19.763263<0:43:20.258353, 0:00:16.150673s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 317/478 | 66.32%\n",
      "[1:25:36.398348<0:43:04.351360, 0:00:16.152196s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 318/478 | 66.53%\n",
      "[1:25:50.955409<0:42:47.404164, 0:00:16.147196s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 319/478 | 66.74%\n",
      "[1:26:08.634196<0:42:32.013156, 0:00:16.151982s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 320/478 | 66.95%\n",
      "[1:26:23.337626<0:42:15.152633, 0:00:16.147469s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 321/478 | 67.15%\n",
      "[1:27:08.588500<0:42:13.104912, 0:00:16.237852s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 322/478 | 67.36%\n",
      "[1:27:26.643677<0:41:57.739245, 0:00:16.243479s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 323/478 | 67.57%\n",
      "[1:27:41.454947<0:41:40.814932, 0:00:16.239058s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 324/478 | 67.78%\n",
      "[1:28:00.998363<0:41:26.131578, 0:00:16.249226s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 325/478 | 67.99%\n",
      "[1:28:12.767892<0:41:07.793568, 0:00:16.235484s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 326/478 | 68.20%\n",
      "[1:28:28.871153<0:40:51.497080, 0:00:16.235080s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 327/478 | 68.41%\n",
      "[1:28:40.399791<0:40:33.109650, 0:00:16.220731s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 328/478 | 68.62%\n",
      "[1:28:59.127818<0:40:18.024448, 0:00:16.228352s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 329/478 | 68.83%\n",
      "[1:29:17.588774<0:40:02.797316, 0:00:16.235117s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 330/478 | 69.04%\n",
      "[1:29:33.431662<0:39:46.388151, 0:00:16.233933s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 331/478 | 69.25%\n",
      "[1:29:54.184770<0:39:32.141424, 0:00:16.247544s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 332/478 | 69.46%\n",
      "[1:30:09.044935<0:39:15.289810, 0:00:16.243378s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 333/478 | 69.67%\n",
      "[1:30:22.716864<0:38:57.937776, 0:00:16.235679s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 334/478 | 69.87%\n",
      "[1:30:34.610502<0:38:39.848674, 0:00:16.222718s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 335/478 | 70.08%\n",
      "[1:30:48.305453<0:38:22.557690, 0:00:16.215195s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 336/478 | 70.29%\n",
      "[1:31:01.179734<0:38:04.944621, 0:00:16.205281s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 337/478 | 70.50%\n",
      "[1:31:16.832810<0:37:48.510580, 0:00:16.203647s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 338/478 | 70.71%\n",
      "[1:31:34.991341<0:37:33.108546, 0:00:16.209414s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 339/478 | 70.92%\n",
      "[1:31:59.646405<0:37:20.327052, 0:00:16.234254s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 340/478 | 71.13%\n",
      "[1:32:20.807684<0:37:06.072311, 0:00:16.248703s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 341/478 | 71.34%\n",
      "[1:32:41.228782<0:36:51.482808, 0:00:16.260903s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 342/478 | 71.55%\n",
      "[1:33:07.676748<0:36:39.231405, 0:00:16.290603s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 343/478 | 71.76%\n",
      "[1:33:23.496189<0:36:22.757222, 0:00:16.289233s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 344/478 | 71.97%\n",
      "[1:33:36.663730<0:36:05.264605, 0:00:16.280185s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 345/478 | 72.18%\n",
      "[1:33:58.545530<0:35:51.121368, 0:00:16.296374s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 346/478 | 72.38%\n",
      "[1:34:16.887280<0:35:35.597239, 0:00:16.302269s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 347/478 | 72.59%\n",
      "[1:34:31.507733<0:35:18.666680, 0:00:16.297436s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 348/478 | 72.80%\n",
      "[1:34:48.465259<0:35:02.613183, 0:00:16.299327s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 349/478 | 73.01%\n",
      "[1:35:03.246926<0:34:45.758848, 0:00:16.294991s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 350/478 | 73.22%\n",
      "[1:35:19.629418<0:34:29.495607, 0:00:16.295241s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 351/478 | 73.43%\n",
      "[1:35:36.182786<0:34:13.292724, 0:00:16.295974s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 352/478 | 73.64%\n",
      "[1:35:52.033399<0:33:56.839000, 0:00:16.294712s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 353/478 | 73.85%\n",
      "[1:36:03.785835<0:33:38.953244, 0:00:16.281881s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 354/478 | 74.06%\n",
      "[1:36:20.465661<0:33:22.809246, 0:00:16.283002s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 355/478 | 74.27%\n",
      "[1:36:36.542900<0:33:06.455728, 0:00:16.282424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 356/478 | 74.48%\n",
      "[1:36:55.559888<0:32:51.100164, 0:00:16.290084s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 357/478 | 74.69%\n",
      "[1:37:13.192504<0:32:35.260080, 0:00:16.293834s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 358/478 | 74.90%\n",
      "[1:37:24.968843<0:32:17.468750, 0:00:16.281250s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 359/478 | 75.10%\n",
      "[1:37:44.210757<0:32:02.157932, 0:00:16.289474s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 360/478 | 75.31%\n",
      "[1:37:58.043159<0:31:45.072156, 0:00:16.282668s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 361/478 | 75.52%\n",
      "[1:38:15.652188<0:31:29.214512, 0:00:16.286332s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 362/478 | 75.73%\n",
      "[1:38:27.688231<0:31:11.581645, 0:00:16.274623s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 363/478 | 75.94%\n",
      "[1:38:51.282245<0:30:57.599334, 0:00:16.294731s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 364/478 | 76.15%\n",
      "[1:39:04.259313<0:30:40.277546, 0:00:16.285642s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 365/478 | 76.36%\n",
      "[1:39:17.587033<0:30:23.086720, 0:00:16.277560s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 366/478 | 76.57%\n",
      "[1:39:29.366647<0:30:05.448744, 0:00:16.265304s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 367/478 | 76.78%\n",
      "[1:39:40.813187<0:29:47.743100, 0:00:16.252210s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 368/478 | 76.99%\n",
      "[1:39:52.493137<0:29:30.140271, 0:00:16.239819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 369/478 | 77.20%\n",
      "[1:40:09.444159<0:29:14.108028, 0:00:16.241741s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 370/478 | 77.41%\n",
      "[1:40:22.964415<0:28:57.081335, 0:00:16.234405s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 371/478 | 77.62%\n",
      "[1:40:37.658687<0:28:40.408090, 0:00:16.230265s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 372/478 | 77.82%\n",
      "[1:40:56.780513<0:28:24.991785, 0:00:16.238017s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 373/478 | 78.03%\n",
      "[1:41:18.087839<0:28:10.163488, 0:00:16.251572s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 374/478 | 78.24%\n",
      "[1:41:36.983364<0:27:54.638066, 0:00:16.258622s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 375/478 | 78.45%\n",
      "[1:41:56.965309<0:27:39.389550, 0:00:16.268525s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 376/478 | 78.66%\n",
      "[1:42:12.988075<0:27:23.055173, 0:00:16.267873s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 377/478 | 78.87%\n",
      "[1:42:26.675224<0:27:06.104600, 0:00:16.261046s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 378/478 | 79.08%\n",
      "[1:42:46.652928<0:26:50.814348, 0:00:16.270852s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 379/478 | 79.29%\n",
      "[1:42:58.391014<0:26:33.374552, 0:00:16.258924s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 380/478 | 79.50%\n",
      "[1:43:21.275162<0:26:18.802361, 0:00:16.276313s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 381/478 | 79.71%\n",
      "[1:43:40.277449<0:26:03.211104, 0:00:16.283449s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 382/478 | 79.92%\n",
      "[1:43:51.814208<0:25:45.750225, 0:00:16.271055s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 383/478 | 80.13%\n",
      "[1:44:08.224556<0:25:29.513292, 0:00:16.271418s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 384/478 | 80.33%\n",
      "[1:44:19.693108<0:25:12.081699, 0:00:16.258943s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 385/478 | 80.54%\n",
      "[1:44:34.447622<0:24:55.464232, 0:00:16.255046s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 386/478 | 80.75%\n",
      "[1:44:55.334415<0:24:40.298274, 0:00:16.267014s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 387/478 | 80.96%\n",
      "[1:45:11.797649<0:24:24.076800, 0:00:16.267520s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 388/478 | 81.17%\n",
      "[1:45:24.304417<0:24:06.948828, 0:00:16.257852s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 389/478 | 81.38%\n",
      "[1:45:36.531862<0:23:49.781584, 0:00:16.247518s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 390/478 | 81.59%\n",
      "[1:45:54.306724<0:23:33.873888, 0:00:16.251424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 391/478 | 81.80%\n",
      "[1:46:10.739586<0:23:17.662282, 0:00:16.251887s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 392/478 | 82.01%\n",
      "[1:46:27.390161<0:23:01.496585, 0:00:16.252901s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 393/478 | 82.22%\n",
      "[1:46:43.584512<0:22:45.231252, 0:00:16.252753s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 394/478 | 82.43%\n",
      "[1:46:56.296977<0:22:28.234570, 0:00:16.243790s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 395/478 | 82.64%\n",
      "[1:47:09.499651<0:22:11.361020, 0:00:16.236110s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 396/478 | 82.85%\n",
      "[1:47:21.225036<0:21:54.204588, 0:00:16.224748s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 397/478 | 83.05%\n",
      "[1:47:32.914821<0:21:37.068320, 0:00:16.213354s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 398/478 | 83.26%\n",
      "[1:47:53.475437<0:21:21.715671, 0:00:16.224249s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 399/478 | 83.47%\n",
      "[1:48:07.929258<0:21:05.146194, 0:00:16.219823s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 400/478 | 83.68%\n",
      "[1:48:23.292162<0:20:48.761822, 0:00:16.217686s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 401/478 | 83.89%\n",
      "[1:48:37.074874<0:20:32.083804, 0:00:16.211629s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 402/478 | 84.10%\n",
      "[1:48:55.901222<0:20:16.358775, 0:00:16.218117s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 403/478 | 84.31%\n",
      "[1:49:11.349792<0:19:59.999688, 0:00:16.216212s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 404/478 | 84.52%\n",
      "[1:49:23.856797<0:19:43.114942, 0:00:16.207054s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 405/478 | 84.73%\n",
      "[1:49:45.820484<0:19:27.928776, 0:00:16.221233s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 406/478 | 84.94%\n",
      "[1:50:00.490671<0:19:11.436962, 0:00:16.217422s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 407/478 | 85.15%\n",
      "[1:50:11.974541<0:18:54.407400, 0:00:16.205820s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 408/478 | 85.36%\n",
      "[1:50:27.981948<0:18:38.168115, 0:00:16.205335s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 409/478 | 85.56%\n",
      "[1:50:41.638095<0:18:21.539956, 0:00:16.199117s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 410/478 | 85.77%\n",
      "[1:50:53.269397<0:18:04.596201, 0:00:16.188003s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 411/478 | 85.98%\n",
      "[1:51:06.758909<0:17:47.975964, 0:00:16.181454s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 412/478 | 86.19%\n",
      "[1:51:30.808423<0:17:33.032825, 0:00:16.200505s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 413/478 | 86.40%\n",
      "[1:51:42.345006<0:17:16.111296, 0:00:16.189239s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 414/478 | 86.61%\n",
      "[1:52:00.296123<0:17:00.189555, 0:00:16.193485s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 415/478 | 86.82%\n",
      "[1:52:20.901089<0:16:44.653518, 0:00:16.204089s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 416/478 | 87.03%\n",
      "[1:52:39.053958<0:16:28.734482, 0:00:16.208762s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 417/478 | 87.24%\n",
      "[1:52:56.725101<0:16:12.735660, 0:00:16.212261s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 418/478 | 87.45%\n",
      "[1:53:13.891359<0:15:56.657742, 0:00:16.214538s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 419/478 | 87.66%\n",
      "[1:53:34.446798<0:15:41.042634, 0:00:16.224873s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 420/478 | 87.87%\n",
      "[1:53:46.136590<0:15:24.203757, 0:00:16.214101s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 421/478 | 88.08%\n",
      "[1:53:59.748252<0:15:07.644304, 0:00:16.207934s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 422/478 | 88.28%\n",
      "[1:54:11.356498<0:14:50.838300, 0:00:16.197060s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 423/478 | 88.49%\n",
      "[1:54:22.946519<0:14:34.054530, 0:00:16.186195s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 424/478 | 88.70%\n",
      "[1:54:36.104088<0:14:17.490604, 0:00:16.179068s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 425/478 | 88.91%\n",
      "[1:54:47.845504<0:14:00.769852, 0:00:16.168651s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 426/478 | 89.12%\n",
      "[1:55:07.784568<0:13:45.051531, 0:00:16.177481s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 427/478 | 89.33%\n",
      "[1:55:21.357115<0:13:28.569750, 0:00:16.171395s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 428/478 | 89.54%\n",
      "[1:55:32.923411<0:13:11.872389, 0:00:16.160661s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 429/478 | 89.75%\n",
      "[1:55:44.743541<0:12:55.227168, 0:00:16.150566s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 430/478 | 89.96%\n",
      "[1:56:01.303994<0:12:39.121299, 0:00:16.151517s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 431/478 | 90.17%\n",
      "[1:56:12.780417<0:12:22.471970, 0:00:16.140695s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 432/478 | 90.38%\n",
      "[1:56:24.345579<0:12:05.855760, 0:00:16.130128s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 433/478 | 90.59%\n",
      "[1:56:35.802272<0:11:49.251840, 0:00:16.119360s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 434/478 | 90.79%\n",
      "[1:56:51.773540<0:11:33.117860, 0:00:16.119020s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 435/478 | 91.00%\n",
      "[1:57:10.499972<0:11:17.250000, 0:00:16.125000s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 436/478 | 91.21%\n",
      "[1:57:25.980614<0:11:01.064525, 0:00:16.123525s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 437/478 | 91.42%\n",
      "[1:57:47.444387<0:10:45.428720, 0:00:16.135718s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 438/478 | 91.63%\n",
      "[1:58:01.250617<0:10:29.086029, 0:00:16.130411s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 439/478 | 91.84%\n",
      "[1:58:20.951268<0:10:13.263988, 0:00:16.138526s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 440/478 | 92.05%\n",
      "[1:58:39.147414<0:09:57.298067, 0:00:16.143191s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 441/478 | 92.26%\n",
      "[1:58:55.986785<0:09:41.211576, 0:00:16.144766s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 442/478 | 92.47%\n",
      "[1:59:17.326930<0:09:25.477290, 0:00:16.156494s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 443/478 | 92.68%\n",
      "[1:59:29.060748<0:09:08.982122, 0:00:16.146533s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 444/478 | 92.89%\n",
      "[1:59:40.045159<0:08:52.452789, 0:00:16.134933s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 445/478 | 93.10%\n",
      "[1:59:56.986083<0:08:36.375680, 0:00:16.136740s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 446/478 | 93.31%\n",
      "[2:00:08.632050<0:08:19.927514, 0:00:16.126694s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 447/478 | 93.51%\n",
      "[2:00:24.934260<0:08:03.812550, 0:00:16.127085s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 448/478 | 93.72%\n",
      "[2:00:43.636101<0:07:47.851780, 0:00:16.132820s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 449/478 | 93.93%\n",
      "[2:01:01.034035<0:07:31.797668, 0:00:16.135631s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 450/478 | 94.14%\n",
      "[2:01:19.599606<0:07:15.807513, 0:00:16.141019s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 451/478 | 94.35%\n",
      "[2:01:33.547870<0:06:59.540368, 0:00:16.136168s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 452/478 | 94.56%\n",
      "[2:01:47.492675<0:06:43.283250, 0:00:16.131330s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 453/478 | 94.77%\n",
      "[2:01:59.424919<0:06:26.929944, 0:00:16.122081s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 454/478 | 94.98%\n",
      "[2:02:14.282559<0:06:10.743946, 0:00:16.119302s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 455/478 | 95.19%\n",
      "[2:02:27.489233<0:05:54.484130, 0:00:16.112915s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 456/478 | 95.40%\n",
      "[2:02:42.028119<0:05:38.298891, 0:00:16.109471s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 457/478 | 95.61%\n",
      "[2:02:57.097897<0:05:22.144020, 0:00:16.107201s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 458/478 | 95.82%\n",
      "[2:03:14.263118<0:05:06.080614, 0:00:16.109506s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 459/478 | 96.03%\n",
      "[2:03:32.814249<0:04:50.066652, 0:00:16.114814s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 460/478 | 96.23%\n",
      "[2:03:52.271374<0:04:34.075088, 0:00:16.122064s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 461/478 | 96.44%\n",
      "[2:04:10.674506<0:04:18.032016, 0:00:16.127001s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 462/478 | 96.65%\n",
      "[2:04:22.434767<0:04:01.763550, 0:00:16.117570s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 463/478 | 96.86%\n",
      "[2:04:40.075104<0:03:45.691928, 0:00:16.120852s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 464/478 | 97.07%\n",
      "[2:04:59.043027<0:03:29.650662, 0:00:16.126974s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 465/478 | 97.28%\n",
      "[2:05:16.693564<0:03:13.562928, 0:00:16.130244s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 466/478 | 97.49%\n",
      "[2:05:32.686737<0:02:57.429450, 0:00:16.129950s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 467/478 | 97.70%\n",
      "[2:05:50.119417<0:02:41.327340, 0:00:16.132734s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 468/478 | 97.91%\n",
      "[2:06:04.318194<0:02:25.157490, 0:00:16.128610s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 469/478 | 98.12%\n",
      "[2:06:20.957165<0:02:09.037568, 0:00:16.129696s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 470/478 | 98.33%\n",
      "[2:06:34.638142<0:01:52.871479, 0:00:16.124497s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 471/478 | 98.54%\n",
      "[2:06:50.085021<0:01:36.738366, 0:00:16.123061s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 472/478 | 98.74%\n",
      "[2:07:04.607864<0:01:20.598390, 0:00:16.119678s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 473/478 | 98.95%\n",
      "[2:07:16.257733<0:01:04.440992, 0:00:16.110248s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 474/478 | 99.16%\n",
      "[2:07:30.714214<0:00:48.320301, 0:00:16.106767s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 475/478 | 99.37%\n",
      "[2:07:42.717108<0:00:32.196290, 0:00:16.098145s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 476/478 | 99.58%\n",
      "[2:08:02.769015<0:00:16.106434, 0:00:16.106434s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 477/478 | 99.79%\n",
      "[2:08:16.581639<0:00:00, 0:00:16.101635s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 3: 478/478 | 100.00%\n",
      "[0:00:00.000199<0:00:00.094923, 0:00:00.000199s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 1/478 | 0.21%\n",
      "[0:00:15.655813<1:02:06.083256, 0:00:07.827906s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 2/478 | 0.42%\n",
      "[0:00:28.453101<1:15:05.074325, 0:00:09.484367s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 3/478 | 0.63%\n",
      "[0:00:38.292330<1:15:37.640868, 0:00:09.573082s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 4/478 | 0.84%\n",
      "[0:00:48.478897<1:16:26.103467, 0:00:09.695779s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 5/478 | 1.05%\n",
      "[0:01:05.281885<1:25:35.508208, 0:00:10.880314s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 6/478 | 1.26%\n",
      "[0:01:17.120538<1:26:29.110620, 0:00:11.017220s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 7/478 | 1.46%\n",
      "[0:01:32.215102<1:30:17.637360, 0:00:11.526888s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 8/478 | 1.67%\n",
      "[0:01:47.538379<1:33:23.944521, 0:00:11.948709s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 9/478 | 1.88%\n",
      "[0:02:04.099834<1:36:47.872044, 0:00:12.409983s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 10/478 | 2.09%\n",
      "[0:02:17.479153<1:37:16.615035, 0:00:12.498105s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 11/478 | 2.30%\n",
      "[0:02:27.514796<1:35:28.491400, 0:00:12.292900s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 12/478 | 2.51%\n",
      "[0:02:43.103920<1:37:14.101575, 0:00:12.546455s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 13/478 | 2.72%\n",
      "[0:02:55.776654<1:37:05.740400, 0:00:12.555475s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 14/478 | 2.93%\n",
      "[0:03:07.953949<1:36:41.511769, 0:00:12.530263s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 15/478 | 3.14%\n",
      "[0:03:25.953595<1:39:06.910200, 0:00:12.872100s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 16/478 | 3.35%\n",
      "[0:03:39.406309<1:39:09.782633, 0:00:12.906253s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 17/478 | 3.56%\n",
      "[0:03:54.684208<1:39:57.485520, 0:00:13.038012s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 18/478 | 3.77%\n",
      "[0:04:10.592162<1:40:53.778999, 0:00:13.189061s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 19/478 | 3.97%\n",
      "[0:04:24.259729<1:40:51.547588, 0:00:13.212986s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 20/478 | 4.18%\n",
      "[0:04:35.657682<1:39:58.836092, 0:00:13.126556s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 21/478 | 4.39%\n",
      "[0:04:52.259764<1:40:57.747960, 0:00:13.284535s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 22/478 | 4.60%\n",
      "[0:05:04.420461<1:40:22.230760, 0:00:13.235672s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 23/478 | 4.81%\n",
      "[0:05:17.095412<1:39:58.388286, 0:00:13.212309s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 24/478 | 5.02%\n",
      "[0:05:30.983229<1:39:57.416037, 0:00:13.239329s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 25/478 | 5.23%\n",
      "[0:05:41.357703<1:38:54.372184, 0:00:13.129142s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 26/478 | 5.44%\n",
      "[0:05:54.799836<1:38:46.471485, 0:00:13.140735s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 27/478 | 5.65%\n",
      "[0:06:04.650983<1:37:40.462050, 0:00:13.023249s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 28/478 | 5.86%\n",
      "[0:06:17.485678<1:37:24.519852, 0:00:13.016748s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 29/478 | 6.07%\n",
      "[0:06:27.546045<1:36:27.354496, 0:00:12.918202s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 30/478 | 6.28%\n",
      "[0:06:41.347257<1:36:27.168642, 0:00:12.946686s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 31/478 | 6.49%\n",
      "[0:06:54.336473<1:36:14.814690, 0:00:12.948015s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 32/478 | 6.69%\n",
      "[0:07:06.274239<1:35:48.243445, 0:00:12.917401s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 33/478 | 6.90%\n",
      "[0:07:19.611916<1:35:40.814328, 0:00:12.929762s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 34/478 | 7.11%\n",
      "[0:07:31.408743<1:35:13.545099, 0:00:12.897393s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 35/478 | 7.32%\n",
      "[0:07:55.065677<1:37:12.750898, 0:00:13.196269s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 36/478 | 7.53%\n",
      "[0:08:09.635384<1:37:15.924549, 0:00:13.233389s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 37/478 | 7.74%\n",
      "[0:08:27.112132<1:37:51.824640, 0:00:13.345056s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 38/478 | 7.95%\n",
      "[0:08:41.642418<1:37:51.821233, 0:00:13.375447s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 39/478 | 8.16%\n",
      "[0:08:55.583880<1:37:44.643486, 0:00:13.389597s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 40/478 | 8.37%\n",
      "[0:09:07.886773<1:37:19.671204, 0:00:13.363092s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 41/478 | 8.58%\n",
      "[0:09:18.023705<1:36:32.817644, 0:00:13.286279s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 42/478 | 8.79%\n",
      "[0:09:30.762950<1:36:13.997295, 0:00:13.273557s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 43/478 | 9.00%\n",
      "[0:09:44.102879<1:36:01.378210, 0:00:13.275065s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 44/478 | 9.21%\n",
      "[0:09:58.486565<1:35:58.770533, 0:00:13.299701s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 45/478 | 9.41%\n",
      "[0:10:08.353325<1:35:13.231104, 0:00:13.225072s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 46/478 | 9.62%\n",
      "[0:10:18.703936<1:34:33.646934, 0:00:13.163914s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 47/478 | 9.83%\n",
      "[0:10:28.854957<1:33:53.492350, 0:00:13.101145s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 48/478 | 10.04%\n",
      "[0:10:39.419914<1:33:18.186594, 0:00:13.049386s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 49/478 | 10.25%\n",
      "[0:10:56.997427<1:33:43.898172, 0:00:13.139949s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 50/478 | 10.46%\n",
      "[0:11:10.089185<1:33:30.354708, 0:00:13.139004s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 51/478 | 10.67%\n",
      "[0:11:21.897436<1:33:06.313512, 0:00:13.113412s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 52/478 | 10.88%\n",
      "[0:11:36.620535<1:33:06.108200, 0:00:13.143784s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 53/478 | 11.09%\n",
      "[0:11:46.704653<1:32:28.940152, 0:00:13.087123s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 54/478 | 11.30%\n",
      "[0:12:07.121227<1:33:12.223278, 0:00:13.220386s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 55/478 | 11.51%\n",
      "[0:12:19.555147<1:32:53.076324, 0:00:13.206342s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 56/478 | 11.72%\n",
      "[0:12:38.716218<1:33:23.851431, 0:00:13.310811s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 57/478 | 11.92%\n",
      "[0:12:53.860847<1:33:23.819760, 0:00:13.342428s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 58/478 | 12.13%\n",
      "[0:13:06.995001<1:33:08.998262, 0:00:13.338898s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 59/478 | 12.34%\n",
      "[0:13:19.670162<1:32:51.035448, 0:00:13.327836s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 60/478 | 12.55%\n",
      "[0:13:37.457057<1:33:08.189895, 0:00:13.400935s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 61/478 | 12.76%\n",
      "[0:13:52.265192<1:33:04.230912, 0:00:13.423632s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 62/478 | 12.97%\n",
      "[0:14:06.921983<1:32:58.930490, 0:00:13.443206s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 63/478 | 13.18%\n",
      "[0:14:25.568308<1:33:19.145070, 0:00:13.524505s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 64/478 | 13.39%\n",
      "[0:14:40.378244<1:33:13.788053, 0:00:13.544281s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 65/478 | 13.60%\n",
      "[0:14:56.033017<1:33:13.418296, 0:00:13.576258s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 66/478 | 13.81%\n",
      "[0:15:14.010052<1:33:26.837751, 0:00:13.641941s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 67/478 | 14.02%\n",
      "[0:15:31.082446<1:33:33.879490, 0:00:13.692389s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 68/478 | 14.23%\n",
      "[0:15:44.613516<1:33:19.230859, 0:00:13.690051s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 69/478 | 14.44%\n",
      "[0:16:00.541554<1:33:18.584976, 0:00:13.722022s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 70/478 | 14.64%\n",
      "[0:16:14.838225<1:33:08.157212, 0:00:13.730116s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 71/478 | 14.85%\n",
      "[0:16:28.672532<1:32:55.014578, 0:00:13.731563s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 72/478 | 15.06%\n",
      "[0:16:42.836579<1:32:43.682235, 0:00:13.737487s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 73/478 | 15.27%\n",
      "[0:16:52.972603<1:32:10.282876, 0:00:13.688819s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 74/478 | 15.48%\n",
      "[0:17:03.835133<1:31:41.407405, 0:00:13.651135s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 75/478 | 15.69%\n",
      "[0:17:15.791486<1:31:18.791670, 0:00:13.628835s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 76/478 | 15.90%\n",
      "[0:17:31.016775<1:31:13.477169, 0:00:13.649569s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 77/478 | 16.11%\n",
      "[0:17:44.924389<1:31:01.150800, 0:00:13.652877s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 78/478 | 16.32%\n",
      "[0:17:57.385472<1:30:41.478609, 0:00:13.637791s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 79/478 | 16.53%\n",
      "[0:18:22.655546<1:31:25.711212, 0:00:13.783194s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 80/478 | 16.74%\n",
      "[0:18:35.823404<1:31:08.912406, 0:00:13.775598s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 81/478 | 16.95%\n",
      "[0:18:53.267082<1:31:12.850680, 0:00:13.820330s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 82/478 | 17.15%\n",
      "[0:19:09.861967<1:31:12.234805, 0:00:13.853759s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 83/478 | 17.36%\n",
      "[0:19:23.197921<1:30:55.952036, 0:00:13.847594s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 84/478 | 17.57%\n",
      "[0:19:33.631024<1:30:26.317632, 0:00:13.807424s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 85/478 | 17.78%\n",
      "[0:19:46.327474<1:30:07.446352, 0:00:13.794506s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 86/478 | 17.99%\n",
      "[0:19:56.342247<1:29:36.664460, 0:00:13.751060s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 87/478 | 18.20%\n",
      "[0:20:13.089121<1:29:36.190560, 0:00:13.785104s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 88/478 | 18.41%\n",
      "[0:20:23.789254<1:29:08.921549, 0:00:13.750441s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 89/478 | 18.62%\n",
      "[0:20:34.185521<1:28:40.710736, 0:00:13.713172s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 90/478 | 18.83%\n",
      "[0:20:44.086624<1:28:10.786134, 0:00:13.671282s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 91/478 | 19.04%\n",
      "[0:20:54.050303<1:27:41.559052, 0:00:13.630982s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 92/478 | 19.25%\n",
      "[0:21:08.503008<1:27:31.329545, 0:00:13.639817s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 93/478 | 19.46%\n",
      "[0:21:21.657000<1:27:15.705216, 0:00:13.634649s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 94/478 | 19.67%\n",
      "[0:21:38.140418<1:27:13.555588, 0:00:13.664636s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 95/478 | 19.87%\n",
      "[0:21:53.675563<1:27:07.333840, 0:00:13.684120s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 96/478 | 20.08%\n",
      "[0:22:08.380654<1:26:57.660126, 0:00:13.694646s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 97/478 | 20.29%\n",
      "[0:22:22.280893<1:26:44.762720, 0:00:13.696744s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 98/478 | 20.50%\n",
      "[0:22:36.894510<1:26:34.575895, 0:00:13.706005s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 99/478 | 20.71%\n",
      "[0:22:47.771081<1:26:10.174758, 0:00:13.677711s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 100/478 | 20.92%\n",
      "[0:23:02.496836<1:26:00.408799, 0:00:13.688087s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 101/478 | 21.13%\n",
      "[0:23:12.390674<1:25:32.734264, 0:00:13.650889s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 102/478 | 21.34%\n",
      "[0:23:25.395295<1:25:16.730625, 0:00:13.644615s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 103/478 | 21.55%\n",
      "[0:23:35.609419<1:24:50.749246, 0:00:13.611629s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 104/478 | 21.76%\n",
      "[0:23:51.197189<1:24:44.157477, 0:00:13.630449s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 105/478 | 21.97%\n",
      "[0:24:07.627312<1:24:40.352292, 0:00:13.656861s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 106/478 | 22.18%\n",
      "[0:24:19.719393<1:24:21.269927, 0:00:13.642237s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 107/478 | 22.38%\n",
      "[0:24:34.246027<1:24:10.657620, 0:00:13.650426s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 108/478 | 22.59%\n",
      "[0:24:48.424604<1:23:58.795368, 0:00:13.655272s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 109/478 | 22.80%\n",
      "[0:25:04.099031<1:23:51.895104, 0:00:13.673628s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 110/478 | 23.01%\n",
      "[0:25:15.127584<1:23:29.475866, 0:00:13.649798s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 111/478 | 23.22%\n",
      "[0:25:28.329460<1:23:14.362434, 0:00:13.645799s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 112/478 | 23.43%\n",
      "[0:25:41.642737<1:22:59.642440, 0:00:13.642856s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 113/478 | 23.64%\n",
      "[0:25:54.092039<1:22:42.188504, 0:00:13.632386s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 114/478 | 23.85%\n",
      "[0:26:12.285440<1:22:42.953061, 0:00:13.672047s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 115/478 | 24.06%\n",
      "[0:26:40.743677<1:23:15.424068, 0:00:13.799514s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 116/478 | 24.27%\n",
      "[0:26:55.109124<1:23:03.370711, 0:00:13.804351s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 117/478 | 24.48%\n",
      "[0:27:11.635596<1:22:57.871200, 0:00:13.827420s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 118/478 | 24.69%\n",
      "[0:27:21.780751<1:22:32.935243, 0:00:13.796477s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 119/478 | 24.90%\n",
      "[0:27:35.142069<1:22:17.840658, 0:00:13.792851s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 120/478 | 25.10%\n",
      "[0:27:46.422211<1:21:56.633988, 0:00:13.772084s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 121/478 | 25.31%\n",
      "[0:27:59.935817<1:21:42.107896, 0:00:13.769966s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 122/478 | 25.52%\n",
      "[0:28:13.919093<1:21:28.953500, 0:00:13.771700s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 123/478 | 25.73%\n",
      "[0:28:24.700659<1:21:06.645444, 0:00:13.747586s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 124/478 | 25.94%\n",
      "[0:28:39.421279<1:20:55.645610, 0:00:13.755370s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 125/478 | 26.15%\n",
      "[0:28:54.336027<1:20:45.129344, 0:00:13.764572s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 126/478 | 26.36%\n",
      "[0:29:11.686344<1:20:41.274906, 0:00:13.792806s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 127/478 | 26.57%\n",
      "[0:29:29.290112<1:20:37.902650, 0:00:13.822579s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 128/478 | 26.78%\n",
      "[0:29:51.109391<1:20:45.714581, 0:00:13.884569s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 129/478 | 26.99%\n",
      "[0:30:05.117952<1:20:32.162004, 0:00:13.885523s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 130/478 | 27.20%\n",
      "[0:30:21.555664<1:20:25.036735, 0:00:13.905005s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 131/478 | 27.41%\n",
      "[0:30:37.598618<1:20:16.735892, 0:00:13.921202s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 132/478 | 27.62%\n",
      "[0:30:54.052947<1:20:09.385560, 0:00:13.940248s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 133/478 | 27.82%\n",
      "[0:31:04.801602<1:19:47.251920, 0:00:13.916430s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 134/478 | 28.03%\n",
      "[0:31:18.472017<1:19:32.710544, 0:00:13.914608s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 135/478 | 28.24%\n",
      "[0:31:38.004583<1:19:32.923272, 0:00:13.955916s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 136/478 | 28.45%\n",
      "[0:31:53.211870<1:19:22.082050, 0:00:13.965050s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 137/478 | 28.66%\n",
      "[0:32:03.720916<1:18:59.602380, 0:00:13.940007s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 138/478 | 28.87%\n",
      "[0:32:14.096857<1:18:36.970074, 0:00:13.914366s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 139/478 | 29.08%\n",
      "[0:32:26.799826<1:18:20.130994, 0:00:13.905713s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 140/478 | 29.29%\n",
      "[0:32:46.640046<1:18:20.409274, 0:00:13.947802s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 141/478 | 29.50%\n",
      "[0:32:58.693748<1:18:01.979568, 0:00:13.934463s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 142/478 | 29.71%\n",
      "[0:33:12.099303<1:17:46.805940, 0:00:13.930764s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 143/478 | 29.92%\n",
      "[0:33:22.091988<1:17:23.741278, 0:00:13.903417s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 144/478 | 30.13%\n",
      "[0:33:32.175145<1:17:01.064310, 0:00:13.877070s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 145/478 | 30.33%\n",
      "[0:33:45.166332<1:16:45.172664, 0:00:13.871002s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 146/478 | 30.54%\n",
      "[0:33:55.557791<1:16:23.466892, 0:00:13.847332s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 147/478 | 30.75%\n",
      "[0:34:10.571320<1:16:12.219960, 0:00:13.855212s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 148/478 | 30.96%\n",
      "[0:34:24.619135<1:15:58.789816, 0:00:13.856504s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 149/478 | 31.17%\n",
      "[0:34:38.066620<1:15:44.038856, 0:00:13.853777s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 150/478 | 31.38%\n",
      "[0:34:55.805331<1:15:38.598462, 0:00:13.879506s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 151/478 | 31.59%\n",
      "[0:35:10.896353<1:15:27.317176, 0:00:13.887476s/generations] fine-tuned-mistral-7b-v0.2-instruct - promt 4: 152/478 | 31.80%\n"
     ]
    }
   ],
   "source": [
    "all_runs = pd.DataFrame()\n",
    "for i in range(len(SYSTEM_PROMPT)):\n",
    "    run = run_model(i, \"fine-tuned-mistral-7b-v0.2-instruct\")\n",
    "    all_runs = pd.concat([all_runs, run])\n",
    "    pd.DataFrame(all_runs).to_pickle(\"fine-tuned.pkl\")"
   ],
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-11T04:01:34.727708312Z"
    }
   },
   "id": "05aa5115",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3223579e746ec60",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
